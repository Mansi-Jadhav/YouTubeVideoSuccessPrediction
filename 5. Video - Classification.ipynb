{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16a16a8-2f0c-4366-8b16-234f3c36f59c",
   "metadata": {},
   "source": [
    "# VideoMAE - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c966d7-eddf-4e09-8650-5e9f4ebfc97d",
   "metadata": {},
   "source": [
    "Note that the feature extraction pipeline is given in the VideoMAE Regression file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab6b2f-27a4-43fb-ba60-2ee3e8c6819d",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "601ce04c-ee64-47ff-9e2a-d902df831522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report, confusion_matrix,\n",
    "    roc_curve, auc, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# ----------------------------- global knobs (match regression) -----------------------------\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 5\n",
    "N_EPOCHS = 40\n",
    "PATIENCE = 10\n",
    "N_TRIALS = 30\n",
    "FEATURE_DIR = \"videomae_features_new\"\n",
    "MODEL_DIR = Path(\"models_final\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR = Path(\"results_final\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "PIN = torch.cuda.is_available()\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "CSV_PATH = \"FinalDataset.csv\"\n",
    "NUM_CLASSES = 5  # adjust if your encoding uses a different count\n",
    "\n",
    "# Two label columns → choose by split name\n",
    "LABEL_COL_MAP = {\n",
    "    \"ind\": \"view_range_enc_ind\",\n",
    "    \"dep\": \"view_range_enc_dep\",\n",
    "}\n",
    "\n",
    "def set_seed(seed: int = SEED):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c4eb9-65ad-4e50-8f51-1011765d366c",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9d449da-5687-4f8f-8e15-459abaeb6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalFeatureDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, feature_dir: str, target_column: str):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.feature_dir = feature_dir     # Base directory containing .npy feature files\n",
    "        self.target_column = target_column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]   # select the idx-th row\n",
    "        video_id = row[\"video_id\"]\n",
    "        feature_path = os.path.join(self.feature_dir, f\"{video_id}_temporal.npy\") \n",
    "        features = np.load(feature_path)  # load features: expected shape [T, D]\n",
    "        label = int(row[self.target_column])  # fetch the target for this sample\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(label, dtype=torch.long)  # Convert to Pytorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e458cc9-81f6-44ad-8174-9ed4db4c217e",
   "metadata": {},
   "source": [
    "# Model - Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06fbb165-bcfd-420d-9cf5-3e7243ecd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, d_model=768, nhead=8, num_layers=2, num_classes=5):\n",
    "        super().__init__()\n",
    "        # One encoder block (self-attention + FFN + residual + norm)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers) # Stack 'num_layers' encoder blocks\n",
    "        self.classifier = nn.Linear(d_model, num_classes) # Linear classifier head mapping pooled [B, D] -> [B, num_classes].\n",
    "\n",
    "    def forward(self, x):  # x: (B, T, D)\n",
    "        x = x.permute(1, 0, 2)         # Permute as by default the transformer expects [T, B, D]\n",
    "        x = self.transformer(x)        # (T, B, D)\n",
    "        x = x.mean(dim=0)              # global average pooling over time\n",
    "        return self.classifier(x)      # Project to class logits - (B, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a068010-4b17-4b71-acd9-a880db000f94",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d3e2f5c-4031-463a-9a76-5300c68b91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_f1_from_logits(logits: np.ndarray, targets: np.ndarray):\n",
    "    preds = logits.argmax(axis=1)   # predicted class = argmax over classes\n",
    "    acc = accuracy_score(targets, preds)  # overall accuracy\n",
    "    f1  = f1_score(targets, preds, average=\"macro\")  # macro-F1 (treats classes equally)\n",
    "    return float(acc), float(f1)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, clip_norm: float = 1.0):\n",
    "    model.train()     # Set the model in train mode\n",
    "    total_loss, n = 0.0, 0\n",
    "    logits_all, tgts_all = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE, non_blocking=True)   # Move to device\n",
    "        y = y.to(DEVICE, non_blocking=True)   # Move to device\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)   # Instead of setting to 0, set the grads to None - slightly faster\n",
    "        logits = model(x)                 # forward pass -> logits (B, C)\n",
    "        loss = criterion(logits, y)       # Cross Entropy loss (expects long targets)\n",
    "        loss.backward()                # Backpropagation\n",
    "        \n",
    "        if clip_norm is not None:        # optional grad-norm clipping for stability\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "            \n",
    "        optimizer.step()                    # apply updates\n",
    "\n",
    "        bs = x.size(0)               # batch size\n",
    "        total_loss += loss.item() * bs    # accumulate sum of loss over samples\n",
    "        n += bs       # accumulate sample count\n",
    "\n",
    "        logits_all.append(logits.detach().cpu())   # Stash logits on CPU\n",
    "        tgts_all.append(y.detach().cpu())         # Stash targets on CPU\n",
    "\n",
    "    if n == 0:\n",
    "        return float(\"nan\"), float(\"nan\"), float(\"nan\")\n",
    "\n",
    "    # Concatenate all batches\n",
    "    logits_all = torch.cat(logits_all, dim=0).numpy()\n",
    "    tgts_all   = torch.cat(tgts_all,   dim=0).numpy()\n",
    "    \n",
    "    acc, f1 = acc_f1_from_logits(logits_all, tgts_all)   # Compute accuracy and macro-F1\n",
    "    avg_ce = total_loss / n             # convert summed loss to mean over samples\n",
    "    return avg_ce, acc, f1\n",
    "\n",
    "\n",
    "@torch.no_grad()                 # disable autograd for evaluation\n",
    "def evaluate(model, loader, criterion=None):\n",
    "    model.eval()         # Set eval mode\n",
    "    total_loss, n = 0.0, 0\n",
    "    logits_all, tgts_all = [], []\n",
    "\n",
    "    # Build/default CE once, move to DEVICE\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(DEVICE)\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE, non_blocking=True)   # Move inputs to device\n",
    "        y = y.to(DEVICE, non_blocking=True)   # Move targets to device\n",
    "\n",
    "        logits = model(x)       # (B, C)\n",
    "        loss = criterion(logits, y)   # CE on this batch\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        total_loss += loss.item() * batch_size     # accumulate sum of losses\n",
    "        n += batch_size\n",
    "\n",
    "        logits_all.append(logits.detach().cpu())\n",
    "        tgts_all.append(y.detach().cpu())\n",
    "\n",
    "    if n == 0:\n",
    "        # empty split safety\n",
    "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), np.empty((0,)), np.empty((0,)), np.empty((0,))\n",
    "\n",
    "    logits_all = torch.cat(logits_all, dim=0).numpy()     # (N, C)\n",
    "    tgts_all   = torch.cat(tgts_all,   dim=0).numpy()     # (N,)\n",
    "    probs = torch.softmax(torch.from_numpy(logits_all), dim=1).numpy()   # convert logits -> probs\n",
    "\n",
    "    acc, f1 = acc_f1_from_logits(logits_all, tgts_all)\n",
    "    avg_ce = total_loss / n         # mean cross entropy over samples\n",
    "    return avg_ce, acc, f1, probs, logits_all, tgts_all\n",
    "\n",
    "\n",
    "def class_weights_from_df(train_df, target_col, num_classes):\n",
    "    # Count per class using integer labels {0..num_classes-1}; fill missing with 0\n",
    "    counts = train_df[target_col].value_counts().reindex(range(num_classes), fill_value=0).astype(float).values\n",
    "    total = counts.sum()\n",
    "    if total <= 0:\n",
    "        # no training data- fall back to uniform\n",
    "        return torch.ones(num_classes, dtype=torch.float32, device=DEVICE)\n",
    "    \n",
    "    weights = total / (num_classes * np.maximum(counts, 1.0)) # Inverse-frequency scaling: total/(num_classes * count_c)\n",
    "    weights = np.maximum(weights, 1e-6)  # avoid zeros\n",
    "    return torch.tensor(weights, dtype=torch.float32, device=DEVICE)    # Return a tensor of weights\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, lr, weight_decay,\n",
    "                       n_epochs=N_EPOCHS, patience=PATIENCE, class_weights=None):\n",
    "    crit = nn.CrossEntropyLoss(weight=class_weights).to(DEVICE)   # Build CE with weights \n",
    "    opt  = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)  # Adam optimizer with weight decay\n",
    "\n",
    "    best_val_acc = -1.0\n",
    "    best_state = None; bad = 0; best_f1 = 0.0\n",
    "    \n",
    "    for ep in range(1, n_epochs + 1):\n",
    "        tr_ce, tr_acc, tr_f1 = train_one_epoch(model, train_loader, crit, opt) # One epoch of training (returns mean CE/Acc/F1 over the epoch)\n",
    "        va_ce, va_acc, va_f1, _, _, _ = evaluate(model, val_loader, crit)  # Validation (no grad)\n",
    "        print(f\"Epoch {ep:02d}: Train Loss={tr_ce:.4f}, Acc={tr_acc:.4f}, F1={tr_f1:.4f} | \"\n",
    "              f\"Val Loss={va_ce:.4f}, Acc={va_acc:.4f}, F1={va_f1:.4f}\")\n",
    "        if va_acc > best_val_acc:\n",
    "            best_val_acc, best_f1 = float(va_acc), float(va_f1)    # save metrics\n",
    "            best_state = copy.deepcopy(model.state_dict())         # save weights\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(\"Early stopping\"); break\n",
    "\n",
    "    # Restore best checkpoint before returning\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, best_val_acc, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc39c2-a0ec-4892-9974-7d49d0ca8e43",
   "metadata": {},
   "source": [
    "# Optuna - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07612f78-3801-4088-b287-acfb3047502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ optuna objective (mirrors reg) ------------------------------\n",
    "def objective_builder(train_df, val_df, input_dim=768, target_col=\"view_range_enc_ind\"):\n",
    "    def objective(trial):\n",
    "        print(f\"\\n[trial {trial.number}] build loaders...\", flush=True)\n",
    "        g = torch.Generator().manual_seed(SEED + trial.number)  # trial-specific RNG for shuffle order\n",
    "        train_loader = DataLoader(\n",
    "            TemporalFeatureDataset(train_df, FEATURE_DIR, target_col),\n",
    "            batch_size=BATCH_SIZE, shuffle=True, generator=g,\n",
    "            num_workers=NUM_WORKERS, pin_memory=PIN\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            TemporalFeatureDataset(val_df, FEATURE_DIR, target_col),\n",
    "            batch_size=BATCH_SIZE, shuffle=False,   # same dataset, no shuffle for val\n",
    "            num_workers=NUM_WORKERS, pin_memory=PIN\n",
    "        )\n",
    "\n",
    "        # hyperparams (kept parallel to regression)\n",
    "        nhead       = trial.suggest_categorical(\"nhead\", [4, 8])   # Suggests either 4 or 8\n",
    "        num_layers  = trial.suggest_int(\"num_layers\", 1, 4)        # Suggests any integer between 1 to 4\n",
    "        lr          = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)   # Suggests any positive float between the range sampled log uniformly\n",
    "        weight_decay= trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True) # Any positive float - also log uniform\n",
    "\n",
    "        model = TransformerClassifier(d_model=input_dim, nhead=nhead, num_layers=num_layers,\n",
    "                                      num_classes=NUM_CLASSES).to(DEVICE)  # Model instance\n",
    "\n",
    "        # class weights per split/target\n",
    "        cw = class_weights_from_df(train_df, target_col, NUM_CLASSES)\n",
    "\n",
    "        # Train and validate\n",
    "        model, val_acc, val_f1 = train_and_evaluate(\n",
    "            model, train_loader, val_loader, lr, weight_decay,\n",
    "            n_epochs=N_EPOCHS, patience=PATIENCE, class_weights=cw\n",
    "        )\n",
    "        \n",
    "        # Attach useful artifacts to the trial for later inspection\n",
    "        trial.set_user_attr(\"val_acc\", float(val_acc))\n",
    "        trial.set_user_attr(\"val_f1\", float(val_f1))\n",
    "        trial.set_user_attr(\"state_dict\", copy.deepcopy(model.state_dict()))\n",
    "        \n",
    "        return float(val_acc) # maximize accuracy\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0231a80f-7f7e-4cc2-8ad8-1349aa0c1667",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7142c850-16f3-47f4-82b2-a48c42d72b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ plotting helpers (heatmap + ROC) ------------------------\n",
    "def plot_confusion_heatmap(y_true, y_pred, num_classes, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))   # Get the confusion matrix\n",
    "    plt.figure(figsize=(6.5, 5.5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",     # Plot the heatmap of the confusion matrix for better visualisation\n",
    "                xticklabels=[f\"{i}\" for i in range(num_classes)],   # Predicted class labels\n",
    "                yticklabels=[f\"{i}\" for i in range(num_classes)])   # True class labels\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\") \n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return cm         # Return counts for further analysis\n",
    "\n",
    "def plot_multiclass_roc(y_true, probs, num_classes, title):\n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(num_classes))) # Binarize in one vs all fashion\n",
    "    plt.figure(figsize=(7.5, 6))\n",
    "    any_class = False    # Track if at least one class is plottable\n",
    "    for c in range(num_classes):          # Plot per class ROC\n",
    "        if y_true_bin[:, c].sum() == 0:         # Skip if no positive samples for the true values\n",
    "            continue\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, c], probs[:, c])  # ROC for class c vs rest\n",
    "        auc_c = auc(fpr, tpr)         # AUC for class c\n",
    "        plt.plot(fpr, tpr, lw=1.8, label=f\"Class {c} (AUC={auc_c:.3f})\")   # Add curve to the plot\n",
    "        any_class = True\n",
    "    # micro-average\n",
    "    try:\n",
    "        auc_micro = roc_auc_score(y_true_bin, probs, average=\"micro\", multi_class=\"ovr\")\n",
    "        fpr_micro, tpr_micro, _ = roc_curve(y_true_bin.ravel(), probs.ravel()) # Compute micro-average ROC curve by flattening all decisions\n",
    "        plt.plot(fpr_micro, tpr_micro, lw=2.2, linestyle=\"--\", label=f\"Micro (AUC={auc_micro:.3f})\")\n",
    "    except Exception:\n",
    "        auc_micro = np.nan\n",
    "    plt.plot([0,1],[0,1],\"k--\", lw=1)    # diagonal reference\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title + (\"\" if any_class else \" (no per-class ROC: missing labels)\"))\n",
    "    plt.legend(loc=\"lower right\", fontsize=9)\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return auc_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8de46b43-25eb-4e8d-88af-2831e85fb858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_split(name: str, train_ids: list, val_ids: list, input_dim: int = 768):\n",
    "    assert name in LABEL_COL_MAP, f\"name must be one of {list(LABEL_COL_MAP.keys())}\"\n",
    "    target_col = LABEL_COL_MAP[name]\n",
    "\n",
    "    print(f\"\\n=== Running CLASSIFICATION split: {name} (target: {target_col}) ===\")\n",
    "\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    train_df = df[df.video_id.isin(train_ids)].reset_index(drop=True)\n",
    "    val_df   = df[df.video_id.isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "    # Optuna (maximize accuracy)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=TPESampler(seed=SEED))\n",
    "    study.optimize(objective_builder(train_df, val_df, input_dim, target_col), n_trials=N_TRIALS)\n",
    "    best = study.best_params   # Get the best trial\n",
    "    print(\"Best hyper-parameters:\", best)\n",
    "    print(\"Best Val ACC (Optuna):\", study.best_trial.value, \"| Val F1:\", study.best_trial.user_attrs[\"val_f1\"])\n",
    "\n",
    "    # Rebuild best model and load exact best-epoch weights\n",
    "    model = TransformerClassifier(\n",
    "        d_model=input_dim, nhead=best[\"nhead\"], num_layers=best[\"num_layers\"], num_classes=NUM_CLASSES\n",
    "    ).to(DEVICE)\n",
    "    model.load_state_dict(study.best_trial.user_attrs[\"state_dict\"])\n",
    "\n",
    "    # Eval loaders (no shuffle)\n",
    "    train_loader = DataLoader(TemporalFeatureDataset(train_df, FEATURE_DIR, target_col),\n",
    "                              batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN)\n",
    "    val_loader   = DataLoader(TemporalFeatureDataset(val_df, FEATURE_DIR, target_col),\n",
    "                              batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN)\n",
    "\n",
    "    # Re-evaluate the reloaded model to verify results with Optuna’s numbers\n",
    "    tr_ce, tr_acc, tr_f1, tr_probs, tr_logits, tr_tgts = evaluate(model, train_loader)\n",
    "    va_ce, va_acc, va_f1, va_probs, va_logits, va_tgts = evaluate(model, val_loader)\n",
    "    print(f\"Reloaded eval — Train Acc={tr_acc:.4f}, F1={tr_f1:.4f} | \"\n",
    "          f\"Val Acc={va_acc:.4f}, F1={va_f1:.4f} | ΔACC={abs(va_acc - study.best_trial.value):.6f}\")\n",
    "\n",
    "    # Save bundle + study \n",
    "    bundle_path = MODEL_DIR / f\"video_cls_{name}.pt\"\n",
    "    torch.save({\n",
    "        \"state_dict\": study.best_trial.user_attrs[\"state_dict\"],\n",
    "        \"best_params\": best,\n",
    "        \"val_acc\": study.best_trial.value,\n",
    "        \"val_f1\": study.best_trial.user_attrs[\"val_f1\"],\n",
    "        \"num_classes\": NUM_CLASSES,\n",
    "        \"target_col\": target_col,\n",
    "    }, bundle_path)\n",
    "\n",
    "    with open(MODEL_DIR / f\"video_cls_{name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(study, f)  # Save the full Optuna study\n",
    "\n",
    "    # Save VAL predictions (for fusion)\n",
    "    va_pred = va_probs.argmax(axis=1)   # predicted class per sample (N,)\n",
    "    out = pd.DataFrame({\n",
    "        \"video_id\": val_df[\"video_id\"].values,  # aligns with val_loader order since shuffle=False\n",
    "        \"y_true\":   va_tgts.astype(int),\n",
    "        \"y_pred\":   va_pred.astype(int),\n",
    "    })\n",
    "    for c in range(NUM_CLASSES):\n",
    "        out[f\"prob_class_{c}\"] = va_probs[:, c]  # Append per-class probabilities as columns: prob_class_0 .. prob_class_{C-1}\n",
    "    fname = RESULTS_DIR / f\"video_cls_val_{name}.csv\"\n",
    "    out.to_csv(fname, index=False)\n",
    "    print(f\"Saved VAL preds → {fname}\")\n",
    "\n",
    "    # Confusion matrix (HEATMAP)\n",
    "    cm = plot_confusion_heatmap(va_tgts, va_pred, NUM_CLASSES, f\"Confusion Matrix (VAL) — {name}\")\n",
    "    print(\"\\nClassification Report (VAL):\\n\",\n",
    "          classification_report(va_tgts, va_pred, labels=list(range(NUM_CLASSES)), digits=4, zero_division=0)) # Detailed per-class precision/recall/F1 report\n",
    "\n",
    "    # ROC curves (multi-class)\n",
    "    auc_micro = plot_multiclass_roc(va_tgts, va_probs, NUM_CLASSES, f\"ROC Curves (VAL) — {name}\")\n",
    "    try:      # Macro-average AUC (may fail if some classes are entirely missing)\n",
    "        y_true_bin = label_binarize(va_tgts, classes=list(range(NUM_CLASSES)))\n",
    "        auc_macro = roc_auc_score(y_true_bin, va_probs, average=\"macro\", multi_class=\"ovr\")\n",
    "    except Exception:\n",
    "        auc_macro = np.nan\n",
    "    print(f\"\\nAUC-ROC (VAL): micro {auc_micro:.4f} | macro {auc_macro:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"train_df\": train_df, \"val_df\": val_df,\n",
    "        \"vl_probs\": va_probs, \"vl_logits\": va_logits, \"vl_tgts\": va_tgts,\n",
    "        \"vl_acc\": va_acc, \"vl_f1\": va_f1,\n",
    "        \"bundle_path\": bundle_path,\n",
    "        \"val_csv\": fname\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db3248-d5f9-4890-913c-473e382e0351",
   "metadata": {},
   "source": [
    "# Person - Independent Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "530af8e1-710a-4ebe-8d25-217cded42308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:39:11,329] A new study created in memory with name: no-name-6490882c-b6a2-42fe-b54a-ace4648a194e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running CLASSIFICATION split: ind (target: view_range_enc_ind) ===\n",
      "\n",
      "[trial 0] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.6233, Acc=0.1933, F1=0.1858 | Val Loss=2.1618, Acc=0.2200, F1=0.0721\n",
      "Epoch 02: Train Loss=1.8027, Acc=0.2167, F1=0.2181 | Val Loss=1.6407, Acc=0.2600, F1=0.0825\n",
      "Epoch 03: Train Loss=1.7734, Acc=0.1833, F1=0.1742 | Val Loss=1.7055, Acc=0.2600, F1=0.0825\n",
      "Epoch 04: Train Loss=1.7488, Acc=0.1767, F1=0.1732 | Val Loss=1.7002, Acc=0.1000, F1=0.0364\n",
      "Epoch 05: Train Loss=1.6886, Acc=0.1800, F1=0.1709 | Val Loss=1.6694, Acc=0.2600, F1=0.0825\n",
      "Epoch 06: Train Loss=1.6893, Acc=0.1867, F1=0.1820 | Val Loss=1.7222, Acc=0.1000, F1=0.0364\n",
      "Epoch 07: Train Loss=1.6721, Acc=0.2100, F1=0.2038 | Val Loss=1.5760, Acc=0.2600, F1=0.0825\n",
      "Epoch 08: Train Loss=1.6692, Acc=0.1767, F1=0.1683 | Val Loss=1.7620, Acc=0.1000, F1=0.0364\n",
      "Epoch 09: Train Loss=1.6624, Acc=0.1833, F1=0.1689 | Val Loss=1.7568, Acc=0.1000, F1=0.0364\n",
      "Epoch 10: Train Loss=1.6478, Acc=0.1800, F1=0.1699 | Val Loss=1.6421, Acc=0.2600, F1=0.0825\n",
      "Epoch 11: Train Loss=1.6494, Acc=0.2067, F1=0.1936 | Val Loss=1.5809, Acc=0.2600, F1=0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:40:26,126] Trial 0 finished with value: 0.26 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.0015751320499779737, 'weight_decay': 2.9380279387035354e-06}. Best is trial 0 with value: 0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=1.6466, Acc=0.1867, F1=0.1618 | Val Loss=1.6074, Acc=0.2600, F1=0.0825\n",
      "Early stopping\n",
      "\n",
      "[trial 1] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.4603, Acc=0.2333, F1=0.2196 | Val Loss=1.7023, Acc=0.1600, F1=0.0552\n",
      "Epoch 02: Train Loss=1.8486, Acc=0.2367, F1=0.2252 | Val Loss=1.8765, Acc=0.2600, F1=0.0825\n",
      "Epoch 03: Train Loss=1.7740, Acc=0.1800, F1=0.1631 | Val Loss=1.8801, Acc=0.2600, F1=0.0825\n",
      "Epoch 04: Train Loss=1.7789, Acc=0.1367, F1=0.1306 | Val Loss=1.5892, Acc=0.2600, F1=0.0825\n",
      "Epoch 05: Train Loss=1.6682, Acc=0.2167, F1=0.1945 | Val Loss=1.5895, Acc=0.2200, F1=0.0721\n",
      "Epoch 06: Train Loss=1.6883, Acc=0.1633, F1=0.1450 | Val Loss=1.7097, Acc=0.2600, F1=0.0825\n",
      "Epoch 07: Train Loss=1.6833, Acc=0.1733, F1=0.1513 | Val Loss=1.7061, Acc=0.1600, F1=0.0552\n",
      "Epoch 08: Train Loss=1.6701, Acc=0.2167, F1=0.1822 | Val Loss=1.6712, Acc=0.1000, F1=0.0364\n",
      "Epoch 09: Train Loss=1.6434, Acc=0.1933, F1=0.1594 | Val Loss=1.8349, Acc=0.1200, F1=0.0732\n",
      "Epoch 10: Train Loss=1.6352, Acc=0.2200, F1=0.1892 | Val Loss=1.6985, Acc=0.2600, F1=0.0825\n",
      "Epoch 11: Train Loss=1.6613, Acc=0.2067, F1=0.1946 | Val Loss=1.7169, Acc=0.1000, F1=0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:41:58,152] Trial 1 finished with value: 0.26 and parameters: {'nhead': 4, 'num_layers': 4, 'lr': 0.0015930522616241021, 'weight_decay': 0.000133112160807369}. Best is trial 0 with value: 0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=1.6481, Acc=0.1900, F1=0.1527 | Val Loss=1.5873, Acc=0.2600, F1=0.0825\n",
      "Early stopping\n",
      "\n",
      "[trial 2] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.1024, Acc=0.1333, F1=0.1287 | Val Loss=1.6039, Acc=0.2600, F1=0.0825\n",
      "Epoch 02: Train Loss=1.6772, Acc=0.2267, F1=0.2187 | Val Loss=1.8610, Acc=0.1600, F1=0.0932\n",
      "Epoch 03: Train Loss=1.6477, Acc=0.3233, F1=0.2968 | Val Loss=1.5401, Acc=0.3200, F1=0.1741\n",
      "Epoch 04: Train Loss=1.6660, Acc=0.2467, F1=0.2364 | Val Loss=1.7568, Acc=0.1200, F1=0.0867\n",
      "Epoch 05: Train Loss=1.5795, Acc=0.2967, F1=0.2753 | Val Loss=1.7506, Acc=0.3000, F1=0.1623\n",
      "Epoch 06: Train Loss=1.5205, Acc=0.3200, F1=0.3097 | Val Loss=1.5473, Acc=0.3200, F1=0.1971\n",
      "Epoch 07: Train Loss=1.5581, Acc=0.3000, F1=0.2873 | Val Loss=1.6896, Acc=0.3600, F1=0.2556\n",
      "Epoch 08: Train Loss=1.5020, Acc=0.3600, F1=0.3281 | Val Loss=1.6376, Acc=0.1600, F1=0.0552\n",
      "Epoch 09: Train Loss=1.5510, Acc=0.3133, F1=0.3129 | Val Loss=1.5713, Acc=0.3200, F1=0.2193\n",
      "Epoch 10: Train Loss=1.4818, Acc=0.3100, F1=0.2631 | Val Loss=1.5696, Acc=0.2200, F1=0.1414\n",
      "Epoch 11: Train Loss=1.5337, Acc=0.3133, F1=0.2907 | Val Loss=1.6420, Acc=0.2800, F1=0.1456\n",
      "Epoch 12: Train Loss=1.5218, Acc=0.3267, F1=0.3136 | Val Loss=1.5957, Acc=0.2200, F1=0.1264\n",
      "Epoch 13: Train Loss=1.5462, Acc=0.3100, F1=0.2826 | Val Loss=1.5597, Acc=0.3000, F1=0.1514\n",
      "Epoch 14: Train Loss=1.4929, Acc=0.3033, F1=0.2891 | Val Loss=1.6448, Acc=0.1600, F1=0.0552\n",
      "Epoch 15: Train Loss=1.4834, Acc=0.2800, F1=0.2748 | Val Loss=1.5984, Acc=0.2800, F1=0.1439\n",
      "Epoch 16: Train Loss=1.5060, Acc=0.2800, F1=0.2604 | Val Loss=1.7087, Acc=0.2600, F1=0.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:44:16,070] Trial 2 finished with value: 0.36 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00026587543983272726, 'weight_decay': 3.5113563139704077e-06}. Best is trial 2 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=1.4647, Acc=0.3167, F1=0.2924 | Val Loss=1.5540, Acc=0.3000, F1=0.1514\n",
      "Early stopping\n",
      "\n",
      "[trial 3] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.3817, Acc=0.1700, F1=0.1672 | Val Loss=1.7530, Acc=0.2200, F1=0.0721\n",
      "Epoch 02: Train Loss=1.7510, Acc=0.1633, F1=0.1618 | Val Loss=1.9110, Acc=0.1000, F1=0.0364\n",
      "Epoch 03: Train Loss=1.7876, Acc=0.1967, F1=0.1949 | Val Loss=1.5832, Acc=0.2600, F1=0.0825\n",
      "Epoch 04: Train Loss=1.7304, Acc=0.2300, F1=0.2246 | Val Loss=1.7744, Acc=0.1600, F1=0.0552\n",
      "Epoch 05: Train Loss=1.6849, Acc=0.2033, F1=0.1797 | Val Loss=1.6336, Acc=0.2600, F1=0.0825\n",
      "Epoch 06: Train Loss=1.6966, Acc=0.1767, F1=0.1674 | Val Loss=1.6874, Acc=0.1000, F1=0.0364\n",
      "Epoch 07: Train Loss=1.6801, Acc=0.1733, F1=0.1461 | Val Loss=1.8985, Acc=0.1000, F1=0.0364\n",
      "Epoch 08: Train Loss=1.6795, Acc=0.1800, F1=0.1471 | Val Loss=1.6928, Acc=0.1000, F1=0.0364\n",
      "Epoch 09: Train Loss=1.6993, Acc=0.1667, F1=0.1438 | Val Loss=1.6659, Acc=0.1600, F1=0.0552\n",
      "Epoch 10: Train Loss=1.6727, Acc=0.1767, F1=0.1603 | Val Loss=1.7040, Acc=0.1600, F1=0.0552\n",
      "Epoch 11: Train Loss=1.6434, Acc=0.2367, F1=0.1993 | Val Loss=1.5881, Acc=0.2200, F1=0.0721\n",
      "Epoch 12: Train Loss=1.6859, Acc=0.2233, F1=0.1899 | Val Loss=1.6021, Acc=0.2600, F1=0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:45:36,707] Trial 3 finished with value: 0.26 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.0007309539835912913, 'weight_decay': 7.4763120622522945e-06}. Best is trial 2 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.6512, Acc=0.1533, F1=0.1289 | Val Loss=1.7068, Acc=0.1000, F1=0.0364\n",
      "Early stopping\n",
      "\n",
      "[trial 4] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.2216, Acc=0.2267, F1=0.2256 | Val Loss=1.8254, Acc=0.1600, F1=0.0552\n",
      "Epoch 02: Train Loss=1.6377, Acc=0.3133, F1=0.2908 | Val Loss=1.7502, Acc=0.3600, F1=0.2755\n",
      "Epoch 03: Train Loss=1.6566, Acc=0.2700, F1=0.2659 | Val Loss=1.7387, Acc=0.2600, F1=0.1338\n",
      "Epoch 04: Train Loss=1.6076, Acc=0.2533, F1=0.2358 | Val Loss=1.8606, Acc=0.2600, F1=0.1545\n",
      "Epoch 05: Train Loss=1.5878, Acc=0.2900, F1=0.2745 | Val Loss=1.5963, Acc=0.3000, F1=0.1500\n",
      "Epoch 06: Train Loss=1.5219, Acc=0.2800, F1=0.2753 | Val Loss=1.5488, Acc=0.2800, F1=0.1412\n",
      "Epoch 07: Train Loss=1.5063, Acc=0.3033, F1=0.2801 | Val Loss=1.5395, Acc=0.2800, F1=0.1850\n",
      "Epoch 08: Train Loss=1.5276, Acc=0.3167, F1=0.3091 | Val Loss=1.5675, Acc=0.3400, F1=0.1945\n",
      "Epoch 09: Train Loss=1.5661, Acc=0.3433, F1=0.3386 | Val Loss=1.6047, Acc=0.3000, F1=0.1607\n",
      "Epoch 10: Train Loss=1.4959, Acc=0.3433, F1=0.3219 | Val Loss=1.6579, Acc=0.2800, F1=0.1460\n",
      "Epoch 11: Train Loss=1.5499, Acc=0.2667, F1=0.2430 | Val Loss=1.7970, Acc=0.1800, F1=0.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:46:28,059] Trial 4 finished with value: 0.36 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.0005404103854647331, 'weight_decay': 2.334586407601622e-05}. Best is trial 2 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=1.4829, Acc=0.3433, F1=0.3114 | Val Loss=1.6523, Acc=0.2800, F1=0.1400\n",
      "Early stopping\n",
      "\n",
      "[trial 5] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.3372, Acc=0.1900, F1=0.1875 | Val Loss=2.3083, Acc=0.1600, F1=0.0552\n",
      "Epoch 02: Train Loss=1.8581, Acc=0.1733, F1=0.1698 | Val Loss=1.8605, Acc=0.2600, F1=0.0825\n",
      "Epoch 03: Train Loss=1.7614, Acc=0.1733, F1=0.1685 | Val Loss=1.7991, Acc=0.1000, F1=0.0364\n",
      "Epoch 04: Train Loss=1.7558, Acc=0.2000, F1=0.1853 | Val Loss=1.7013, Acc=0.2600, F1=0.0825\n",
      "Epoch 05: Train Loss=1.7168, Acc=0.1933, F1=0.1891 | Val Loss=1.7806, Acc=0.1600, F1=0.0552\n",
      "Epoch 06: Train Loss=1.7145, Acc=0.2033, F1=0.1763 | Val Loss=1.5963, Acc=0.2200, F1=0.0721\n",
      "Epoch 07: Train Loss=1.6731, Acc=0.1800, F1=0.1614 | Val Loss=1.6633, Acc=0.1600, F1=0.0552\n",
      "Epoch 08: Train Loss=1.6749, Acc=0.1700, F1=0.1579 | Val Loss=1.7542, Acc=0.1600, F1=0.0552\n",
      "Epoch 09: Train Loss=1.6482, Acc=0.1733, F1=0.1626 | Val Loss=1.8426, Acc=0.1600, F1=0.0552\n",
      "Epoch 10: Train Loss=1.6588, Acc=0.1600, F1=0.1502 | Val Loss=1.6501, Acc=0.1000, F1=0.0364\n",
      "Epoch 11: Train Loss=1.6690, Acc=0.1900, F1=0.1889 | Val Loss=1.6834, Acc=0.1600, F1=0.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:47:40,682] Trial 5 finished with value: 0.26 and parameters: {'nhead': 4, 'num_layers': 3, 'lr': 0.0015304852121831463, 'weight_decay': 1.3783237455007196e-06}. Best is trial 2 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=1.6523, Acc=0.1767, F1=0.1651 | Val Loss=1.6865, Acc=0.1600, F1=0.0552\n",
      "Early stopping\n",
      "\n",
      "[trial 6] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=3.1601, Acc=0.1967, F1=0.1958 | Val Loss=1.6182, Acc=0.2600, F1=0.0825\n",
      "Epoch 02: Train Loss=1.9734, Acc=0.2033, F1=0.2030 | Val Loss=1.6177, Acc=0.2800, F1=0.1397\n",
      "Epoch 03: Train Loss=1.7047, Acc=0.1933, F1=0.1863 | Val Loss=1.8011, Acc=0.1600, F1=0.0552\n",
      "Epoch 04: Train Loss=1.7086, Acc=0.1633, F1=0.1582 | Val Loss=1.6496, Acc=0.1000, F1=0.0364\n",
      "Epoch 05: Train Loss=1.6588, Acc=0.1833, F1=0.1663 | Val Loss=1.7087, Acc=0.2200, F1=0.0721\n",
      "Epoch 06: Train Loss=1.6576, Acc=0.1467, F1=0.1432 | Val Loss=1.6199, Acc=0.2600, F1=0.0825\n",
      "Epoch 07: Train Loss=1.6347, Acc=0.1900, F1=0.1510 | Val Loss=1.6287, Acc=0.2600, F1=0.0825\n",
      "Epoch 08: Train Loss=1.6679, Acc=0.2200, F1=0.2177 | Val Loss=1.6304, Acc=0.2200, F1=0.0721\n",
      "Epoch 09: Train Loss=1.6378, Acc=0.1767, F1=0.1734 | Val Loss=1.7774, Acc=0.2000, F1=0.1096\n",
      "Epoch 10: Train Loss=1.6521, Acc=0.2067, F1=0.1990 | Val Loss=1.6150, Acc=0.2600, F1=0.0825\n",
      "Epoch 11: Train Loss=1.6651, Acc=0.1933, F1=0.1853 | Val Loss=1.5845, Acc=0.2200, F1=0.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:48:11,183] Trial 6 finished with value: 0.28 and parameters: {'nhead': 4, 'num_layers': 1, 'lr': 0.007902619549708232, 'weight_decay': 0.0007886714129990489}. Best is trial 2 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=1.6281, Acc=0.2600, F1=0.2460 | Val Loss=1.5392, Acc=0.1600, F1=0.0964\n",
      "Early stopping\n",
      "\n",
      "[trial 7] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.4812, Acc=0.2300, F1=0.2251 | Val Loss=1.7774, Acc=0.2200, F1=0.1333\n",
      "Epoch 02: Train Loss=1.8293, Acc=0.2300, F1=0.2274 | Val Loss=1.6476, Acc=0.2400, F1=0.1429\n",
      "Epoch 03: Train Loss=1.6483, Acc=0.3233, F1=0.3139 | Val Loss=1.7653, Acc=0.3000, F1=0.1642\n",
      "Epoch 04: Train Loss=1.7749, Acc=0.2367, F1=0.2207 | Val Loss=2.0504, Acc=0.1200, F1=0.0916\n",
      "Epoch 05: Train Loss=1.7324, Acc=0.2767, F1=0.2569 | Val Loss=1.7018, Acc=0.1600, F1=0.0552\n",
      "Epoch 06: Train Loss=1.5994, Acc=0.2700, F1=0.2566 | Val Loss=1.8413, Acc=0.2800, F1=0.1759\n",
      "Epoch 07: Train Loss=1.5470, Acc=0.2700, F1=0.2667 | Val Loss=1.7779, Acc=0.2800, F1=0.1412\n",
      "Epoch 08: Train Loss=1.5822, Acc=0.2867, F1=0.2351 | Val Loss=1.7970, Acc=0.2800, F1=0.1545\n",
      "Epoch 09: Train Loss=1.5582, Acc=0.3267, F1=0.3211 | Val Loss=1.5709, Acc=0.2600, F1=0.1431\n",
      "Epoch 10: Train Loss=1.5438, Acc=0.3000, F1=0.2666 | Val Loss=1.6013, Acc=0.2200, F1=0.1954\n",
      "Epoch 11: Train Loss=1.5229, Acc=0.2833, F1=0.2645 | Val Loss=1.6336, Acc=0.3000, F1=0.1998\n",
      "Epoch 12: Train Loss=1.4752, Acc=0.3300, F1=0.2897 | Val Loss=1.6120, Acc=0.2600, F1=0.1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:48:44,335] Trial 7 finished with value: 0.3 and parameters: {'nhead': 4, 'num_layers': 1, 'lr': 0.0023359635026261607, 'weight_decay': 2.091498132903561e-05}. Best is trial 2 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.4805, Acc=0.2967, F1=0.2663 | Val Loss=1.6058, Acc=0.2800, F1=0.1456\n",
      "Early stopping\n",
      "\n",
      "[trial 8] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=3.0625, Acc=0.2000, F1=0.1991 | Val Loss=2.4224, Acc=0.1600, F1=0.0552\n",
      "Epoch 02: Train Loss=2.1922, Acc=0.2033, F1=0.2028 | Val Loss=2.5779, Acc=0.2600, F1=0.0825\n",
      "Epoch 03: Train Loss=1.7535, Acc=0.2367, F1=0.2383 | Val Loss=1.5342, Acc=0.3000, F1=0.1956\n",
      "Epoch 04: Train Loss=1.6338, Acc=0.2600, F1=0.2429 | Val Loss=1.5624, Acc=0.3000, F1=0.2020\n",
      "Epoch 05: Train Loss=1.5560, Acc=0.3000, F1=0.2831 | Val Loss=1.9016, Acc=0.1400, F1=0.0993\n",
      "Epoch 06: Train Loss=1.5247, Acc=0.2600, F1=0.2518 | Val Loss=1.6841, Acc=0.3400, F1=0.2844\n",
      "Epoch 07: Train Loss=1.5039, Acc=0.3133, F1=0.3007 | Val Loss=1.6779, Acc=0.2400, F1=0.1455\n",
      "Epoch 08: Train Loss=1.4370, Acc=0.3267, F1=0.3153 | Val Loss=1.5956, Acc=0.2800, F1=0.2053\n",
      "Epoch 09: Train Loss=1.3911, Acc=0.3500, F1=0.3422 | Val Loss=1.7728, Acc=0.2200, F1=0.1016\n",
      "Epoch 10: Train Loss=1.3845, Acc=0.3000, F1=0.2907 | Val Loss=1.6777, Acc=0.2600, F1=0.1888\n",
      "Epoch 11: Train Loss=1.3027, Acc=0.3367, F1=0.3209 | Val Loss=1.7025, Acc=0.2800, F1=0.2185\n",
      "Epoch 12: Train Loss=1.2344, Acc=0.3633, F1=0.3319 | Val Loss=1.7986, Acc=0.1600, F1=0.1074\n",
      "Epoch 13: Train Loss=1.2007, Acc=0.4200, F1=0.4177 | Val Loss=2.0850, Acc=0.3000, F1=0.2239\n",
      "Epoch 14: Train Loss=1.0940, Acc=0.4233, F1=0.4140 | Val Loss=2.4504, Acc=0.2400, F1=0.1707\n",
      "Epoch 15: Train Loss=1.2328, Acc=0.4367, F1=0.4284 | Val Loss=2.3423, Acc=0.1600, F1=0.1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:49:25,843] Trial 8 finished with value: 0.34 and parameters: {'nhead': 8, 'num_layers': 1, 'lr': 0.006586289317583112, 'weight_decay': 5.975027999960295e-06}. Best is trial 2 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=1.0742, Acc=0.4867, F1=0.4543 | Val Loss=2.4366, Acc=0.2400, F1=0.1769\n",
      "Early stopping\n",
      "\n",
      "[trial 9] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.7885, Acc=0.2033, F1=0.2027 | Val Loss=1.9324, Acc=0.1000, F1=0.0364\n",
      "Epoch 02: Train Loss=1.7889, Acc=0.1900, F1=0.1816 | Val Loss=1.6004, Acc=0.2200, F1=0.0721\n",
      "Epoch 03: Train Loss=1.7357, Acc=0.2033, F1=0.1822 | Val Loss=1.6215, Acc=0.2600, F1=0.0825\n",
      "Epoch 04: Train Loss=1.7398, Acc=0.2200, F1=0.1979 | Val Loss=1.7126, Acc=0.1600, F1=0.0552\n",
      "Epoch 05: Train Loss=1.7349, Acc=0.2133, F1=0.2068 | Val Loss=1.6491, Acc=0.2600, F1=0.0825\n",
      "Epoch 06: Train Loss=1.6969, Acc=0.1567, F1=0.1532 | Val Loss=1.6680, Acc=0.2600, F1=0.0825\n",
      "Epoch 07: Train Loss=1.6883, Acc=0.1933, F1=0.1693 | Val Loss=1.7643, Acc=0.1600, F1=0.0552\n",
      "Epoch 08: Train Loss=1.6889, Acc=0.2233, F1=0.1931 | Val Loss=1.6581, Acc=0.1000, F1=0.0364\n",
      "Epoch 09: Train Loss=1.6936, Acc=0.1733, F1=0.1691 | Val Loss=1.6479, Acc=0.2600, F1=0.0825\n",
      "Epoch 10: Train Loss=1.6323, Acc=0.2133, F1=0.1746 | Val Loss=1.7577, Acc=0.1600, F1=0.0552\n",
      "Epoch 11: Train Loss=1.6954, Acc=0.2233, F1=0.1970 | Val Loss=1.6561, Acc=0.2200, F1=0.0721\n",
      "Epoch 12: Train Loss=1.6507, Acc=0.1800, F1=0.1704 | Val Loss=1.6446, Acc=0.1600, F1=0.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:50:45,450] Trial 9 finished with value: 0.26 and parameters: {'nhead': 4, 'num_layers': 3, 'lr': 0.0012399967836846098, 'weight_decay': 3.5856126103453987e-06}. Best is trial 2 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.6494, Acc=0.1900, F1=0.1542 | Val Loss=1.6214, Acc=0.1600, F1=0.0552\n",
      "Early stopping\n",
      "\n",
      "[trial 10] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.8731, Acc=0.2267, F1=0.2137 | Val Loss=1.5949, Acc=0.2800, F1=0.1547\n",
      "Epoch 02: Train Loss=1.6202, Acc=0.2733, F1=0.2643 | Val Loss=1.7167, Acc=0.2600, F1=0.1467\n",
      "Epoch 03: Train Loss=1.6393, Acc=0.2900, F1=0.2882 | Val Loss=1.5166, Acc=0.3600, F1=0.2567\n",
      "Epoch 04: Train Loss=1.5489, Acc=0.3100, F1=0.3007 | Val Loss=1.7838, Acc=0.1600, F1=0.0561\n",
      "Epoch 05: Train Loss=1.5313, Acc=0.3633, F1=0.3483 | Val Loss=1.6114, Acc=0.3400, F1=0.2724\n",
      "Epoch 06: Train Loss=1.5529, Acc=0.2700, F1=0.2608 | Val Loss=1.6362, Acc=0.3000, F1=0.2216\n",
      "Epoch 07: Train Loss=1.5767, Acc=0.3200, F1=0.3148 | Val Loss=1.5608, Acc=0.3600, F1=0.2752\n",
      "Epoch 08: Train Loss=1.5059, Acc=0.3233, F1=0.3138 | Val Loss=1.6017, Acc=0.4200, F1=0.2879\n",
      "Epoch 09: Train Loss=1.4748, Acc=0.3533, F1=0.3399 | Val Loss=1.6099, Acc=0.3800, F1=0.2622\n",
      "Epoch 10: Train Loss=1.4422, Acc=0.3767, F1=0.3598 | Val Loss=1.4897, Acc=0.3200, F1=0.2364\n",
      "Epoch 11: Train Loss=1.5225, Acc=0.3600, F1=0.3584 | Val Loss=1.4741, Acc=0.3800, F1=0.3333\n",
      "Epoch 12: Train Loss=1.4471, Acc=0.4000, F1=0.3857 | Val Loss=1.5314, Acc=0.2600, F1=0.1338\n",
      "Epoch 13: Train Loss=1.4474, Acc=0.3967, F1=0.3684 | Val Loss=1.5906, Acc=0.3000, F1=0.1952\n",
      "Epoch 14: Train Loss=1.4282, Acc=0.3467, F1=0.3345 | Val Loss=1.4158, Acc=0.4600, F1=0.3865\n",
      "Epoch 15: Train Loss=1.3335, Acc=0.4267, F1=0.4191 | Val Loss=1.6758, Acc=0.4000, F1=0.2765\n",
      "Epoch 16: Train Loss=1.3370, Acc=0.4133, F1=0.4066 | Val Loss=1.4381, Acc=0.4800, F1=0.4213\n",
      "Epoch 17: Train Loss=1.2857, Acc=0.4500, F1=0.4359 | Val Loss=1.4792, Acc=0.4800, F1=0.4025\n",
      "Epoch 18: Train Loss=1.3631, Acc=0.4500, F1=0.4473 | Val Loss=1.7089, Acc=0.3000, F1=0.2709\n",
      "Epoch 19: Train Loss=1.2320, Acc=0.4733, F1=0.4601 | Val Loss=1.4719, Acc=0.3400, F1=0.3185\n",
      "Epoch 20: Train Loss=1.2820, Acc=0.5167, F1=0.5069 | Val Loss=1.4974, Acc=0.3600, F1=0.3058\n",
      "Epoch 21: Train Loss=1.2037, Acc=0.5200, F1=0.5152 | Val Loss=1.6872, Acc=0.3400, F1=0.2684\n",
      "Epoch 22: Train Loss=1.1352, Acc=0.5200, F1=0.5187 | Val Loss=1.9966, Acc=0.4000, F1=0.3110\n",
      "Epoch 23: Train Loss=1.0928, Acc=0.5833, F1=0.5802 | Val Loss=1.7055, Acc=0.3400, F1=0.2614\n",
      "Epoch 24: Train Loss=1.1303, Acc=0.5600, F1=0.5623 | Val Loss=2.0829, Acc=0.4800, F1=0.3765\n",
      "Epoch 25: Train Loss=1.0125, Acc=0.6567, F1=0.6575 | Val Loss=1.5718, Acc=0.4600, F1=0.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:54:15,378] Trial 10 finished with value: 0.48 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00010353677627159794, 'weight_decay': 0.00010323015857001468}. Best is trial 10 with value: 0.48.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=0.8060, Acc=0.6767, F1=0.6774 | Val Loss=2.1666, Acc=0.4200, F1=0.3571\n",
      "Early stopping\n",
      "\n",
      "[trial 11] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9518, Acc=0.2233, F1=0.2206 | Val Loss=1.6765, Acc=0.1600, F1=0.0819\n",
      "Epoch 02: Train Loss=1.6018, Acc=0.3033, F1=0.2887 | Val Loss=1.6411, Acc=0.3000, F1=0.1887\n",
      "Epoch 03: Train Loss=1.6083, Acc=0.3267, F1=0.3174 | Val Loss=1.6909, Acc=0.2400, F1=0.1286\n",
      "Epoch 04: Train Loss=1.5673, Acc=0.3300, F1=0.3184 | Val Loss=1.6164, Acc=0.3600, F1=0.3027\n",
      "Epoch 05: Train Loss=1.5553, Acc=0.3500, F1=0.3096 | Val Loss=1.6159, Acc=0.2600, F1=0.1689\n",
      "Epoch 06: Train Loss=1.5509, Acc=0.3267, F1=0.3210 | Val Loss=1.6561, Acc=0.2200, F1=0.1511\n",
      "Epoch 07: Train Loss=1.5193, Acc=0.3133, F1=0.3090 | Val Loss=1.6851, Acc=0.2800, F1=0.1834\n",
      "Epoch 08: Train Loss=1.4616, Acc=0.3767, F1=0.3610 | Val Loss=1.6020, Acc=0.2000, F1=0.1470\n",
      "Epoch 09: Train Loss=1.4721, Acc=0.3833, F1=0.3619 | Val Loss=1.6663, Acc=0.3400, F1=0.2490\n",
      "Epoch 10: Train Loss=1.4890, Acc=0.3633, F1=0.3542 | Val Loss=1.5194, Acc=0.3800, F1=0.2763\n",
      "Epoch 11: Train Loss=1.4161, Acc=0.3833, F1=0.3745 | Val Loss=1.5984, Acc=0.3200, F1=0.2259\n",
      "Epoch 12: Train Loss=1.4434, Acc=0.3900, F1=0.3727 | Val Loss=1.5621, Acc=0.4000, F1=0.3046\n",
      "Epoch 13: Train Loss=1.4240, Acc=0.3800, F1=0.3393 | Val Loss=1.5324, Acc=0.4400, F1=0.4162\n",
      "Epoch 14: Train Loss=1.4523, Acc=0.3700, F1=0.3524 | Val Loss=1.5218, Acc=0.3400, F1=0.2469\n",
      "Epoch 15: Train Loss=1.4373, Acc=0.3567, F1=0.3481 | Val Loss=1.6429, Acc=0.3200, F1=0.2757\n",
      "Epoch 16: Train Loss=1.3657, Acc=0.4333, F1=0.4126 | Val Loss=1.5519, Acc=0.3600, F1=0.2719\n",
      "Epoch 17: Train Loss=1.3345, Acc=0.4333, F1=0.4227 | Val Loss=1.5312, Acc=0.4600, F1=0.3219\n",
      "Epoch 18: Train Loss=1.3181, Acc=0.4567, F1=0.4467 | Val Loss=1.6107, Acc=0.3000, F1=0.2000\n",
      "Epoch 19: Train Loss=1.3085, Acc=0.4600, F1=0.4421 | Val Loss=1.5916, Acc=0.3000, F1=0.1859\n",
      "Epoch 20: Train Loss=1.2702, Acc=0.4467, F1=0.4356 | Val Loss=1.6717, Acc=0.3600, F1=0.2966\n",
      "Epoch 21: Train Loss=1.2270, Acc=0.5033, F1=0.4782 | Val Loss=1.6593, Acc=0.3800, F1=0.3157\n",
      "Epoch 22: Train Loss=1.1643, Acc=0.5067, F1=0.5035 | Val Loss=1.7965, Acc=0.4000, F1=0.3000\n",
      "Epoch 23: Train Loss=1.1187, Acc=0.5200, F1=0.5054 | Val Loss=1.7130, Acc=0.3800, F1=0.3240\n",
      "Epoch 24: Train Loss=1.1104, Acc=0.5300, F1=0.5141 | Val Loss=1.7905, Acc=0.3800, F1=0.3747\n",
      "Epoch 25: Train Loss=1.1109, Acc=0.5300, F1=0.5271 | Val Loss=1.7963, Acc=0.4000, F1=0.2907\n",
      "Epoch 26: Train Loss=0.9070, Acc=0.6267, F1=0.6202 | Val Loss=1.8858, Acc=0.4000, F1=0.3556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 18:57:53,054] Trial 11 finished with value: 0.46 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00010703464927379283, 'weight_decay': 0.00017476943076551356}. Best is trial 10 with value: 0.48.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss=0.8817, Acc=0.6767, F1=0.6717 | Val Loss=2.6533, Acc=0.3200, F1=0.2619\n",
      "Early stopping\n",
      "\n",
      "[trial 12] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9123, Acc=0.2533, F1=0.2520 | Val Loss=1.7822, Acc=0.2800, F1=0.1764\n",
      "Epoch 02: Train Loss=1.6676, Acc=0.2567, F1=0.2447 | Val Loss=1.5860, Acc=0.3000, F1=0.2029\n",
      "Epoch 03: Train Loss=1.5873, Acc=0.3233, F1=0.3074 | Val Loss=1.6713, Acc=0.3400, F1=0.2441\n",
      "Epoch 04: Train Loss=1.5829, Acc=0.2667, F1=0.2577 | Val Loss=1.6969, Acc=0.2800, F1=0.1460\n",
      "Epoch 05: Train Loss=1.5706, Acc=0.3167, F1=0.3005 | Val Loss=1.7909, Acc=0.2600, F1=0.1337\n",
      "Epoch 06: Train Loss=1.5907, Acc=0.2967, F1=0.2896 | Val Loss=1.6150, Acc=0.3000, F1=0.2300\n",
      "Epoch 07: Train Loss=1.5327, Acc=0.3400, F1=0.3175 | Val Loss=1.6563, Acc=0.2600, F1=0.1361\n",
      "Epoch 08: Train Loss=1.4838, Acc=0.3233, F1=0.3061 | Val Loss=1.5641, Acc=0.3200, F1=0.2105\n",
      "Epoch 09: Train Loss=1.5532, Acc=0.3067, F1=0.2946 | Val Loss=1.5948, Acc=0.3400, F1=0.2375\n",
      "Epoch 10: Train Loss=1.5455, Acc=0.3067, F1=0.2949 | Val Loss=1.6481, Acc=0.3200, F1=0.2262\n",
      "Epoch 11: Train Loss=1.4968, Acc=0.3233, F1=0.3094 | Val Loss=1.5201, Acc=0.4200, F1=0.2890\n",
      "Epoch 12: Train Loss=1.5009, Acc=0.3400, F1=0.3218 | Val Loss=1.6875, Acc=0.2800, F1=0.1904\n",
      "Epoch 13: Train Loss=1.4864, Acc=0.3333, F1=0.3120 | Val Loss=1.5893, Acc=0.2800, F1=0.1979\n",
      "Epoch 14: Train Loss=1.4626, Acc=0.3167, F1=0.2887 | Val Loss=1.5026, Acc=0.3400, F1=0.2453\n",
      "Epoch 15: Train Loss=1.4878, Acc=0.3767, F1=0.3674 | Val Loss=1.5869, Acc=0.3000, F1=0.1901\n",
      "Epoch 16: Train Loss=1.4286, Acc=0.3767, F1=0.3739 | Val Loss=1.6738, Acc=0.3000, F1=0.1976\n",
      "Epoch 17: Train Loss=1.3777, Acc=0.4233, F1=0.3973 | Val Loss=1.5989, Acc=0.4800, F1=0.3389\n",
      "Epoch 18: Train Loss=1.4186, Acc=0.4200, F1=0.4151 | Val Loss=1.5093, Acc=0.4200, F1=0.2873\n",
      "Epoch 19: Train Loss=1.3415, Acc=0.4300, F1=0.4141 | Val Loss=1.4696, Acc=0.4400, F1=0.3096\n",
      "Epoch 20: Train Loss=1.4387, Acc=0.3833, F1=0.3804 | Val Loss=1.5663, Acc=0.2800, F1=0.1673\n",
      "Epoch 21: Train Loss=1.3671, Acc=0.4133, F1=0.4125 | Val Loss=1.4557, Acc=0.4400, F1=0.3751\n",
      "Epoch 22: Train Loss=1.3581, Acc=0.4500, F1=0.4343 | Val Loss=1.5575, Acc=0.3800, F1=0.3246\n",
      "Epoch 23: Train Loss=1.3283, Acc=0.4300, F1=0.4269 | Val Loss=1.5466, Acc=0.3200, F1=0.2704\n",
      "Epoch 24: Train Loss=1.2915, Acc=0.4433, F1=0.4391 | Val Loss=1.4994, Acc=0.4000, F1=0.3576\n",
      "Epoch 25: Train Loss=1.2802, Acc=0.4800, F1=0.4715 | Val Loss=1.4672, Acc=0.4800, F1=0.4471\n",
      "Epoch 26: Train Loss=1.2597, Acc=0.4667, F1=0.4521 | Val Loss=1.4828, Acc=0.5400, F1=0.4381\n",
      "Epoch 27: Train Loss=1.2226, Acc=0.4667, F1=0.4535 | Val Loss=1.7311, Acc=0.3200, F1=0.2393\n",
      "Epoch 28: Train Loss=1.1885, Acc=0.4567, F1=0.4501 | Val Loss=1.7559, Acc=0.4000, F1=0.3467\n",
      "Epoch 29: Train Loss=1.1536, Acc=0.5233, F1=0.5095 | Val Loss=1.6813, Acc=0.4200, F1=0.3646\n",
      "Epoch 30: Train Loss=1.0607, Acc=0.5767, F1=0.5744 | Val Loss=1.9555, Acc=0.3800, F1=0.3145\n",
      "Epoch 31: Train Loss=1.0175, Acc=0.5867, F1=0.5799 | Val Loss=1.7218, Acc=0.4600, F1=0.4259\n",
      "Epoch 32: Train Loss=0.9860, Acc=0.6200, F1=0.6206 | Val Loss=1.8456, Acc=0.4400, F1=0.3670\n",
      "Epoch 33: Train Loss=0.9116, Acc=0.6267, F1=0.6200 | Val Loss=1.8019, Acc=0.4200, F1=0.3851\n",
      "Epoch 34: Train Loss=0.8195, Acc=0.6600, F1=0.6605 | Val Loss=2.4158, Acc=0.3400, F1=0.2676\n",
      "Epoch 35: Train Loss=0.7458, Acc=0.7100, F1=0.7111 | Val Loss=2.1232, Acc=0.4600, F1=0.4477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:02:52,552] Trial 12 finished with value: 0.54 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00010752174995221688, 'weight_decay': 0.00017350533812756405}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=0.6661, Acc=0.7600, F1=0.7612 | Val Loss=2.5038, Acc=0.4200, F1=0.3514\n",
      "Early stopping\n",
      "\n",
      "[trial 13] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9161, Acc=0.2133, F1=0.2127 | Val Loss=1.5768, Acc=0.3200, F1=0.1997\n",
      "Epoch 02: Train Loss=1.6019, Acc=0.3000, F1=0.2988 | Val Loss=1.5926, Acc=0.3400, F1=0.2405\n",
      "Epoch 03: Train Loss=1.5787, Acc=0.3033, F1=0.2797 | Val Loss=1.6451, Acc=0.2600, F1=0.1659\n",
      "Epoch 04: Train Loss=1.5428, Acc=0.3533, F1=0.3279 | Val Loss=1.5827, Acc=0.4000, F1=0.3172\n",
      "Epoch 05: Train Loss=1.5992, Acc=0.2800, F1=0.2729 | Val Loss=1.5480, Acc=0.3000, F1=0.1844\n",
      "Epoch 06: Train Loss=1.5324, Acc=0.3033, F1=0.2959 | Val Loss=1.5224, Acc=0.3200, F1=0.2526\n",
      "Epoch 07: Train Loss=1.5113, Acc=0.3033, F1=0.2780 | Val Loss=1.5092, Acc=0.3400, F1=0.3074\n",
      "Epoch 08: Train Loss=1.5379, Acc=0.3333, F1=0.3256 | Val Loss=1.6806, Acc=0.1800, F1=0.1219\n",
      "Epoch 09: Train Loss=1.4702, Acc=0.3433, F1=0.3350 | Val Loss=1.6060, Acc=0.3200, F1=0.2472\n",
      "Epoch 10: Train Loss=1.4781, Acc=0.3667, F1=0.3509 | Val Loss=1.5397, Acc=0.3800, F1=0.3481\n",
      "Epoch 11: Train Loss=1.4324, Acc=0.4100, F1=0.3856 | Val Loss=1.4750, Acc=0.4400, F1=0.3476\n",
      "Epoch 12: Train Loss=1.4334, Acc=0.3833, F1=0.3455 | Val Loss=1.4986, Acc=0.4800, F1=0.3979\n",
      "Epoch 13: Train Loss=1.3968, Acc=0.3600, F1=0.3531 | Val Loss=1.4996, Acc=0.4000, F1=0.3130\n",
      "Epoch 14: Train Loss=1.3489, Acc=0.4067, F1=0.3873 | Val Loss=1.5805, Acc=0.3400, F1=0.2386\n",
      "Epoch 15: Train Loss=1.3766, Acc=0.4167, F1=0.4157 | Val Loss=1.4589, Acc=0.4200, F1=0.3225\n",
      "Epoch 16: Train Loss=1.3308, Acc=0.4067, F1=0.3870 | Val Loss=1.5826, Acc=0.3000, F1=0.2742\n",
      "Epoch 17: Train Loss=1.3096, Acc=0.4467, F1=0.4403 | Val Loss=1.5433, Acc=0.3200, F1=0.2615\n",
      "Epoch 18: Train Loss=1.2543, Acc=0.4500, F1=0.4353 | Val Loss=1.6304, Acc=0.4600, F1=0.3645\n",
      "Epoch 19: Train Loss=1.2531, Acc=0.4533, F1=0.4386 | Val Loss=1.9029, Acc=0.3800, F1=0.3312\n",
      "Epoch 20: Train Loss=1.2100, Acc=0.5233, F1=0.5135 | Val Loss=1.7062, Acc=0.3200, F1=0.3004\n",
      "Epoch 21: Train Loss=1.1530, Acc=0.5333, F1=0.5249 | Val Loss=1.5134, Acc=0.4200, F1=0.3414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:05:58,457] Trial 13 finished with value: 0.48 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00011531865648562694, 'weight_decay': 0.00011146634654798883}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=1.1888, Acc=0.5033, F1=0.5054 | Val Loss=1.8120, Acc=0.3800, F1=0.3626\n",
      "Early stopping\n",
      "\n",
      "[trial 14] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9327, Acc=0.2533, F1=0.2471 | Val Loss=1.6145, Acc=0.3000, F1=0.2688\n",
      "Epoch 02: Train Loss=1.6483, Acc=0.2767, F1=0.2733 | Val Loss=1.6573, Acc=0.2800, F1=0.2006\n",
      "Epoch 03: Train Loss=1.5835, Acc=0.3033, F1=0.3052 | Val Loss=1.6897, Acc=0.2600, F1=0.1319\n",
      "Epoch 04: Train Loss=1.5624, Acc=0.3067, F1=0.3027 | Val Loss=1.6651, Acc=0.2800, F1=0.1758\n",
      "Epoch 05: Train Loss=1.5558, Acc=0.3333, F1=0.3279 | Val Loss=1.5167, Acc=0.3600, F1=0.2503\n",
      "Epoch 06: Train Loss=1.5268, Acc=0.3133, F1=0.3028 | Val Loss=1.6608, Acc=0.2800, F1=0.2470\n",
      "Epoch 07: Train Loss=1.5542, Acc=0.3167, F1=0.3039 | Val Loss=1.4796, Acc=0.4400, F1=0.3642\n",
      "Epoch 08: Train Loss=1.4804, Acc=0.3633, F1=0.3586 | Val Loss=1.4935, Acc=0.4000, F1=0.3453\n",
      "Epoch 09: Train Loss=1.4590, Acc=0.3633, F1=0.3488 | Val Loss=1.4912, Acc=0.4600, F1=0.3858\n",
      "Epoch 10: Train Loss=1.4613, Acc=0.3533, F1=0.3504 | Val Loss=1.5056, Acc=0.3600, F1=0.2888\n",
      "Epoch 11: Train Loss=1.4363, Acc=0.3833, F1=0.3749 | Val Loss=1.4740, Acc=0.4400, F1=0.4148\n",
      "Epoch 12: Train Loss=1.4260, Acc=0.3800, F1=0.3755 | Val Loss=1.4478, Acc=0.4400, F1=0.3357\n",
      "Epoch 13: Train Loss=1.3874, Acc=0.4233, F1=0.4144 | Val Loss=1.4994, Acc=0.4000, F1=0.3314\n",
      "Epoch 14: Train Loss=1.3710, Acc=0.3833, F1=0.3783 | Val Loss=1.4184, Acc=0.3800, F1=0.3044\n",
      "Epoch 15: Train Loss=1.3829, Acc=0.4300, F1=0.4228 | Val Loss=1.3594, Acc=0.4600, F1=0.4094\n",
      "Epoch 16: Train Loss=1.3370, Acc=0.4300, F1=0.4237 | Val Loss=1.3805, Acc=0.4000, F1=0.3147\n",
      "Epoch 17: Train Loss=1.3564, Acc=0.4100, F1=0.3905 | Val Loss=1.4432, Acc=0.4000, F1=0.3271\n",
      "Epoch 18: Train Loss=1.3256, Acc=0.4600, F1=0.4447 | Val Loss=1.6850, Acc=0.3400, F1=0.3390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:07:28,156] Trial 14 finished with value: 0.46 and parameters: {'nhead': 8, 'num_layers': 2, 'lr': 0.0002583605014014802, 'weight_decay': 0.00048054815675422816}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=1.3140, Acc=0.4567, F1=0.4429 | Val Loss=1.3803, Acc=0.4200, F1=0.3647\n",
      "Early stopping\n",
      "\n",
      "[trial 15] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9721, Acc=0.2300, F1=0.2290 | Val Loss=1.6849, Acc=0.2200, F1=0.1157\n",
      "Epoch 02: Train Loss=1.6245, Acc=0.2233, F1=0.2135 | Val Loss=1.7991, Acc=0.1200, F1=0.0708\n",
      "Epoch 03: Train Loss=1.6030, Acc=0.2633, F1=0.2580 | Val Loss=1.7383, Acc=0.3200, F1=0.2242\n",
      "Epoch 04: Train Loss=1.6138, Acc=0.3033, F1=0.2968 | Val Loss=1.6062, Acc=0.2600, F1=0.1324\n",
      "Epoch 05: Train Loss=1.5968, Acc=0.3000, F1=0.2937 | Val Loss=1.7492, Acc=0.2800, F1=0.1669\n",
      "Epoch 06: Train Loss=1.5200, Acc=0.3000, F1=0.2830 | Val Loss=1.6607, Acc=0.2200, F1=0.1402\n",
      "Epoch 07: Train Loss=1.5758, Acc=0.2767, F1=0.2697 | Val Loss=1.5712, Acc=0.3000, F1=0.1500\n",
      "Epoch 08: Train Loss=1.5854, Acc=0.3000, F1=0.2894 | Val Loss=1.7386, Acc=0.2600, F1=0.1317\n",
      "Epoch 09: Train Loss=1.5332, Acc=0.3067, F1=0.2992 | Val Loss=1.6121, Acc=0.1800, F1=0.1028\n",
      "Epoch 10: Train Loss=1.5092, Acc=0.3333, F1=0.2917 | Val Loss=1.7427, Acc=0.2600, F1=0.1317\n",
      "Epoch 11: Train Loss=1.5397, Acc=0.2667, F1=0.2536 | Val Loss=1.6527, Acc=0.3200, F1=0.1997\n",
      "Epoch 12: Train Loss=1.5334, Acc=0.2600, F1=0.2435 | Val Loss=1.5859, Acc=0.2800, F1=0.1412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:09:18,157] Trial 15 finished with value: 0.32 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00022545502715832472, 'weight_decay': 0.0002829842260424557}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.5063, Acc=0.3000, F1=0.2713 | Val Loss=1.8033, Acc=0.2600, F1=0.1324\n",
      "Early stopping\n",
      "\n",
      "[trial 16] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.1053, Acc=0.2533, F1=0.2553 | Val Loss=1.6822, Acc=0.2600, F1=0.0825\n",
      "Epoch 02: Train Loss=1.6430, Acc=0.2633, F1=0.2406 | Val Loss=1.7006, Acc=0.2000, F1=0.1070\n",
      "Epoch 03: Train Loss=1.5703, Acc=0.3100, F1=0.3066 | Val Loss=1.7781, Acc=0.3800, F1=0.3213\n",
      "Epoch 04: Train Loss=1.6119, Acc=0.3000, F1=0.2889 | Val Loss=1.5772, Acc=0.3000, F1=0.1500\n",
      "Epoch 05: Train Loss=1.5467, Acc=0.2867, F1=0.2805 | Val Loss=1.6275, Acc=0.2600, F1=0.2048\n",
      "Epoch 06: Train Loss=1.5615, Acc=0.3100, F1=0.2969 | Val Loss=1.5281, Acc=0.3400, F1=0.1842\n",
      "Epoch 07: Train Loss=1.5663, Acc=0.3100, F1=0.2977 | Val Loss=1.6873, Acc=0.2000, F1=0.1340\n",
      "Epoch 08: Train Loss=1.5363, Acc=0.3333, F1=0.2997 | Val Loss=1.5824, Acc=0.2600, F1=0.1398\n",
      "Epoch 09: Train Loss=1.4849, Acc=0.2767, F1=0.2738 | Val Loss=1.5556, Acc=0.3600, F1=0.2706\n",
      "Epoch 10: Train Loss=1.5583, Acc=0.3533, F1=0.3198 | Val Loss=1.7698, Acc=0.3000, F1=0.2060\n",
      "Epoch 11: Train Loss=1.5526, Acc=0.2867, F1=0.2757 | Val Loss=1.5694, Acc=0.2000, F1=0.1429\n",
      "Epoch 12: Train Loss=1.5062, Acc=0.3433, F1=0.2997 | Val Loss=1.5104, Acc=0.3200, F1=0.2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:11:08,026] Trial 16 finished with value: 0.38 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.000163933989301113, 'weight_decay': 4.565594045445848e-05}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.4841, Acc=0.3200, F1=0.3149 | Val Loss=1.5499, Acc=0.2600, F1=0.2074\n",
      "Early stopping\n",
      "\n",
      "[trial 17] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.2229, Acc=0.2333, F1=0.2122 | Val Loss=1.7028, Acc=0.2200, F1=0.1146\n",
      "Epoch 02: Train Loss=1.6427, Acc=0.3133, F1=0.2974 | Val Loss=1.8363, Acc=0.2000, F1=0.1217\n",
      "Epoch 03: Train Loss=1.6772, Acc=0.3067, F1=0.3047 | Val Loss=1.8283, Acc=0.1800, F1=0.0957\n",
      "Epoch 04: Train Loss=1.6020, Acc=0.2833, F1=0.2789 | Val Loss=2.0782, Acc=0.3000, F1=0.2191\n",
      "Epoch 05: Train Loss=1.6103, Acc=0.2667, F1=0.2642 | Val Loss=1.5268, Acc=0.4400, F1=0.3346\n",
      "Epoch 06: Train Loss=1.5714, Acc=0.3467, F1=0.3172 | Val Loss=1.4600, Acc=0.3800, F1=0.3300\n",
      "Epoch 07: Train Loss=1.5456, Acc=0.3100, F1=0.3039 | Val Loss=1.7023, Acc=0.2800, F1=0.1431\n",
      "Epoch 08: Train Loss=1.5956, Acc=0.2600, F1=0.2464 | Val Loss=1.6412, Acc=0.3200, F1=0.2751\n",
      "Epoch 09: Train Loss=1.5224, Acc=0.2933, F1=0.2782 | Val Loss=1.5802, Acc=0.2400, F1=0.1427\n",
      "Epoch 10: Train Loss=1.4650, Acc=0.3167, F1=0.3045 | Val Loss=1.5985, Acc=0.2400, F1=0.1998\n",
      "Epoch 11: Train Loss=1.4430, Acc=0.3533, F1=0.3312 | Val Loss=1.4873, Acc=0.3800, F1=0.3207\n",
      "Epoch 12: Train Loss=1.3895, Acc=0.3633, F1=0.3485 | Val Loss=1.5691, Acc=0.2400, F1=0.2349\n",
      "Epoch 13: Train Loss=1.4168, Acc=0.3900, F1=0.3737 | Val Loss=1.6167, Acc=0.4000, F1=0.3431\n",
      "Epoch 14: Train Loss=1.3564, Acc=0.4400, F1=0.4329 | Val Loss=1.9654, Acc=0.3200, F1=0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:12:18,672] Trial 17 finished with value: 0.44 and parameters: {'nhead': 8, 'num_layers': 2, 'lr': 0.0004424521231538716, 'weight_decay': 5.833343330594983e-05}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=1.3479, Acc=0.4533, F1=0.4462 | Val Loss=1.6860, Acc=0.3000, F1=0.2094\n",
      "Early stopping\n",
      "\n",
      "[trial 18] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.6368, Acc=0.2167, F1=0.2186 | Val Loss=2.0416, Acc=0.2600, F1=0.0825\n",
      "Epoch 02: Train Loss=1.9753, Acc=0.1567, F1=0.1437 | Val Loss=1.6767, Acc=0.2200, F1=0.0721\n",
      "Epoch 03: Train Loss=1.8095, Acc=0.1933, F1=0.1853 | Val Loss=1.7330, Acc=0.2600, F1=0.0825\n",
      "Epoch 04: Train Loss=1.6931, Acc=0.1767, F1=0.1623 | Val Loss=1.6111, Acc=0.2600, F1=0.0825\n",
      "Epoch 05: Train Loss=1.7792, Acc=0.1900, F1=0.1762 | Val Loss=1.5610, Acc=0.2600, F1=0.0825\n",
      "Epoch 06: Train Loss=1.6538, Acc=0.1900, F1=0.1647 | Val Loss=1.6478, Acc=0.1000, F1=0.0364\n",
      "Epoch 07: Train Loss=1.6260, Acc=0.1300, F1=0.1202 | Val Loss=1.6122, Acc=0.1600, F1=0.0552\n",
      "Epoch 08: Train Loss=1.6211, Acc=0.2100, F1=0.1984 | Val Loss=1.6198, Acc=0.1600, F1=0.0552\n",
      "Epoch 09: Train Loss=1.6193, Acc=0.1733, F1=0.1619 | Val Loss=1.6006, Acc=0.2600, F1=0.0825\n",
      "Epoch 10: Train Loss=1.6141, Acc=0.2033, F1=0.1272 | Val Loss=1.6595, Acc=0.1000, F1=0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:13:31,478] Trial 18 finished with value: 0.26 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.0037816515063329717, 'weight_decay': 0.000980148758283862}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=1.6212, Acc=0.1767, F1=0.1268 | Val Loss=1.6121, Acc=0.1600, F1=0.0552\n",
      "Early stopping\n",
      "\n",
      "[trial 19] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.1331, Acc=0.2067, F1=0.1900 | Val Loss=1.8230, Acc=0.1000, F1=0.0364\n",
      "Epoch 02: Train Loss=1.8129, Acc=0.1600, F1=0.1596 | Val Loss=1.6356, Acc=0.2600, F1=0.0825\n",
      "Epoch 03: Train Loss=1.6935, Acc=0.2000, F1=0.1965 | Val Loss=1.6702, Acc=0.2600, F1=0.0825\n",
      "Epoch 04: Train Loss=1.7344, Acc=0.2200, F1=0.2068 | Val Loss=1.9772, Acc=0.1600, F1=0.0552\n",
      "Epoch 05: Train Loss=1.7051, Acc=0.1933, F1=0.1795 | Val Loss=1.7355, Acc=0.2600, F1=0.0825\n",
      "Epoch 06: Train Loss=1.7201, Acc=0.2033, F1=0.1903 | Val Loss=2.2702, Acc=0.2400, F1=0.1952\n",
      "Epoch 07: Train Loss=1.7109, Acc=0.2167, F1=0.1820 | Val Loss=1.8304, Acc=0.1600, F1=0.0552\n",
      "Epoch 08: Train Loss=1.7056, Acc=0.1467, F1=0.1460 | Val Loss=1.6737, Acc=0.1000, F1=0.0364\n",
      "Epoch 09: Train Loss=1.6909, Acc=0.1400, F1=0.1300 | Val Loss=1.7089, Acc=0.2200, F1=0.0721\n",
      "Epoch 10: Train Loss=1.7162, Acc=0.2167, F1=0.1971 | Val Loss=1.6075, Acc=0.2200, F1=0.0721\n",
      "Epoch 11: Train Loss=1.6795, Acc=0.2133, F1=0.1817 | Val Loss=1.5836, Acc=0.2600, F1=0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:15:13,100] Trial 19 finished with value: 0.26 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00041359362575230096, 'weight_decay': 6.916807717235078e-05}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=1.6561, Acc=0.1700, F1=0.1599 | Val Loss=1.8174, Acc=0.1000, F1=0.0364\n",
      "Early stopping\n",
      "\n",
      "[trial 20] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.1366, Acc=0.2000, F1=0.1983 | Val Loss=1.6484, Acc=0.3000, F1=0.1496\n",
      "Epoch 02: Train Loss=1.5986, Acc=0.2867, F1=0.2807 | Val Loss=1.5430, Acc=0.2200, F1=0.1333\n",
      "Epoch 03: Train Loss=1.6057, Acc=0.2933, F1=0.2838 | Val Loss=1.6775, Acc=0.3800, F1=0.2713\n",
      "Epoch 04: Train Loss=1.5857, Acc=0.3233, F1=0.2873 | Val Loss=1.5211, Acc=0.4200, F1=0.4012\n",
      "Epoch 05: Train Loss=1.5536, Acc=0.2933, F1=0.2844 | Val Loss=1.5888, Acc=0.2600, F1=0.1697\n",
      "Epoch 06: Train Loss=1.5235, Acc=0.3467, F1=0.3312 | Val Loss=1.5446, Acc=0.3600, F1=0.2766\n",
      "Epoch 07: Train Loss=1.5473, Acc=0.3100, F1=0.2949 | Val Loss=1.6808, Acc=0.3200, F1=0.2360\n",
      "Epoch 08: Train Loss=1.5402, Acc=0.3400, F1=0.3251 | Val Loss=1.7451, Acc=0.2600, F1=0.1317\n",
      "Epoch 09: Train Loss=1.4865, Acc=0.3367, F1=0.3250 | Val Loss=1.6968, Acc=0.2600, F1=0.1586\n",
      "Epoch 10: Train Loss=1.4869, Acc=0.3633, F1=0.3357 | Val Loss=1.4942, Acc=0.3800, F1=0.3144\n",
      "Epoch 11: Train Loss=1.4787, Acc=0.3600, F1=0.3515 | Val Loss=1.5590, Acc=0.3200, F1=0.2663\n",
      "Epoch 12: Train Loss=1.4398, Acc=0.3333, F1=0.3218 | Val Loss=1.5423, Acc=0.3200, F1=0.2385\n",
      "Epoch 13: Train Loss=1.4216, Acc=0.3967, F1=0.3828 | Val Loss=1.6060, Acc=0.1800, F1=0.1229\n",
      "Epoch 14: Train Loss=1.4572, Acc=0.3733, F1=0.3694 | Val Loss=1.4523, Acc=0.4600, F1=0.3476\n",
      "Epoch 15: Train Loss=1.4521, Acc=0.3800, F1=0.3756 | Val Loss=1.4116, Acc=0.4200, F1=0.3467\n",
      "Epoch 16: Train Loss=1.3965, Acc=0.4133, F1=0.4051 | Val Loss=1.4775, Acc=0.4000, F1=0.3254\n",
      "Epoch 17: Train Loss=1.3526, Acc=0.4100, F1=0.3915 | Val Loss=1.5082, Acc=0.4200, F1=0.3910\n",
      "Epoch 18: Train Loss=1.3668, Acc=0.4333, F1=0.4118 | Val Loss=1.4746, Acc=0.3800, F1=0.3315\n",
      "Epoch 19: Train Loss=1.3158, Acc=0.4133, F1=0.4119 | Val Loss=1.4713, Acc=0.4000, F1=0.3488\n",
      "Epoch 20: Train Loss=1.3046, Acc=0.4300, F1=0.4261 | Val Loss=1.6195, Acc=0.4200, F1=0.3719\n",
      "Epoch 21: Train Loss=1.2746, Acc=0.4367, F1=0.4259 | Val Loss=1.4956, Acc=0.4600, F1=0.4013\n",
      "Epoch 22: Train Loss=1.2689, Acc=0.4833, F1=0.4791 | Val Loss=1.4389, Acc=0.4200, F1=0.3503\n",
      "Epoch 23: Train Loss=1.2416, Acc=0.4933, F1=0.4869 | Val Loss=1.6275, Acc=0.3400, F1=0.3241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:17:51,572] Trial 20 finished with value: 0.46 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.00013953416755976746, 'weight_decay': 0.00032249274539476985}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=1.1852, Acc=0.4833, F1=0.4746 | Val Loss=1.6402, Acc=0.3600, F1=0.3411\n",
      "Early stopping\n",
      "\n",
      "[trial 21] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9698, Acc=0.2533, F1=0.2559 | Val Loss=1.5465, Acc=0.2400, F1=0.2030\n",
      "Epoch 02: Train Loss=1.6292, Acc=0.3033, F1=0.2979 | Val Loss=1.6419, Acc=0.2600, F1=0.0825\n",
      "Epoch 03: Train Loss=1.6032, Acc=0.2767, F1=0.2608 | Val Loss=1.5997, Acc=0.3000, F1=0.1850\n",
      "Epoch 04: Train Loss=1.5642, Acc=0.2900, F1=0.2697 | Val Loss=1.7581, Acc=0.1800, F1=0.1017\n",
      "Epoch 05: Train Loss=1.5898, Acc=0.3400, F1=0.3358 | Val Loss=1.5558, Acc=0.2000, F1=0.1238\n",
      "Epoch 06: Train Loss=1.5386, Acc=0.2967, F1=0.2720 | Val Loss=1.5212, Acc=0.2600, F1=0.1815\n",
      "Epoch 07: Train Loss=1.5097, Acc=0.3300, F1=0.3234 | Val Loss=1.5245, Acc=0.4000, F1=0.3742\n",
      "Epoch 08: Train Loss=1.4843, Acc=0.3367, F1=0.3299 | Val Loss=1.5798, Acc=0.3400, F1=0.1842\n",
      "Epoch 09: Train Loss=1.5134, Acc=0.3333, F1=0.3140 | Val Loss=1.6022, Acc=0.3000, F1=0.1972\n",
      "Epoch 10: Train Loss=1.4658, Acc=0.4000, F1=0.3936 | Val Loss=1.5218, Acc=0.3400, F1=0.3118\n",
      "Epoch 11: Train Loss=1.4131, Acc=0.3333, F1=0.3281 | Val Loss=1.4594, Acc=0.4600, F1=0.3691\n",
      "Epoch 12: Train Loss=1.3859, Acc=0.4233, F1=0.4032 | Val Loss=1.5179, Acc=0.4800, F1=0.4311\n",
      "Epoch 13: Train Loss=1.3819, Acc=0.4367, F1=0.4072 | Val Loss=1.4852, Acc=0.4600, F1=0.3175\n",
      "Epoch 14: Train Loss=1.3315, Acc=0.3933, F1=0.3802 | Val Loss=1.6736, Acc=0.5000, F1=0.3677\n",
      "Epoch 15: Train Loss=1.4102, Acc=0.4367, F1=0.4218 | Val Loss=1.6594, Acc=0.3400, F1=0.2532\n",
      "Epoch 16: Train Loss=1.3331, Acc=0.4167, F1=0.3967 | Val Loss=1.4407, Acc=0.3200, F1=0.2810\n",
      "Epoch 17: Train Loss=1.3013, Acc=0.4633, F1=0.4527 | Val Loss=1.5446, Acc=0.3400, F1=0.2808\n",
      "Epoch 18: Train Loss=1.2902, Acc=0.4667, F1=0.4355 | Val Loss=1.5180, Acc=0.3800, F1=0.2716\n",
      "Epoch 19: Train Loss=1.2159, Acc=0.5033, F1=0.4928 | Val Loss=1.6978, Acc=0.4200, F1=0.3612\n",
      "Epoch 20: Train Loss=1.1426, Acc=0.5367, F1=0.5347 | Val Loss=1.8817, Acc=0.4000, F1=0.3124\n",
      "Epoch 21: Train Loss=1.0874, Acc=0.5667, F1=0.5636 | Val Loss=1.8087, Acc=0.4200, F1=0.3421\n",
      "Epoch 22: Train Loss=0.9857, Acc=0.6200, F1=0.6173 | Val Loss=1.7354, Acc=0.4000, F1=0.3259\n",
      "Epoch 23: Train Loss=0.9085, Acc=0.6667, F1=0.6661 | Val Loss=1.9495, Acc=0.3600, F1=0.3620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:21:14,740] Trial 21 finished with value: 0.5 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00010435233450894518, 'weight_decay': 0.00010682922545241557}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=0.8143, Acc=0.6767, F1=0.6736 | Val Loss=2.3005, Acc=0.3600, F1=0.2833\n",
      "Early stopping\n",
      "\n",
      "[trial 22] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.0660, Acc=0.2567, F1=0.2515 | Val Loss=1.7771, Acc=0.2000, F1=0.1082\n",
      "Epoch 02: Train Loss=1.6643, Acc=0.2800, F1=0.2754 | Val Loss=1.7753, Acc=0.1600, F1=0.0604\n",
      "Epoch 03: Train Loss=1.6635, Acc=0.2600, F1=0.2548 | Val Loss=1.6257, Acc=0.2800, F1=0.1401\n",
      "Epoch 04: Train Loss=1.5945, Acc=0.2767, F1=0.2562 | Val Loss=1.5552, Acc=0.3200, F1=0.2237\n",
      "Epoch 05: Train Loss=1.5582, Acc=0.2867, F1=0.2799 | Val Loss=1.5830, Acc=0.2200, F1=0.1333\n",
      "Epoch 06: Train Loss=1.5335, Acc=0.3033, F1=0.2811 | Val Loss=1.7086, Acc=0.3400, F1=0.1904\n",
      "Epoch 07: Train Loss=1.5098, Acc=0.3567, F1=0.3512 | Val Loss=1.8941, Acc=0.2400, F1=0.1251\n",
      "Epoch 08: Train Loss=1.5344, Acc=0.3333, F1=0.3165 | Val Loss=1.6417, Acc=0.3400, F1=0.2357\n",
      "Epoch 09: Train Loss=1.5509, Acc=0.3300, F1=0.3104 | Val Loss=1.5390, Acc=0.2000, F1=0.1463\n",
      "Epoch 10: Train Loss=1.5194, Acc=0.2967, F1=0.2783 | Val Loss=1.5234, Acc=0.3000, F1=0.1514\n",
      "Epoch 11: Train Loss=1.4627, Acc=0.3367, F1=0.3306 | Val Loss=1.7709, Acc=0.1600, F1=0.1102\n",
      "Epoch 12: Train Loss=1.4616, Acc=0.3867, F1=0.3581 | Val Loss=1.5913, Acc=0.1800, F1=0.0847\n",
      "Epoch 13: Train Loss=1.4869, Acc=0.3200, F1=0.3128 | Val Loss=1.5004, Acc=0.3400, F1=0.2465\n",
      "Epoch 14: Train Loss=1.5221, Acc=0.2967, F1=0.2985 | Val Loss=1.5085, Acc=0.3000, F1=0.2259\n",
      "Epoch 15: Train Loss=1.4663, Acc=0.3600, F1=0.3484 | Val Loss=1.7774, Acc=0.3000, F1=0.2346\n",
      "Epoch 16: Train Loss=1.4212, Acc=0.3333, F1=0.3277 | Val Loss=1.5146, Acc=0.4400, F1=0.3863\n",
      "Epoch 17: Train Loss=1.4142, Acc=0.4300, F1=0.4199 | Val Loss=1.5207, Acc=0.4400, F1=0.3925\n",
      "Epoch 18: Train Loss=1.5399, Acc=0.3400, F1=0.3050 | Val Loss=1.9094, Acc=0.1400, F1=0.1112\n",
      "Epoch 19: Train Loss=1.4589, Acc=0.3567, F1=0.3387 | Val Loss=1.7084, Acc=0.3000, F1=0.2198\n",
      "Epoch 20: Train Loss=1.4247, Acc=0.3400, F1=0.3326 | Val Loss=1.5168, Acc=0.3800, F1=0.2900\n",
      "Epoch 21: Train Loss=1.4006, Acc=0.3767, F1=0.3602 | Val Loss=1.5735, Acc=0.4400, F1=0.3391\n",
      "Epoch 22: Train Loss=1.3714, Acc=0.4200, F1=0.3813 | Val Loss=1.6167, Acc=0.3400, F1=0.2200\n",
      "Epoch 23: Train Loss=1.3724, Acc=0.4367, F1=0.4275 | Val Loss=1.5500, Acc=0.3400, F1=0.2247\n",
      "Epoch 24: Train Loss=1.3271, Acc=0.4433, F1=0.4242 | Val Loss=1.5813, Acc=0.3800, F1=0.3032\n",
      "Epoch 25: Train Loss=1.2953, Acc=0.4533, F1=0.4464 | Val Loss=1.7153, Acc=0.4000, F1=0.2821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:24:54,446] Trial 22 finished with value: 0.44 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00017320214282304762, 'weight_decay': 9.828969736656175e-05}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=1.2716, Acc=0.4867, F1=0.4333 | Val Loss=1.6485, Acc=0.2400, F1=0.2300\n",
      "Early stopping\n",
      "\n",
      "[trial 23] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.8539, Acc=0.2667, F1=0.2646 | Val Loss=1.7865, Acc=0.1600, F1=0.0552\n",
      "Epoch 02: Train Loss=1.6696, Acc=0.2667, F1=0.2586 | Val Loss=1.7139, Acc=0.2000, F1=0.1670\n",
      "Epoch 03: Train Loss=1.5914, Acc=0.2867, F1=0.2844 | Val Loss=1.5095, Acc=0.3200, F1=0.2370\n",
      "Epoch 04: Train Loss=1.5796, Acc=0.3233, F1=0.3170 | Val Loss=1.6787, Acc=0.2600, F1=0.1319\n",
      "Epoch 05: Train Loss=1.5693, Acc=0.2733, F1=0.2585 | Val Loss=1.5371, Acc=0.3600, F1=0.2667\n",
      "Epoch 06: Train Loss=1.5430, Acc=0.3433, F1=0.3282 | Val Loss=1.6534, Acc=0.2000, F1=0.1669\n",
      "Epoch 07: Train Loss=1.5008, Acc=0.3733, F1=0.3658 | Val Loss=1.5487, Acc=0.3200, F1=0.2481\n",
      "Epoch 08: Train Loss=1.4962, Acc=0.3400, F1=0.3256 | Val Loss=1.5275, Acc=0.4000, F1=0.2799\n",
      "Epoch 09: Train Loss=1.4715, Acc=0.3233, F1=0.3177 | Val Loss=1.5124, Acc=0.3200, F1=0.1997\n",
      "Epoch 10: Train Loss=1.4917, Acc=0.3233, F1=0.3162 | Val Loss=1.5662, Acc=0.3000, F1=0.2310\n",
      "Epoch 11: Train Loss=1.4720, Acc=0.3767, F1=0.3605 | Val Loss=1.6060, Acc=0.3000, F1=0.1781\n",
      "Epoch 12: Train Loss=1.4748, Acc=0.3500, F1=0.3271 | Val Loss=1.5888, Acc=0.3800, F1=0.2530\n",
      "Epoch 13: Train Loss=1.4624, Acc=0.3600, F1=0.3394 | Val Loss=1.5518, Acc=0.3400, F1=0.2506\n",
      "Epoch 14: Train Loss=1.4141, Acc=0.3633, F1=0.3316 | Val Loss=1.5671, Acc=0.3000, F1=0.2293\n",
      "Epoch 15: Train Loss=1.4233, Acc=0.4000, F1=0.3871 | Val Loss=1.6191, Acc=0.3000, F1=0.1940\n",
      "Epoch 16: Train Loss=1.3788, Acc=0.4167, F1=0.3894 | Val Loss=1.7170, Acc=0.1800, F1=0.1096\n",
      "Epoch 17: Train Loss=1.3992, Acc=0.4000, F1=0.3815 | Val Loss=1.6103, Acc=0.3400, F1=0.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:27:26,883] Trial 23 finished with value: 0.4 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00010052411549148645, 'weight_decay': 0.0002144612266342391}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=1.3595, Acc=0.4300, F1=0.4232 | Val Loss=1.7003, Acc=0.3800, F1=0.3025\n",
      "Early stopping\n",
      "\n",
      "[trial 24] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.0502, Acc=0.2633, F1=0.2566 | Val Loss=1.8525, Acc=0.2200, F1=0.0721\n",
      "Epoch 02: Train Loss=1.7591, Acc=0.1767, F1=0.1617 | Val Loss=1.8231, Acc=0.1600, F1=0.0552\n",
      "Epoch 03: Train Loss=1.7889, Acc=0.1900, F1=0.1594 | Val Loss=1.7822, Acc=0.1600, F1=0.0552\n",
      "Epoch 04: Train Loss=1.9802, Acc=0.2300, F1=0.2249 | Val Loss=1.7855, Acc=0.1600, F1=0.0552\n",
      "Epoch 05: Train Loss=1.7279, Acc=0.1700, F1=0.1665 | Val Loss=1.7949, Acc=0.1600, F1=0.0552\n",
      "Epoch 06: Train Loss=1.6997, Acc=0.2133, F1=0.1806 | Val Loss=1.6077, Acc=0.2200, F1=0.0721\n",
      "Epoch 07: Train Loss=1.6882, Acc=0.1867, F1=0.1788 | Val Loss=1.5995, Acc=0.2200, F1=0.0721\n",
      "Epoch 08: Train Loss=1.6725, Acc=0.2067, F1=0.1929 | Val Loss=1.7153, Acc=0.2600, F1=0.0825\n",
      "Epoch 09: Train Loss=1.6670, Acc=0.1900, F1=0.1695 | Val Loss=1.7249, Acc=0.1000, F1=0.0364\n",
      "Epoch 10: Train Loss=1.6932, Acc=0.2300, F1=0.1847 | Val Loss=1.6067, Acc=0.2600, F1=0.0825\n",
      "Epoch 11: Train Loss=1.7196, Acc=0.1867, F1=0.1767 | Val Loss=1.5967, Acc=0.2600, F1=0.0825\n",
      "Epoch 12: Train Loss=1.6603, Acc=0.1767, F1=0.1588 | Val Loss=1.6631, Acc=0.2600, F1=0.0825\n",
      "Epoch 13: Train Loss=1.6600, Acc=0.1700, F1=0.1483 | Val Loss=1.6041, Acc=0.2200, F1=0.0721\n",
      "Epoch 14: Train Loss=1.6492, Acc=0.2133, F1=0.1814 | Val Loss=1.6820, Acc=0.1600, F1=0.0552\n",
      "Epoch 15: Train Loss=1.6601, Acc=0.1633, F1=0.1571 | Val Loss=1.6480, Acc=0.2600, F1=0.0825\n",
      "Epoch 16: Train Loss=1.6632, Acc=0.2000, F1=0.1945 | Val Loss=1.6896, Acc=0.1600, F1=0.0552\n",
      "Epoch 17: Train Loss=1.6852, Acc=0.2033, F1=0.1750 | Val Loss=1.7506, Acc=0.2200, F1=0.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:29:59,341] Trial 24 finished with value: 0.26 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00032367871286896876, 'weight_decay': 3.389551727280967e-05}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=1.7013, Acc=0.1967, F1=0.1724 | Val Loss=1.5564, Acc=0.2600, F1=0.0825\n",
      "Early stopping\n",
      "\n",
      "[trial 25] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.0186, Acc=0.2433, F1=0.2418 | Val Loss=1.5813, Acc=0.3000, F1=0.1500\n",
      "Epoch 02: Train Loss=1.7343, Acc=0.2767, F1=0.2674 | Val Loss=1.5851, Acc=0.2800, F1=0.1524\n",
      "Epoch 03: Train Loss=1.5934, Acc=0.3367, F1=0.3208 | Val Loss=1.5867, Acc=0.2800, F1=0.1855\n",
      "Epoch 04: Train Loss=1.5721, Acc=0.2833, F1=0.2769 | Val Loss=1.7419, Acc=0.3000, F1=0.1949\n",
      "Epoch 05: Train Loss=1.6196, Acc=0.3167, F1=0.2955 | Val Loss=1.9813, Acc=0.1600, F1=0.0909\n",
      "Epoch 06: Train Loss=1.4827, Acc=0.3800, F1=0.3525 | Val Loss=1.5084, Acc=0.4000, F1=0.2718\n",
      "Epoch 07: Train Loss=1.4959, Acc=0.3033, F1=0.2917 | Val Loss=1.5841, Acc=0.2200, F1=0.1515\n",
      "Epoch 08: Train Loss=1.4754, Acc=0.3467, F1=0.3424 | Val Loss=1.7111, Acc=0.3000, F1=0.2300\n",
      "Epoch 09: Train Loss=1.4813, Acc=0.3833, F1=0.3655 | Val Loss=1.6727, Acc=0.2600, F1=0.1683\n",
      "Epoch 10: Train Loss=1.4090, Acc=0.4000, F1=0.3790 | Val Loss=1.5487, Acc=0.3400, F1=0.2522\n",
      "Epoch 11: Train Loss=1.4024, Acc=0.4100, F1=0.4059 | Val Loss=1.3810, Acc=0.3800, F1=0.3512\n",
      "Epoch 12: Train Loss=1.3188, Acc=0.4400, F1=0.4366 | Val Loss=1.5824, Acc=0.4200, F1=0.2845\n",
      "Epoch 13: Train Loss=1.3001, Acc=0.4400, F1=0.4293 | Val Loss=1.6626, Acc=0.4600, F1=0.3456\n",
      "Epoch 14: Train Loss=1.1564, Acc=0.5233, F1=0.5089 | Val Loss=2.0621, Acc=0.3400, F1=0.2586\n",
      "Epoch 15: Train Loss=1.2399, Acc=0.5467, F1=0.5428 | Val Loss=1.3911, Acc=0.3600, F1=0.2898\n",
      "Epoch 16: Train Loss=1.1097, Acc=0.5767, F1=0.5621 | Val Loss=1.8173, Acc=0.3000, F1=0.2213\n",
      "Epoch 17: Train Loss=0.9945, Acc=0.6167, F1=0.6153 | Val Loss=2.1021, Acc=0.3000, F1=0.2244\n",
      "Epoch 18: Train Loss=0.8674, Acc=0.7000, F1=0.7005 | Val Loss=1.9817, Acc=0.3600, F1=0.3144\n",
      "Epoch 19: Train Loss=0.7334, Acc=0.7400, F1=0.7377 | Val Loss=2.4535, Acc=0.3400, F1=0.3076\n",
      "Epoch 20: Train Loss=0.7629, Acc=0.7233, F1=0.7243 | Val Loss=2.3454, Acc=0.4200, F1=0.3611\n",
      "Epoch 21: Train Loss=0.7491, Acc=0.7967, F1=0.7965 | Val Loss=2.4391, Acc=0.3400, F1=0.3059\n",
      "Epoch 22: Train Loss=0.5633, Acc=0.8300, F1=0.8321 | Val Loss=4.2612, Acc=0.3000, F1=0.2879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:32:31,438] Trial 25 finished with value: 0.46 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.00020301680804382034, 'weight_decay': 1.3919323771901774e-05}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss=0.4960, Acc=0.8500, F1=0.8493 | Val Loss=3.4879, Acc=0.3600, F1=0.3319\n",
      "Early stopping\n",
      "\n",
      "[trial 26] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9445, Acc=0.2433, F1=0.2376 | Val Loss=2.1825, Acc=0.2200, F1=0.1227\n",
      "Epoch 02: Train Loss=1.7524, Acc=0.2833, F1=0.2744 | Val Loss=1.7764, Acc=0.2600, F1=0.0825\n",
      "Epoch 03: Train Loss=1.6883, Acc=0.2600, F1=0.2483 | Val Loss=1.8591, Acc=0.2600, F1=0.1317\n",
      "Epoch 04: Train Loss=1.5893, Acc=0.2333, F1=0.2235 | Val Loss=1.8032, Acc=0.1400, F1=0.0774\n",
      "Epoch 05: Train Loss=1.5878, Acc=0.2267, F1=0.2204 | Val Loss=1.9825, Acc=0.1600, F1=0.0922\n",
      "Epoch 06: Train Loss=1.5968, Acc=0.3233, F1=0.3063 | Val Loss=1.5973, Acc=0.2400, F1=0.1340\n",
      "Epoch 07: Train Loss=1.5453, Acc=0.3000, F1=0.2896 | Val Loss=1.5888, Acc=0.3600, F1=0.2473\n",
      "Epoch 08: Train Loss=1.5636, Acc=0.3000, F1=0.2868 | Val Loss=1.5855, Acc=0.3000, F1=0.2016\n",
      "Epoch 09: Train Loss=1.5243, Acc=0.3233, F1=0.3118 | Val Loss=1.6384, Acc=0.4200, F1=0.2882\n",
      "Epoch 10: Train Loss=1.5106, Acc=0.3633, F1=0.3501 | Val Loss=1.6008, Acc=0.2200, F1=0.1767\n",
      "Epoch 11: Train Loss=1.5199, Acc=0.3333, F1=0.3178 | Val Loss=1.6474, Acc=0.3200, F1=0.2327\n",
      "Epoch 12: Train Loss=1.5027, Acc=0.3367, F1=0.3085 | Val Loss=1.5332, Acc=0.3400, F1=0.2106\n",
      "Epoch 13: Train Loss=1.5158, Acc=0.3267, F1=0.3030 | Val Loss=1.6446, Acc=0.3200, F1=0.2343\n",
      "Epoch 14: Train Loss=1.5007, Acc=0.3400, F1=0.3234 | Val Loss=1.6032, Acc=0.2800, F1=0.1890\n",
      "Epoch 15: Train Loss=1.4962, Acc=0.3533, F1=0.3354 | Val Loss=1.5551, Acc=0.2600, F1=0.1363\n",
      "Epoch 16: Train Loss=1.4910, Acc=0.3433, F1=0.3288 | Val Loss=1.6372, Acc=0.2600, F1=0.1672\n",
      "Epoch 17: Train Loss=1.4720, Acc=0.3867, F1=0.3680 | Val Loss=1.5962, Acc=0.2800, F1=0.1765\n",
      "Epoch 18: Train Loss=1.4770, Acc=0.3633, F1=0.3429 | Val Loss=1.6278, Acc=0.2800, F1=0.1762\n",
      "Epoch 19: Train Loss=1.4636, Acc=0.3533, F1=0.3339 | Val Loss=1.5420, Acc=0.4600, F1=0.4098\n",
      "Epoch 20: Train Loss=1.4364, Acc=0.3733, F1=0.3431 | Val Loss=1.5017, Acc=0.3400, F1=0.2752\n",
      "Epoch 21: Train Loss=1.4648, Acc=0.3867, F1=0.3830 | Val Loss=1.5496, Acc=0.3400, F1=0.2444\n",
      "Epoch 22: Train Loss=1.4421, Acc=0.3367, F1=0.3112 | Val Loss=1.6273, Acc=0.4000, F1=0.2767\n",
      "Epoch 23: Train Loss=1.4558, Acc=0.3633, F1=0.3459 | Val Loss=1.4682, Acc=0.3800, F1=0.3320\n",
      "Epoch 24: Train Loss=1.4247, Acc=0.3733, F1=0.3508 | Val Loss=1.6213, Acc=0.3200, F1=0.2416\n",
      "Epoch 25: Train Loss=1.4283, Acc=0.3867, F1=0.3710 | Val Loss=1.6220, Acc=0.3400, F1=0.2713\n",
      "Epoch 26: Train Loss=1.4118, Acc=0.4000, F1=0.3835 | Val Loss=1.5562, Acc=0.4400, F1=0.3527\n",
      "Epoch 27: Train Loss=1.4030, Acc=0.3967, F1=0.3848 | Val Loss=1.7019, Acc=0.2800, F1=0.2382\n",
      "Epoch 28: Train Loss=1.4442, Acc=0.3667, F1=0.3388 | Val Loss=1.5290, Acc=0.3600, F1=0.2787\n",
      "Epoch 29: Train Loss=1.3428, Acc=0.4233, F1=0.3896 | Val Loss=1.5885, Acc=0.4800, F1=0.3838\n",
      "Epoch 30: Train Loss=1.3630, Acc=0.4267, F1=0.4173 | Val Loss=1.5181, Acc=0.3400, F1=0.2559\n",
      "Epoch 31: Train Loss=1.3587, Acc=0.3900, F1=0.3709 | Val Loss=1.5503, Acc=0.4000, F1=0.2971\n",
      "Epoch 32: Train Loss=1.3703, Acc=0.4000, F1=0.3621 | Val Loss=1.5367, Acc=0.4000, F1=0.2976\n",
      "Epoch 33: Train Loss=1.3398, Acc=0.4267, F1=0.3837 | Val Loss=1.4999, Acc=0.5000, F1=0.4393\n",
      "Epoch 34: Train Loss=1.3345, Acc=0.4100, F1=0.3926 | Val Loss=1.6137, Acc=0.3400, F1=0.2607\n",
      "Epoch 35: Train Loss=1.3722, Acc=0.4233, F1=0.4101 | Val Loss=1.6381, Acc=0.2200, F1=0.1867\n",
      "Epoch 36: Train Loss=1.3089, Acc=0.4667, F1=0.4440 | Val Loss=1.6135, Acc=0.3200, F1=0.2747\n",
      "Epoch 37: Train Loss=1.2625, Acc=0.4333, F1=0.3991 | Val Loss=1.5646, Acc=0.4800, F1=0.3614\n",
      "Epoch 38: Train Loss=1.2975, Acc=0.4367, F1=0.4008 | Val Loss=1.7487, Acc=0.4000, F1=0.3252\n",
      "Epoch 39: Train Loss=1.3392, Acc=0.3967, F1=0.3857 | Val Loss=1.5263, Acc=0.4000, F1=0.3383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:38:10,290] Trial 26 finished with value: 0.5 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00015463037622545837, 'weight_decay': 0.00043429459438439495}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss=1.3038, Acc=0.4100, F1=0.3836 | Val Loss=1.7823, Acc=0.3000, F1=0.2133\n",
      "\n",
      "[trial 27] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.4296, Acc=0.1700, F1=0.1629 | Val Loss=2.0176, Acc=0.2600, F1=0.0825\n",
      "Epoch 02: Train Loss=1.7384, Acc=0.2100, F1=0.1994 | Val Loss=1.7092, Acc=0.2600, F1=0.0825\n",
      "Epoch 03: Train Loss=1.7082, Acc=0.2067, F1=0.2048 | Val Loss=1.7246, Acc=0.2200, F1=0.0721\n",
      "Epoch 04: Train Loss=1.7444, Acc=0.2300, F1=0.2042 | Val Loss=1.6228, Acc=0.2600, F1=0.0825\n",
      "Epoch 05: Train Loss=1.6776, Acc=0.1900, F1=0.1745 | Val Loss=1.7731, Acc=0.2200, F1=0.0721\n",
      "Epoch 06: Train Loss=1.6861, Acc=0.1733, F1=0.1619 | Val Loss=1.5925, Acc=0.3000, F1=0.1512\n",
      "Epoch 07: Train Loss=1.6674, Acc=0.2167, F1=0.2160 | Val Loss=1.6091, Acc=0.2000, F1=0.1116\n",
      "Epoch 08: Train Loss=1.6762, Acc=0.2533, F1=0.2318 | Val Loss=1.7456, Acc=0.2400, F1=0.0857\n",
      "Epoch 09: Train Loss=1.6287, Acc=0.2167, F1=0.2136 | Val Loss=1.6385, Acc=0.3200, F1=0.2300\n",
      "Epoch 10: Train Loss=1.6753, Acc=0.2800, F1=0.2702 | Val Loss=1.5501, Acc=0.2800, F1=0.1504\n",
      "Epoch 11: Train Loss=1.5553, Acc=0.2800, F1=0.2608 | Val Loss=1.6331, Acc=0.2800, F1=0.1676\n",
      "Epoch 12: Train Loss=1.5059, Acc=0.3433, F1=0.3051 | Val Loss=1.5245, Acc=0.2600, F1=0.1396\n",
      "Epoch 13: Train Loss=1.5059, Acc=0.3133, F1=0.2726 | Val Loss=1.6259, Acc=0.2400, F1=0.1384\n",
      "Epoch 14: Train Loss=1.5015, Acc=0.2833, F1=0.2580 | Val Loss=1.5541, Acc=0.2600, F1=0.1644\n",
      "Epoch 15: Train Loss=1.4791, Acc=0.3133, F1=0.2881 | Val Loss=1.6572, Acc=0.2400, F1=0.1296\n",
      "Epoch 16: Train Loss=1.5110, Acc=0.3033, F1=0.2497 | Val Loss=1.5404, Acc=0.3000, F1=0.2118\n",
      "Epoch 17: Train Loss=1.4804, Acc=0.3267, F1=0.3006 | Val Loss=1.5634, Acc=0.3000, F1=0.2355\n",
      "Epoch 18: Train Loss=1.4750, Acc=0.3000, F1=0.2639 | Val Loss=1.7001, Acc=0.1600, F1=0.1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:40:15,790] Trial 27 finished with value: 0.32 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.0007158831801916574, 'weight_decay': 0.00042031838077478696}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=1.4768, Acc=0.3100, F1=0.2504 | Val Loss=1.5592, Acc=0.1800, F1=0.1117\n",
      "Early stopping\n",
      "\n",
      "[trial 28] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.0912, Acc=0.2567, F1=0.2498 | Val Loss=1.6954, Acc=0.3000, F1=0.2065\n",
      "Epoch 02: Train Loss=1.6101, Acc=0.3000, F1=0.2939 | Val Loss=1.7520, Acc=0.1400, F1=0.0820\n",
      "Epoch 03: Train Loss=1.6287, Acc=0.2867, F1=0.2742 | Val Loss=1.6715, Acc=0.3000, F1=0.1612\n",
      "Epoch 04: Train Loss=1.6064, Acc=0.3033, F1=0.2938 | Val Loss=1.5689, Acc=0.2600, F1=0.1317\n",
      "Epoch 05: Train Loss=1.5456, Acc=0.3300, F1=0.3227 | Val Loss=1.7115, Acc=0.2600, F1=0.1317\n",
      "Epoch 06: Train Loss=1.5657, Acc=0.3267, F1=0.3065 | Val Loss=1.7152, Acc=0.2800, F1=0.1404\n",
      "Epoch 07: Train Loss=1.5657, Acc=0.3200, F1=0.3140 | Val Loss=1.5722, Acc=0.2800, F1=0.1785\n",
      "Epoch 08: Train Loss=1.5354, Acc=0.3400, F1=0.3172 | Val Loss=1.7209, Acc=0.2600, F1=0.1369\n",
      "Epoch 09: Train Loss=1.5246, Acc=0.3033, F1=0.2693 | Val Loss=1.6175, Acc=0.2200, F1=0.1333\n",
      "Epoch 10: Train Loss=1.5209, Acc=0.3133, F1=0.3007 | Val Loss=1.7212, Acc=0.3200, F1=0.2294\n",
      "Epoch 11: Train Loss=1.5226, Acc=0.2900, F1=0.2769 | Val Loss=1.6601, Acc=0.2400, F1=0.1314\n",
      "Epoch 12: Train Loss=1.5167, Acc=0.3033, F1=0.2820 | Val Loss=1.4759, Acc=0.5200, F1=0.4623\n",
      "Epoch 13: Train Loss=1.5024, Acc=0.3700, F1=0.3636 | Val Loss=1.6693, Acc=0.1800, F1=0.1219\n",
      "Epoch 14: Train Loss=1.5119, Acc=0.3533, F1=0.3173 | Val Loss=1.6257, Acc=0.4000, F1=0.2763\n",
      "Epoch 15: Train Loss=1.4874, Acc=0.3600, F1=0.3222 | Val Loss=1.6170, Acc=0.3000, F1=0.1891\n",
      "Epoch 16: Train Loss=1.5130, Acc=0.3200, F1=0.3053 | Val Loss=1.6471, Acc=0.2600, F1=0.2015\n",
      "Epoch 17: Train Loss=1.4751, Acc=0.3033, F1=0.3018 | Val Loss=1.5552, Acc=0.3000, F1=0.2062\n",
      "Epoch 18: Train Loss=1.4695, Acc=0.3667, F1=0.3321 | Val Loss=1.5460, Acc=0.3400, F1=0.2257\n",
      "Epoch 19: Train Loss=1.4874, Acc=0.3267, F1=0.3176 | Val Loss=1.5182, Acc=0.4200, F1=0.3505\n",
      "Epoch 20: Train Loss=1.4532, Acc=0.3400, F1=0.3283 | Val Loss=1.5057, Acc=0.4000, F1=0.3158\n",
      "Epoch 21: Train Loss=1.4427, Acc=0.3500, F1=0.3209 | Val Loss=1.5656, Acc=0.4600, F1=0.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:43:22,144] Trial 28 finished with value: 0.52 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00015747250912443657, 'weight_decay': 0.0005219298077403784}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=1.5154, Acc=0.3433, F1=0.3073 | Val Loss=1.5602, Acc=0.3600, F1=0.2574\n",
      "Early stopping\n",
      "\n",
      "[trial 29] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.0246, Acc=0.2300, F1=0.2258 | Val Loss=1.7407, Acc=0.2600, F1=0.0825\n",
      "Epoch 02: Train Loss=1.7715, Acc=0.2467, F1=0.2434 | Val Loss=1.5585, Acc=0.3200, F1=0.1722\n",
      "Epoch 03: Train Loss=1.5959, Acc=0.2567, F1=0.2506 | Val Loss=1.9088, Acc=0.1600, F1=0.0914\n",
      "Epoch 04: Train Loss=1.6169, Acc=0.2633, F1=0.2486 | Val Loss=1.5526, Acc=0.2600, F1=0.0839\n",
      "Epoch 05: Train Loss=1.6684, Acc=0.2833, F1=0.2641 | Val Loss=1.5179, Acc=0.3000, F1=0.1484\n",
      "Epoch 06: Train Loss=1.5801, Acc=0.2833, F1=0.2813 | Val Loss=1.5604, Acc=0.3600, F1=0.2321\n",
      "Epoch 07: Train Loss=1.5905, Acc=0.3067, F1=0.2963 | Val Loss=1.4920, Acc=0.3800, F1=0.2559\n",
      "Epoch 08: Train Loss=1.5802, Acc=0.2900, F1=0.2849 | Val Loss=1.6105, Acc=0.3200, F1=0.2021\n",
      "Epoch 09: Train Loss=1.5285, Acc=0.3100, F1=0.2932 | Val Loss=1.9406, Acc=0.2600, F1=0.1317\n",
      "Epoch 10: Train Loss=1.5454, Acc=0.3133, F1=0.2849 | Val Loss=1.6063, Acc=0.3000, F1=0.1612\n",
      "Epoch 11: Train Loss=1.5239, Acc=0.3300, F1=0.3180 | Val Loss=1.5518, Acc=0.2400, F1=0.1766\n",
      "Epoch 12: Train Loss=1.5147, Acc=0.3367, F1=0.3280 | Val Loss=1.6381, Acc=0.1800, F1=0.1028\n",
      "Epoch 13: Train Loss=1.5689, Acc=0.3267, F1=0.3208 | Val Loss=1.6058, Acc=0.3600, F1=0.2519\n",
      "Epoch 14: Train Loss=1.4792, Acc=0.3467, F1=0.3327 | Val Loss=1.4876, Acc=0.2800, F1=0.2049\n",
      "Epoch 15: Train Loss=1.4740, Acc=0.3367, F1=0.3204 | Val Loss=1.5813, Acc=0.4200, F1=0.3545\n",
      "Epoch 16: Train Loss=1.4810, Acc=0.3333, F1=0.3101 | Val Loss=1.4441, Acc=0.3800, F1=0.2815\n",
      "Epoch 17: Train Loss=1.4815, Acc=0.3200, F1=0.3181 | Val Loss=1.5314, Acc=0.2600, F1=0.1317\n",
      "Epoch 18: Train Loss=1.4727, Acc=0.3267, F1=0.3173 | Val Loss=1.5128, Acc=0.3200, F1=0.2119\n",
      "Epoch 19: Train Loss=1.4484, Acc=0.3500, F1=0.3346 | Val Loss=1.5616, Acc=0.3600, F1=0.2960\n",
      "Epoch 20: Train Loss=1.4662, Acc=0.3433, F1=0.3160 | Val Loss=1.5583, Acc=0.4200, F1=0.3916\n",
      "Epoch 21: Train Loss=1.4644, Acc=0.3367, F1=0.3332 | Val Loss=1.4975, Acc=0.3600, F1=0.3000\n",
      "Epoch 22: Train Loss=1.4429, Acc=0.3933, F1=0.3674 | Val Loss=1.5073, Acc=0.3600, F1=0.3205\n",
      "Epoch 23: Train Loss=1.4670, Acc=0.3333, F1=0.3227 | Val Loss=1.4772, Acc=0.3600, F1=0.3207\n",
      "Epoch 24: Train Loss=1.4498, Acc=0.3567, F1=0.3307 | Val Loss=1.5324, Acc=0.4000, F1=0.3751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 19:46:09,373] Trial 29 finished with value: 0.42 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.00033983273946461924, 'weight_decay': 0.0006449676822578032}. Best is trial 12 with value: 0.54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=1.4538, Acc=0.3733, F1=0.3428 | Val Loss=1.4689, Acc=0.3000, F1=0.2348\n",
      "Early stopping\n",
      "Best hyper-parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00010752174995221688, 'weight_decay': 0.00017350533812756405}\n",
      "Best Val ACC (Optuna): 0.54 | Val F1: 0.43806411453470273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded eval — Train Acc=0.5500, F1=0.5218 | Val Acc=0.5400, F1=0.4381 | ΔACC=0.000000\n",
      "Saved VAL preds → results_final\\video_cls_val_ind.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 650x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (VAL):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5556    0.4545    0.5000        11\n",
      "           1     0.6667    0.7692    0.7143        13\n",
      "           2     0.7143    0.7692    0.7407        13\n",
      "           3     0.0000    0.0000    0.0000         8\n",
      "           4     0.1667    0.4000    0.2353         5\n",
      "\n",
      "    accuracy                         0.5400        50\n",
      "   macro avg     0.4206    0.4786    0.4381        50\n",
      "weighted avg     0.4979    0.5400    0.5118        50\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC-ROC (VAL): micro 0.7162 | macro 0.6983\n"
     ]
    }
   ],
   "source": [
    "def read_ids_from_dir(dir_path: str):\n",
    "    return set(os.path.splitext(fn)[0] for fn in os.listdir(dir_path))\n",
    "\n",
    "# Load + encode once\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# --- Split 1: Person-Independent\n",
    "train_ids_A = read_ids_from_dir(\"Person-Independent_Split/train\")\n",
    "val_ids_A   = read_ids_from_dir(\"Person-Independent_Split/val\")\n",
    "\n",
    "res_A = run_split(\"ind\", train_ids_A, val_ids_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a80ff-96d3-4db5-a242-5110107b7d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9f8a0dd-f46f-41d0-9483-b1608d158c4a",
   "metadata": {},
   "source": [
    "# Person - Dependent Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8372d73-0c43-44c2-ba89-ab9e98ae53f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:38:24,075] A new study created in memory with name: no-name-5d134f02-2b18-49be-b715-12577e53b39b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running CLASSIFICATION split: dep (target: view_range_enc_dep) ===\n",
      "\n",
      "[trial 0] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.4271, Acc=0.1806, F1=0.1804 | Val Loss=1.8844, Acc=0.1961, F1=0.0656\n",
      "Epoch 02: Train Loss=1.8747, Acc=0.2174, F1=0.1845 | Val Loss=1.8339, Acc=0.1961, F1=0.0656\n",
      "Epoch 03: Train Loss=1.8362, Acc=0.1706, F1=0.1631 | Val Loss=1.6408, Acc=0.1961, F1=0.0656\n",
      "Epoch 04: Train Loss=1.7461, Acc=0.1806, F1=0.1748 | Val Loss=1.7657, Acc=0.1961, F1=0.0656\n",
      "Epoch 05: Train Loss=1.6912, Acc=0.1873, F1=0.1827 | Val Loss=1.6825, Acc=0.1961, F1=0.0656\n",
      "Epoch 06: Train Loss=1.6549, Acc=0.1906, F1=0.1826 | Val Loss=1.6556, Acc=0.1961, F1=0.0656\n",
      "Epoch 07: Train Loss=1.6970, Acc=0.1639, F1=0.1618 | Val Loss=1.6524, Acc=0.1961, F1=0.0656\n",
      "Epoch 08: Train Loss=1.6803, Acc=0.1739, F1=0.1480 | Val Loss=1.6271, Acc=0.1961, F1=0.0656\n",
      "Epoch 09: Train Loss=1.6636, Acc=0.1672, F1=0.1544 | Val Loss=1.6211, Acc=0.1961, F1=0.0656\n",
      "Epoch 10: Train Loss=1.6547, Acc=0.1940, F1=0.1606 | Val Loss=1.6612, Acc=0.2157, F1=0.0710\n",
      "Epoch 11: Train Loss=1.6456, Acc=0.2074, F1=0.1932 | Val Loss=1.6364, Acc=0.1961, F1=0.0656\n",
      "Epoch 12: Train Loss=1.6383, Acc=0.1940, F1=0.1799 | Val Loss=1.6269, Acc=0.1961, F1=0.0656\n",
      "Epoch 13: Train Loss=1.6387, Acc=0.1672, F1=0.1439 | Val Loss=1.6232, Acc=0.1961, F1=0.0656\n",
      "Epoch 14: Train Loss=1.6352, Acc=0.1773, F1=0.1627 | Val Loss=1.6213, Acc=0.1961, F1=0.0656\n",
      "Epoch 15: Train Loss=1.6483, Acc=0.2007, F1=0.1977 | Val Loss=1.6202, Acc=0.1961, F1=0.0656\n",
      "Epoch 16: Train Loss=1.6292, Acc=0.2040, F1=0.1843 | Val Loss=1.6140, Acc=0.1961, F1=0.0656\n",
      "Epoch 17: Train Loss=1.6180, Acc=0.1806, F1=0.1497 | Val Loss=1.6333, Acc=0.1961, F1=0.0656\n",
      "Epoch 18: Train Loss=1.6371, Acc=0.1873, F1=0.1778 | Val Loss=1.6845, Acc=0.1961, F1=0.0656\n",
      "Epoch 19: Train Loss=1.6442, Acc=0.2107, F1=0.1868 | Val Loss=1.6131, Acc=0.1961, F1=0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:41:10,428] Trial 0 finished with value: 0.21568627450980393 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.0015751320499779737, 'weight_decay': 2.9380279387035354e-06}. Best is trial 0 with value: 0.21568627450980393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=1.6328, Acc=0.2007, F1=0.1767 | Val Loss=1.6648, Acc=0.1961, F1=0.0656\n",
      "Early stopping\n",
      "\n",
      "[trial 1] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.3415, Acc=0.2441, F1=0.2410 | Val Loss=1.9023, Acc=0.1961, F1=0.0656\n",
      "Epoch 02: Train Loss=1.8181, Acc=0.2174, F1=0.2066 | Val Loss=2.0777, Acc=0.1961, F1=0.0656\n",
      "Epoch 03: Train Loss=1.7609, Acc=0.2107, F1=0.1993 | Val Loss=1.6289, Acc=0.1961, F1=0.0656\n",
      "Epoch 04: Train Loss=1.7185, Acc=0.2040, F1=0.2039 | Val Loss=1.7843, Acc=0.1961, F1=0.0656\n",
      "Epoch 05: Train Loss=1.7011, Acc=0.1773, F1=0.1684 | Val Loss=1.6701, Acc=0.1961, F1=0.0656\n",
      "Epoch 06: Train Loss=1.6657, Acc=0.2107, F1=0.2084 | Val Loss=1.9073, Acc=0.1961, F1=0.0656\n",
      "Epoch 07: Train Loss=1.7334, Acc=0.1237, F1=0.1211 | Val Loss=1.6346, Acc=0.1961, F1=0.0656\n",
      "Epoch 08: Train Loss=1.6626, Acc=0.1906, F1=0.1770 | Val Loss=1.6351, Acc=0.1961, F1=0.0656\n",
      "Epoch 09: Train Loss=1.6464, Acc=0.2375, F1=0.2350 | Val Loss=1.7436, Acc=0.1961, F1=0.0656\n",
      "Epoch 10: Train Loss=1.7059, Acc=0.1906, F1=0.1842 | Val Loss=1.6107, Acc=0.1961, F1=0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:43:07,544] Trial 1 finished with value: 0.19607843137254902 and parameters: {'nhead': 4, 'num_layers': 4, 'lr': 0.0015930522616241021, 'weight_decay': 0.000133112160807369}. Best is trial 0 with value: 0.21568627450980393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=1.6379, Acc=0.1773, F1=0.1654 | Val Loss=1.6204, Acc=0.1961, F1=0.0656\n",
      "Early stopping\n",
      "\n",
      "[trial 2] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.0099, Acc=0.2207, F1=0.2173 | Val Loss=1.6026, Acc=0.2745, F1=0.1595\n",
      "Epoch 02: Train Loss=1.6308, Acc=0.2508, F1=0.2421 | Val Loss=1.6246, Acc=0.1961, F1=0.0656\n",
      "Epoch 03: Train Loss=1.7323, Acc=0.2274, F1=0.2237 | Val Loss=1.5924, Acc=0.2549, F1=0.1474\n",
      "Epoch 04: Train Loss=1.6798, Acc=0.2642, F1=0.2629 | Val Loss=1.7753, Acc=0.2549, F1=0.1521\n",
      "Epoch 05: Train Loss=1.5858, Acc=0.2709, F1=0.2500 | Val Loss=1.6437, Acc=0.2549, F1=0.1387\n",
      "Epoch 06: Train Loss=1.5429, Acc=0.2943, F1=0.2857 | Val Loss=1.5321, Acc=0.2549, F1=0.1689\n",
      "Epoch 07: Train Loss=1.5359, Acc=0.3010, F1=0.2663 | Val Loss=1.5748, Acc=0.3137, F1=0.1843\n",
      "Epoch 08: Train Loss=1.5624, Acc=0.2475, F1=0.2391 | Val Loss=1.6544, Acc=0.1961, F1=0.0656\n",
      "Epoch 09: Train Loss=1.6683, Acc=0.2140, F1=0.1690 | Val Loss=1.6320, Acc=0.2157, F1=0.0710\n",
      "Epoch 10: Train Loss=1.7442, Acc=0.1706, F1=0.1464 | Val Loss=1.6879, Acc=0.1961, F1=0.0656\n",
      "Epoch 11: Train Loss=1.6548, Acc=0.1940, F1=0.1633 | Val Loss=1.6289, Acc=0.1961, F1=0.0656\n",
      "Epoch 12: Train Loss=1.6467, Acc=0.2007, F1=0.1728 | Val Loss=1.6604, Acc=0.1961, F1=0.0656\n",
      "Epoch 13: Train Loss=1.6497, Acc=0.2040, F1=0.1779 | Val Loss=1.6137, Acc=0.1961, F1=0.0656\n",
      "Epoch 14: Train Loss=1.6383, Acc=0.1806, F1=0.1419 | Val Loss=1.6287, Acc=0.1961, F1=0.0656\n",
      "Epoch 15: Train Loss=1.6609, Acc=0.1371, F1=0.1235 | Val Loss=1.6378, Acc=0.2157, F1=0.0710\n",
      "Epoch 16: Train Loss=1.6375, Acc=0.1739, F1=0.1514 | Val Loss=1.6617, Acc=0.1961, F1=0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:46:08,396] Trial 2 finished with value: 0.3137254901960784 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00026587543983272726, 'weight_decay': 3.5113563139704077e-06}. Best is trial 2 with value: 0.3137254901960784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=1.6444, Acc=0.2107, F1=0.1576 | Val Loss=1.6215, Acc=0.1961, F1=0.0656\n",
      "Early stopping\n",
      "\n",
      "[trial 3] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.1971, Acc=0.2040, F1=0.1915 | Val Loss=1.6750, Acc=0.1961, F1=0.0656\n",
      "Epoch 02: Train Loss=1.8081, Acc=0.1839, F1=0.1652 | Val Loss=1.6350, Acc=0.1961, F1=0.0656\n",
      "Epoch 03: Train Loss=1.6856, Acc=0.2140, F1=0.1996 | Val Loss=1.8026, Acc=0.1961, F1=0.0656\n",
      "Epoch 04: Train Loss=1.7214, Acc=0.2207, F1=0.2136 | Val Loss=1.7008, Acc=0.1961, F1=0.0656\n",
      "Epoch 05: Train Loss=1.7098, Acc=0.2207, F1=0.2104 | Val Loss=1.7102, Acc=0.1961, F1=0.0656\n",
      "Epoch 06: Train Loss=1.6825, Acc=0.2207, F1=0.1945 | Val Loss=1.8316, Acc=0.1961, F1=0.0656\n",
      "Epoch 07: Train Loss=1.6823, Acc=0.1873, F1=0.1817 | Val Loss=1.6275, Acc=0.1961, F1=0.0656\n",
      "Epoch 08: Train Loss=1.6793, Acc=0.1906, F1=0.1819 | Val Loss=1.6479, Acc=0.1961, F1=0.0656\n",
      "Epoch 09: Train Loss=1.6452, Acc=0.2040, F1=0.1848 | Val Loss=1.6608, Acc=0.1961, F1=0.0656\n",
      "Epoch 10: Train Loss=1.6642, Acc=0.2174, F1=0.2098 | Val Loss=1.6350, Acc=0.1961, F1=0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:47:41,465] Trial 3 finished with value: 0.19607843137254902 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.0007309539835912913, 'weight_decay': 7.4763120622522945e-06}. Best is trial 2 with value: 0.3137254901960784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=1.6578, Acc=0.1706, F1=0.1554 | Val Loss=1.6730, Acc=0.1961, F1=0.0656\n",
      "Early stopping\n",
      "\n",
      "[trial 4] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.1925, Acc=0.2308, F1=0.2284 | Val Loss=1.9674, Acc=0.2941, F1=0.1651\n",
      "Epoch 02: Train Loss=1.6603, Acc=0.3077, F1=0.3062 | Val Loss=1.5903, Acc=0.3137, F1=0.1787\n",
      "Epoch 03: Train Loss=1.6517, Acc=0.2508, F1=0.2266 | Val Loss=1.6577, Acc=0.2157, F1=0.1011\n",
      "Epoch 04: Train Loss=1.6951, Acc=0.2742, F1=0.2703 | Val Loss=1.6957, Acc=0.2157, F1=0.0994\n",
      "Epoch 05: Train Loss=1.6069, Acc=0.2609, F1=0.2630 | Val Loss=1.5963, Acc=0.3137, F1=0.1851\n",
      "Epoch 06: Train Loss=1.5498, Acc=0.2977, F1=0.2779 | Val Loss=1.6967, Acc=0.2549, F1=0.1812\n",
      "Epoch 07: Train Loss=1.5773, Acc=0.2977, F1=0.2908 | Val Loss=1.5566, Acc=0.2745, F1=0.1665\n",
      "Epoch 08: Train Loss=1.4926, Acc=0.3244, F1=0.3223 | Val Loss=1.4973, Acc=0.3333, F1=0.2349\n",
      "Epoch 09: Train Loss=1.4419, Acc=0.2876, F1=0.2714 | Val Loss=1.5474, Acc=0.3137, F1=0.1818\n",
      "Epoch 10: Train Loss=1.5051, Acc=0.2776, F1=0.2676 | Val Loss=1.5450, Acc=0.2941, F1=0.1826\n",
      "Epoch 11: Train Loss=1.4406, Acc=0.3512, F1=0.3301 | Val Loss=1.6305, Acc=0.3137, F1=0.2267\n",
      "Epoch 12: Train Loss=1.4964, Acc=0.3110, F1=0.3138 | Val Loss=1.5051, Acc=0.2941, F1=0.2375\n",
      "Epoch 13: Train Loss=1.5394, Acc=0.3077, F1=0.2968 | Val Loss=1.5953, Acc=0.1961, F1=0.1432\n",
      "Epoch 14: Train Loss=1.4859, Acc=0.3043, F1=0.2665 | Val Loss=1.4846, Acc=0.2941, F1=0.1703\n",
      "Epoch 15: Train Loss=1.5047, Acc=0.2742, F1=0.2683 | Val Loss=1.5095, Acc=0.3137, F1=0.2543\n",
      "Epoch 16: Train Loss=1.4624, Acc=0.2876, F1=0.2537 | Val Loss=1.4481, Acc=0.3137, F1=0.2316\n",
      "Epoch 17: Train Loss=1.4615, Acc=0.3177, F1=0.3103 | Val Loss=1.4869, Acc=0.2941, F1=0.1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:49:24,109] Trial 4 finished with value: 0.3333333333333333 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.0005404103854647331, 'weight_decay': 2.334586407601622e-05}. Best is trial 4 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=1.5159, Acc=0.3077, F1=0.3043 | Val Loss=1.4966, Acc=0.2941, F1=0.2047\n",
      "Early stopping\n",
      "\n",
      "[trial 5] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.5144, Acc=0.1773, F1=0.1648 | Val Loss=1.7401, Acc=0.2157, F1=0.0710\n",
      "Epoch 02: Train Loss=1.7592, Acc=0.1873, F1=0.1736 | Val Loss=1.7326, Acc=0.2157, F1=0.0710\n",
      "Epoch 03: Train Loss=1.7494, Acc=0.2140, F1=0.2079 | Val Loss=1.7608, Acc=0.1961, F1=0.0656\n",
      "Epoch 04: Train Loss=1.7576, Acc=0.1706, F1=0.1641 | Val Loss=1.8437, Acc=0.1961, F1=0.0656\n",
      "Epoch 05: Train Loss=1.7170, Acc=0.2140, F1=0.2089 | Val Loss=1.6452, Acc=0.1961, F1=0.0656\n",
      "Epoch 06: Train Loss=1.6686, Acc=0.1706, F1=0.1496 | Val Loss=1.6399, Acc=0.1961, F1=0.0656\n",
      "Epoch 07: Train Loss=1.6717, Acc=0.1873, F1=0.1801 | Val Loss=1.6733, Acc=0.1961, F1=0.0656\n",
      "Epoch 08: Train Loss=1.6750, Acc=0.1773, F1=0.1418 | Val Loss=1.6327, Acc=0.1961, F1=0.0656\n",
      "Epoch 09: Train Loss=1.6529, Acc=0.1672, F1=0.1420 | Val Loss=1.7025, Acc=0.2157, F1=0.0710\n",
      "Epoch 10: Train Loss=1.6732, Acc=0.1405, F1=0.1355 | Val Loss=1.6263, Acc=0.1961, F1=0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:50:33,382] Trial 5 finished with value: 0.21568627450980393 and parameters: {'nhead': 4, 'num_layers': 3, 'lr': 0.0015304852121831463, 'weight_decay': 1.3783237455007196e-06}. Best is trial 4 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=1.6687, Acc=0.1839, F1=0.1644 | Val Loss=1.6420, Acc=0.1961, F1=0.0656\n",
      "Early stopping\n",
      "\n",
      "[trial 6] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=3.5388, Acc=0.1572, F1=0.1576 | Val Loss=1.8741, Acc=0.1961, F1=0.0656\n",
      "Epoch 02: Train Loss=1.8679, Acc=0.2007, F1=0.1978 | Val Loss=1.6471, Acc=0.1961, F1=0.0656\n",
      "Epoch 03: Train Loss=1.6613, Acc=0.2007, F1=0.1897 | Val Loss=1.6339, Acc=0.1961, F1=0.0656\n",
      "Epoch 04: Train Loss=1.6916, Acc=0.2241, F1=0.2255 | Val Loss=1.7563, Acc=0.2157, F1=0.0710\n",
      "Epoch 05: Train Loss=1.6060, Acc=0.2575, F1=0.2444 | Val Loss=1.6121, Acc=0.2941, F1=0.1750\n",
      "Epoch 06: Train Loss=1.5658, Acc=0.2676, F1=0.2433 | Val Loss=1.4996, Acc=0.2941, F1=0.1706\n",
      "Epoch 07: Train Loss=1.5922, Acc=0.2408, F1=0.2381 | Val Loss=1.6388, Acc=0.1961, F1=0.0656\n",
      "Epoch 08: Train Loss=1.7116, Acc=0.1973, F1=0.1862 | Val Loss=1.7282, Acc=0.1765, F1=0.0935\n",
      "Epoch 09: Train Loss=1.6502, Acc=0.2475, F1=0.2409 | Val Loss=2.0057, Acc=0.2353, F1=0.1181\n",
      "Epoch 10: Train Loss=1.6668, Acc=0.2441, F1=0.2373 | Val Loss=1.6308, Acc=0.1765, F1=0.0832\n",
      "Epoch 11: Train Loss=1.6279, Acc=0.2709, F1=0.2476 | Val Loss=1.6551, Acc=0.1961, F1=0.0656\n",
      "Epoch 12: Train Loss=1.6686, Acc=0.2007, F1=0.1992 | Val Loss=1.5650, Acc=0.2353, F1=0.1363\n",
      "Epoch 13: Train Loss=1.5920, Acc=0.2375, F1=0.2112 | Val Loss=1.5941, Acc=0.2353, F1=0.1481\n",
      "Epoch 14: Train Loss=1.5692, Acc=0.2542, F1=0.2065 | Val Loss=1.5871, Acc=0.2941, F1=0.2249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:51:10,594] Trial 6 finished with value: 0.29411764705882354 and parameters: {'nhead': 4, 'num_layers': 1, 'lr': 0.007902619549708232, 'weight_decay': 0.0007886714129990489}. Best is trial 4 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=1.5998, Acc=0.2542, F1=0.2404 | Val Loss=1.6214, Acc=0.2157, F1=0.1035\n",
      "Early stopping\n",
      "\n",
      "[trial 7] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.5197, Acc=0.2508, F1=0.2491 | Val Loss=2.1059, Acc=0.3137, F1=0.2227\n",
      "Epoch 02: Train Loss=1.7330, Acc=0.2776, F1=0.2734 | Val Loss=1.5618, Acc=0.2745, F1=0.1548\n",
      "Epoch 03: Train Loss=1.6322, Acc=0.2843, F1=0.2803 | Val Loss=1.5329, Acc=0.2941, F1=0.1689\n",
      "Epoch 04: Train Loss=1.6407, Acc=0.2977, F1=0.2961 | Val Loss=1.7938, Acc=0.3137, F1=0.1812\n",
      "Epoch 05: Train Loss=1.6377, Acc=0.2742, F1=0.2522 | Val Loss=1.7235, Acc=0.2549, F1=0.1910\n",
      "Epoch 06: Train Loss=1.6088, Acc=0.2642, F1=0.2633 | Val Loss=1.6038, Acc=0.2353, F1=0.1211\n",
      "Epoch 07: Train Loss=1.5832, Acc=0.2977, F1=0.2793 | Val Loss=1.5389, Acc=0.2745, F1=0.1551\n",
      "Epoch 08: Train Loss=1.5489, Acc=0.2776, F1=0.2595 | Val Loss=1.5409, Acc=0.2745, F1=0.1629\n",
      "Epoch 09: Train Loss=1.5080, Acc=0.2843, F1=0.2769 | Val Loss=1.5884, Acc=0.2941, F1=0.1757\n",
      "Epoch 10: Train Loss=1.4593, Acc=0.3177, F1=0.2916 | Val Loss=1.5645, Acc=0.2353, F1=0.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:51:37,818] Trial 7 finished with value: 0.3137254901960784 and parameters: {'nhead': 4, 'num_layers': 1, 'lr': 0.0023359635026261607, 'weight_decay': 2.091498132903561e-05}. Best is trial 4 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=1.4237, Acc=0.3378, F1=0.2978 | Val Loss=1.5376, Acc=0.2941, F1=0.2282\n",
      "Early stopping\n",
      "\n",
      "[trial 8] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.6662, Acc=0.1906, F1=0.1882 | Val Loss=2.0698, Acc=0.1961, F1=0.0656\n",
      "Epoch 02: Train Loss=2.0916, Acc=0.1839, F1=0.1852 | Val Loss=1.8124, Acc=0.1961, F1=0.0656\n",
      "Epoch 03: Train Loss=1.7136, Acc=0.2040, F1=0.2001 | Val Loss=1.6900, Acc=0.2941, F1=0.2186\n",
      "Epoch 04: Train Loss=1.5651, Acc=0.2876, F1=0.2815 | Val Loss=1.5198, Acc=0.3137, F1=0.2415\n",
      "Epoch 05: Train Loss=1.5816, Acc=0.3010, F1=0.2999 | Val Loss=1.5264, Acc=0.3333, F1=0.2529\n",
      "Epoch 06: Train Loss=1.5229, Acc=0.3077, F1=0.2946 | Val Loss=1.7012, Acc=0.2157, F1=0.1238\n",
      "Epoch 07: Train Loss=1.4804, Acc=0.3110, F1=0.3057 | Val Loss=1.6970, Acc=0.2549, F1=0.1898\n",
      "Epoch 08: Train Loss=1.4921, Acc=0.2843, F1=0.2828 | Val Loss=1.5273, Acc=0.2745, F1=0.2224\n",
      "Epoch 09: Train Loss=1.4347, Acc=0.3344, F1=0.2974 | Val Loss=1.7198, Acc=0.2353, F1=0.2052\n",
      "Epoch 10: Train Loss=1.4035, Acc=0.3244, F1=0.3047 | Val Loss=1.5962, Acc=0.2353, F1=0.1713\n",
      "Epoch 11: Train Loss=1.3684, Acc=0.3612, F1=0.3421 | Val Loss=1.9481, Acc=0.2157, F1=0.1434\n",
      "Epoch 12: Train Loss=1.4001, Acc=0.3244, F1=0.2561 | Val Loss=1.7084, Acc=0.2549, F1=0.1636\n",
      "Epoch 13: Train Loss=1.3464, Acc=0.3712, F1=0.3553 | Val Loss=1.7791, Acc=0.2745, F1=0.2050\n",
      "Epoch 14: Train Loss=1.3146, Acc=0.3177, F1=0.2925 | Val Loss=2.1422, Acc=0.2157, F1=0.1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:52:16,145] Trial 8 finished with value: 0.3333333333333333 and parameters: {'nhead': 8, 'num_layers': 1, 'lr': 0.006586289317583112, 'weight_decay': 5.975027999960295e-06}. Best is trial 4 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=1.2843, Acc=0.3645, F1=0.3615 | Val Loss=2.1676, Acc=0.1373, F1=0.0890\n",
      "Early stopping\n",
      "\n",
      "[trial 9] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.4651, Acc=0.1873, F1=0.1838 | Val Loss=1.8937, Acc=0.2157, F1=0.0710\n",
      "Epoch 02: Train Loss=1.7356, Acc=0.2140, F1=0.2072 | Val Loss=1.6394, Acc=0.1961, F1=0.0656\n",
      "Epoch 03: Train Loss=1.7081, Acc=0.1906, F1=0.1854 | Val Loss=1.7558, Acc=0.1961, F1=0.0656\n",
      "Epoch 04: Train Loss=1.7241, Acc=0.1572, F1=0.1491 | Val Loss=1.7099, Acc=0.1961, F1=0.0656\n",
      "Epoch 05: Train Loss=1.7062, Acc=0.1505, F1=0.1500 | Val Loss=1.7009, Acc=0.2157, F1=0.0710\n",
      "Epoch 06: Train Loss=1.7008, Acc=0.1639, F1=0.1533 | Val Loss=1.6405, Acc=0.1961, F1=0.0656\n",
      "Epoch 07: Train Loss=1.6901, Acc=0.1739, F1=0.1564 | Val Loss=1.6261, Acc=0.1961, F1=0.0656\n",
      "Epoch 08: Train Loss=1.6729, Acc=0.1873, F1=0.1738 | Val Loss=1.6310, Acc=0.1961, F1=0.0656\n",
      "Epoch 09: Train Loss=1.6624, Acc=0.2140, F1=0.2106 | Val Loss=1.6382, Acc=0.1961, F1=0.0656\n",
      "Epoch 10: Train Loss=1.6809, Acc=0.1739, F1=0.1412 | Val Loss=1.6294, Acc=0.1961, F1=0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:53:22,284] Trial 9 finished with value: 0.21568627450980393 and parameters: {'nhead': 4, 'num_layers': 3, 'lr': 0.0012399967836846098, 'weight_decay': 3.5856126103453987e-06}. Best is trial 4 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=1.6486, Acc=0.2174, F1=0.1760 | Val Loss=1.6308, Acc=0.1961, F1=0.0656\n",
      "Early stopping\n",
      "\n",
      "[trial 10] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.7603, Acc=0.2542, F1=0.2527 | Val Loss=1.7236, Acc=0.2745, F1=0.1629\n",
      "Epoch 02: Train Loss=1.5559, Acc=0.3311, F1=0.3308 | Val Loss=1.5547, Acc=0.2549, F1=0.1984\n",
      "Epoch 03: Train Loss=1.5620, Acc=0.3344, F1=0.3304 | Val Loss=1.4909, Acc=0.3333, F1=0.3001\n",
      "Epoch 04: Train Loss=1.4985, Acc=0.3378, F1=0.3336 | Val Loss=1.4423, Acc=0.3725, F1=0.3758\n",
      "Epoch 05: Train Loss=1.4244, Acc=0.3612, F1=0.3608 | Val Loss=1.8217, Acc=0.3725, F1=0.2770\n",
      "Epoch 06: Train Loss=1.4733, Acc=0.4348, F1=0.4340 | Val Loss=1.4802, Acc=0.3725, F1=0.3311\n",
      "Epoch 07: Train Loss=1.3749, Acc=0.4080, F1=0.4087 | Val Loss=1.4811, Acc=0.3333, F1=0.2908\n",
      "Epoch 08: Train Loss=1.3149, Acc=0.4582, F1=0.4516 | Val Loss=1.4956, Acc=0.2549, F1=0.2161\n",
      "Epoch 09: Train Loss=1.2803, Acc=0.4716, F1=0.4640 | Val Loss=1.3704, Acc=0.4314, F1=0.4231\n",
      "Epoch 10: Train Loss=1.2330, Acc=0.5385, F1=0.5338 | Val Loss=1.4760, Acc=0.2941, F1=0.2883\n",
      "Epoch 11: Train Loss=1.1160, Acc=0.5652, F1=0.5646 | Val Loss=1.6726, Acc=0.3529, F1=0.3587\n",
      "Epoch 12: Train Loss=1.0510, Acc=0.5518, F1=0.5484 | Val Loss=1.4121, Acc=0.4706, F1=0.4482\n",
      "Epoch 13: Train Loss=0.9058, Acc=0.6555, F1=0.6516 | Val Loss=1.7503, Acc=0.3922, F1=0.3976\n",
      "Epoch 14: Train Loss=0.7948, Acc=0.7258, F1=0.7255 | Val Loss=1.7841, Acc=0.4902, F1=0.4480\n",
      "Epoch 15: Train Loss=0.7419, Acc=0.7124, F1=0.7126 | Val Loss=1.9333, Acc=0.4510, F1=0.4567\n",
      "Epoch 16: Train Loss=0.5964, Acc=0.8161, F1=0.8150 | Val Loss=2.0962, Acc=0.4314, F1=0.3986\n",
      "Epoch 17: Train Loss=0.4500, Acc=0.8261, F1=0.8263 | Val Loss=2.2857, Acc=0.5098, F1=0.5091\n",
      "Epoch 18: Train Loss=0.4223, Acc=0.8428, F1=0.8429 | Val Loss=2.6612, Acc=0.4510, F1=0.4452\n",
      "Epoch 19: Train Loss=0.4299, Acc=0.8495, F1=0.8498 | Val Loss=2.3837, Acc=0.4902, F1=0.4894\n",
      "Epoch 20: Train Loss=0.2105, Acc=0.9064, F1=0.9067 | Val Loss=3.4134, Acc=0.4314, F1=0.4246\n",
      "Epoch 21: Train Loss=0.1524, Acc=0.9498, F1=0.9497 | Val Loss=3.8098, Acc=0.5294, F1=0.5335\n",
      "Epoch 22: Train Loss=0.2293, Acc=0.9231, F1=0.9230 | Val Loss=3.5542, Acc=0.4902, F1=0.4912\n",
      "Epoch 23: Train Loss=0.0806, Acc=0.9799, F1=0.9799 | Val Loss=3.6411, Acc=0.5294, F1=0.5067\n",
      "Epoch 24: Train Loss=0.0517, Acc=0.9866, F1=0.9867 | Val Loss=4.5904, Acc=0.5098, F1=0.5086\n",
      "Epoch 25: Train Loss=0.1152, Acc=0.9666, F1=0.9663 | Val Loss=4.7686, Acc=0.4510, F1=0.4365\n",
      "Epoch 26: Train Loss=0.0697, Acc=0.9799, F1=0.9800 | Val Loss=4.8109, Acc=0.4706, F1=0.4859\n",
      "Epoch 27: Train Loss=0.1096, Acc=0.9732, F1=0.9733 | Val Loss=4.6144, Acc=0.5294, F1=0.5189\n",
      "Epoch 28: Train Loss=0.0654, Acc=0.9799, F1=0.9799 | Val Loss=4.1269, Acc=0.5098, F1=0.5167\n",
      "Epoch 29: Train Loss=0.0124, Acc=0.9967, F1=0.9967 | Val Loss=4.7735, Acc=0.4510, F1=0.4647\n",
      "Epoch 30: Train Loss=0.0102, Acc=1.0000, F1=1.0000 | Val Loss=5.0777, Acc=0.4902, F1=0.4852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:55:34,638] Trial 10 finished with value: 0.5294117647058824 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00010353677627159794, 'weight_decay': 8.306050731972222e-05}. Best is trial 10 with value: 0.5294117647058824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=0.0048, Acc=0.9967, F1=0.9966 | Val Loss=4.5266, Acc=0.5294, F1=0.5272\n",
      "Early stopping\n",
      "\n",
      "[trial 11] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.8253, Acc=0.2441, F1=0.2409 | Val Loss=1.6374, Acc=0.2157, F1=0.1137\n",
      "Epoch 02: Train Loss=1.5937, Acc=0.3244, F1=0.3179 | Val Loss=1.6582, Acc=0.3137, F1=0.2084\n",
      "Epoch 03: Train Loss=1.5184, Acc=0.3211, F1=0.3153 | Val Loss=1.6546, Acc=0.3529, F1=0.2308\n",
      "Epoch 04: Train Loss=1.5175, Acc=0.3813, F1=0.3763 | Val Loss=1.5132, Acc=0.3333, F1=0.2709\n",
      "Epoch 05: Train Loss=1.4953, Acc=0.3645, F1=0.3653 | Val Loss=1.4465, Acc=0.2549, F1=0.2348\n",
      "Epoch 06: Train Loss=1.4035, Acc=0.3913, F1=0.3878 | Val Loss=1.4280, Acc=0.4118, F1=0.3310\n",
      "Epoch 07: Train Loss=1.3997, Acc=0.4214, F1=0.4211 | Val Loss=1.4074, Acc=0.4314, F1=0.3948\n",
      "Epoch 08: Train Loss=1.3549, Acc=0.4749, F1=0.4664 | Val Loss=1.6667, Acc=0.3333, F1=0.2765\n",
      "Epoch 09: Train Loss=1.3833, Acc=0.4214, F1=0.4204 | Val Loss=1.3795, Acc=0.3529, F1=0.3399\n",
      "Epoch 10: Train Loss=1.2457, Acc=0.4716, F1=0.4623 | Val Loss=1.5364, Acc=0.3725, F1=0.3275\n",
      "Epoch 11: Train Loss=1.1942, Acc=0.5251, F1=0.5216 | Val Loss=1.6191, Acc=0.4314, F1=0.4046\n",
      "Epoch 12: Train Loss=1.1216, Acc=0.5318, F1=0.5323 | Val Loss=1.5526, Acc=0.3725, F1=0.3392\n",
      "Epoch 13: Train Loss=0.9772, Acc=0.6054, F1=0.6023 | Val Loss=1.4844, Acc=0.4118, F1=0.4223\n",
      "Epoch 14: Train Loss=0.8766, Acc=0.6120, F1=0.6108 | Val Loss=1.6897, Acc=0.4118, F1=0.3828\n",
      "Epoch 15: Train Loss=0.7355, Acc=0.7157, F1=0.7128 | Val Loss=1.8641, Acc=0.4706, F1=0.4486\n",
      "Epoch 16: Train Loss=0.6206, Acc=0.7692, F1=0.7678 | Val Loss=1.8193, Acc=0.3725, F1=0.3870\n",
      "Epoch 17: Train Loss=0.4929, Acc=0.8227, F1=0.8232 | Val Loss=2.2728, Acc=0.4314, F1=0.4208\n",
      "Epoch 18: Train Loss=0.4306, Acc=0.8462, F1=0.8454 | Val Loss=2.4365, Acc=0.4118, F1=0.4263\n",
      "Epoch 19: Train Loss=0.3787, Acc=0.8729, F1=0.8726 | Val Loss=2.7647, Acc=0.4118, F1=0.4114\n",
      "Epoch 20: Train Loss=0.2865, Acc=0.8997, F1=0.8988 | Val Loss=2.9583, Acc=0.4314, F1=0.4072\n",
      "Epoch 21: Train Loss=0.4325, Acc=0.8629, F1=0.8622 | Val Loss=2.9112, Acc=0.4902, F1=0.4829\n",
      "Epoch 22: Train Loss=0.1996, Acc=0.9064, F1=0.9069 | Val Loss=2.9433, Acc=0.4706, F1=0.4579\n",
      "Epoch 23: Train Loss=0.1416, Acc=0.9498, F1=0.9496 | Val Loss=4.1342, Acc=0.4314, F1=0.4154\n",
      "Epoch 24: Train Loss=0.1013, Acc=0.9565, F1=0.9564 | Val Loss=4.4120, Acc=0.4118, F1=0.4017\n",
      "Epoch 25: Train Loss=0.1192, Acc=0.9666, F1=0.9665 | Val Loss=3.8300, Acc=0.4314, F1=0.4032\n",
      "Epoch 26: Train Loss=0.0425, Acc=0.9900, F1=0.9899 | Val Loss=4.1657, Acc=0.5490, F1=0.5298\n",
      "Epoch 27: Train Loss=0.0604, Acc=0.9732, F1=0.9733 | Val Loss=4.3112, Acc=0.4314, F1=0.4060\n",
      "Epoch 28: Train Loss=0.0500, Acc=0.9799, F1=0.9799 | Val Loss=4.0399, Acc=0.4510, F1=0.4425\n",
      "Epoch 29: Train Loss=0.0285, Acc=0.9900, F1=0.9900 | Val Loss=4.7793, Acc=0.4118, F1=0.4121\n",
      "Epoch 30: Train Loss=0.0227, Acc=0.9900, F1=0.9900 | Val Loss=4.5494, Acc=0.3922, F1=0.3851\n",
      "Epoch 31: Train Loss=0.0588, Acc=0.9833, F1=0.9832 | Val Loss=4.2172, Acc=0.5098, F1=0.4904\n",
      "Epoch 32: Train Loss=0.0301, Acc=0.9933, F1=0.9933 | Val Loss=4.6549, Acc=0.4902, F1=0.4836\n",
      "Epoch 33: Train Loss=0.0044, Acc=1.0000, F1=1.0000 | Val Loss=4.8228, Acc=0.4706, F1=0.4903\n",
      "Epoch 34: Train Loss=0.0017, Acc=1.0000, F1=1.0000 | Val Loss=4.5037, Acc=0.5294, F1=0.5290\n",
      "Epoch 35: Train Loss=0.0194, Acc=0.9933, F1=0.9933 | Val Loss=4.8391, Acc=0.4510, F1=0.4478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:58:10,309] Trial 11 finished with value: 0.5490196078431373 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00010744583847151158, 'weight_decay': 8.201915027201743e-05}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=0.0201, Acc=0.9967, F1=0.9967 | Val Loss=4.6521, Acc=0.5294, F1=0.5067\n",
      "Early stopping\n",
      "\n",
      "[trial 12] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.7403, Acc=0.2542, F1=0.2498 | Val Loss=1.5101, Acc=0.2549, F1=0.1462\n",
      "Epoch 02: Train Loss=1.5708, Acc=0.2642, F1=0.2625 | Val Loss=1.7083, Acc=0.2745, F1=0.1996\n",
      "Epoch 03: Train Loss=1.5353, Acc=0.2910, F1=0.2902 | Val Loss=1.4636, Acc=0.3529, F1=0.2958\n",
      "Epoch 04: Train Loss=1.4868, Acc=0.3445, F1=0.3423 | Val Loss=1.5828, Acc=0.2353, F1=0.1227\n",
      "Epoch 05: Train Loss=1.4779, Acc=0.3411, F1=0.3345 | Val Loss=1.4904, Acc=0.3529, F1=0.3145\n",
      "Epoch 06: Train Loss=1.4253, Acc=0.3311, F1=0.3274 | Val Loss=1.4283, Acc=0.3137, F1=0.2704\n",
      "Epoch 07: Train Loss=1.3563, Acc=0.4013, F1=0.3965 | Val Loss=1.4935, Acc=0.3529, F1=0.3175\n",
      "Epoch 08: Train Loss=1.3409, Acc=0.4515, F1=0.4506 | Val Loss=1.5073, Acc=0.4118, F1=0.3509\n",
      "Epoch 09: Train Loss=1.3521, Acc=0.4214, F1=0.4201 | Val Loss=1.5202, Acc=0.4118, F1=0.3849\n",
      "Epoch 10: Train Loss=1.2082, Acc=0.5151, F1=0.5110 | Val Loss=1.5069, Acc=0.3529, F1=0.3280\n",
      "Epoch 11: Train Loss=1.1862, Acc=0.4916, F1=0.4889 | Val Loss=1.5163, Acc=0.3922, F1=0.3412\n",
      "Epoch 12: Train Loss=1.1294, Acc=0.5819, F1=0.5801 | Val Loss=1.5722, Acc=0.3922, F1=0.3755\n",
      "Epoch 13: Train Loss=1.0111, Acc=0.5953, F1=0.5924 | Val Loss=1.6283, Acc=0.3529, F1=0.3313\n",
      "Epoch 14: Train Loss=0.8660, Acc=0.6789, F1=0.6765 | Val Loss=1.9862, Acc=0.3137, F1=0.3002\n",
      "Epoch 15: Train Loss=0.7569, Acc=0.6957, F1=0.6931 | Val Loss=1.5999, Acc=0.4706, F1=0.4698\n",
      "Epoch 16: Train Loss=0.6398, Acc=0.7726, F1=0.7718 | Val Loss=2.0903, Acc=0.4118, F1=0.3937\n",
      "Epoch 17: Train Loss=0.5301, Acc=0.8328, F1=0.8302 | Val Loss=2.2347, Acc=0.4706, F1=0.4511\n",
      "Epoch 18: Train Loss=0.4315, Acc=0.8395, F1=0.8387 | Val Loss=2.5168, Acc=0.3725, F1=0.3754\n",
      "Epoch 19: Train Loss=0.4292, Acc=0.8562, F1=0.8550 | Val Loss=2.1908, Acc=0.3529, F1=0.3483\n",
      "Epoch 20: Train Loss=0.3759, Acc=0.8763, F1=0.8747 | Val Loss=2.8226, Acc=0.3922, F1=0.3894\n",
      "Epoch 21: Train Loss=0.2909, Acc=0.9064, F1=0.9059 | Val Loss=2.9701, Acc=0.4510, F1=0.4209\n",
      "Epoch 22: Train Loss=0.2277, Acc=0.9465, F1=0.9463 | Val Loss=3.3767, Acc=0.4706, F1=0.4622\n",
      "Epoch 23: Train Loss=0.1226, Acc=0.9632, F1=0.9633 | Val Loss=3.8684, Acc=0.4314, F1=0.4334\n",
      "Epoch 24: Train Loss=0.1167, Acc=0.9699, F1=0.9697 | Val Loss=5.1555, Acc=0.3922, F1=0.3746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 21:59:59,833] Trial 12 finished with value: 0.47058823529411764 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00010752119651179309, 'weight_decay': 0.0001234433488463974}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=0.1472, Acc=0.9532, F1=0.9531 | Val Loss=4.7224, Acc=0.3725, F1=0.3810\n",
      "Early stopping\n",
      "\n",
      "[trial 13] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.7090, Acc=0.2676, F1=0.2665 | Val Loss=1.6211, Acc=0.3529, F1=0.2731\n",
      "Epoch 02: Train Loss=1.6040, Acc=0.2977, F1=0.2949 | Val Loss=1.4585, Acc=0.3333, F1=0.2823\n",
      "Epoch 03: Train Loss=1.4819, Acc=0.3378, F1=0.3293 | Val Loss=1.4740, Acc=0.4118, F1=0.3684\n",
      "Epoch 04: Train Loss=1.5226, Acc=0.3077, F1=0.3053 | Val Loss=1.5504, Acc=0.3137, F1=0.2298\n",
      "Epoch 05: Train Loss=1.4839, Acc=0.3579, F1=0.3485 | Val Loss=1.5649, Acc=0.2353, F1=0.1590\n",
      "Epoch 06: Train Loss=1.4589, Acc=0.3512, F1=0.3526 | Val Loss=1.4376, Acc=0.3137, F1=0.2904\n",
      "Epoch 07: Train Loss=1.4205, Acc=0.3746, F1=0.3691 | Val Loss=1.4846, Acc=0.3333, F1=0.2764\n",
      "Epoch 08: Train Loss=1.4093, Acc=0.3946, F1=0.3846 | Val Loss=1.3929, Acc=0.3333, F1=0.3166\n",
      "Epoch 09: Train Loss=1.3323, Acc=0.4381, F1=0.4357 | Val Loss=1.4663, Acc=0.2941, F1=0.2829\n",
      "Epoch 10: Train Loss=1.2268, Acc=0.5050, F1=0.4991 | Val Loss=1.4389, Acc=0.4314, F1=0.3715\n",
      "Epoch 11: Train Loss=1.1158, Acc=0.5251, F1=0.5236 | Val Loss=1.5071, Acc=0.2941, F1=0.2525\n",
      "Epoch 12: Train Loss=0.9888, Acc=0.6087, F1=0.6073 | Val Loss=1.6408, Acc=0.3529, F1=0.3211\n",
      "Epoch 13: Train Loss=0.9076, Acc=0.6455, F1=0.6449 | Val Loss=1.7596, Acc=0.3922, F1=0.3761\n",
      "Epoch 14: Train Loss=0.7474, Acc=0.7324, F1=0.7331 | Val Loss=1.6413, Acc=0.3922, F1=0.3931\n",
      "Epoch 15: Train Loss=0.6871, Acc=0.7659, F1=0.7623 | Val Loss=1.8175, Acc=0.3922, F1=0.3394\n",
      "Epoch 16: Train Loss=0.5247, Acc=0.8294, F1=0.8298 | Val Loss=1.9371, Acc=0.4118, F1=0.4070\n",
      "Epoch 17: Train Loss=0.5810, Acc=0.7860, F1=0.7846 | Val Loss=2.2467, Acc=0.4314, F1=0.4465\n",
      "Epoch 18: Train Loss=0.3284, Acc=0.8963, F1=0.8962 | Val Loss=2.1969, Acc=0.5098, F1=0.4984\n",
      "Epoch 19: Train Loss=0.2979, Acc=0.8763, F1=0.8761 | Val Loss=3.4062, Acc=0.4706, F1=0.4343\n",
      "Epoch 20: Train Loss=0.2582, Acc=0.9164, F1=0.9162 | Val Loss=2.9522, Acc=0.4706, F1=0.4732\n",
      "Epoch 21: Train Loss=0.2286, Acc=0.9331, F1=0.9330 | Val Loss=2.9931, Acc=0.5294, F1=0.4701\n",
      "Epoch 22: Train Loss=0.1345, Acc=0.9498, F1=0.9500 | Val Loss=3.2268, Acc=0.4706, F1=0.4684\n",
      "Epoch 23: Train Loss=0.0938, Acc=0.9666, F1=0.9666 | Val Loss=3.1734, Acc=0.5294, F1=0.5235\n",
      "Epoch 24: Train Loss=0.1049, Acc=0.9599, F1=0.9600 | Val Loss=4.1262, Acc=0.4314, F1=0.4216\n",
      "Epoch 25: Train Loss=0.1005, Acc=0.9732, F1=0.9732 | Val Loss=4.2607, Acc=0.4314, F1=0.4209\n",
      "Epoch 26: Train Loss=0.0302, Acc=0.9933, F1=0.9933 | Val Loss=4.2842, Acc=0.4510, F1=0.4576\n",
      "Epoch 27: Train Loss=0.0604, Acc=0.9766, F1=0.9766 | Val Loss=4.4703, Acc=0.4510, F1=0.4389\n",
      "Epoch 28: Train Loss=0.0261, Acc=0.9866, F1=0.9866 | Val Loss=4.7742, Acc=0.4314, F1=0.4216\n",
      "Epoch 29: Train Loss=0.0297, Acc=0.9933, F1=0.9933 | Val Loss=4.1977, Acc=0.4902, F1=0.4673\n",
      "Epoch 30: Train Loss=0.0286, Acc=0.9900, F1=0.9898 | Val Loss=3.9484, Acc=0.4510, F1=0.4453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:02:15,621] Trial 13 finished with value: 0.5294117647058824 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00011531894892803138, 'weight_decay': 0.00011437759657785997}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=0.0413, Acc=0.9799, F1=0.9800 | Val Loss=4.8015, Acc=0.4314, F1=0.4038\n",
      "Early stopping\n",
      "\n",
      "[trial 14] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.8847, Acc=0.2609, F1=0.2536 | Val Loss=1.8439, Acc=0.2157, F1=0.0977\n",
      "Epoch 02: Train Loss=1.6334, Acc=0.2742, F1=0.2682 | Val Loss=1.9299, Acc=0.2157, F1=0.0721\n",
      "Epoch 03: Train Loss=1.5955, Acc=0.2943, F1=0.2911 | Val Loss=1.4789, Acc=0.2941, F1=0.2543\n",
      "Epoch 04: Train Loss=1.5411, Acc=0.2508, F1=0.2465 | Val Loss=1.5392, Acc=0.2353, F1=0.1920\n",
      "Epoch 05: Train Loss=1.4575, Acc=0.3579, F1=0.3570 | Val Loss=1.4533, Acc=0.3725, F1=0.3235\n",
      "Epoch 06: Train Loss=1.4594, Acc=0.3177, F1=0.3142 | Val Loss=1.4596, Acc=0.3137, F1=0.2720\n",
      "Epoch 07: Train Loss=1.4252, Acc=0.3445, F1=0.3397 | Val Loss=1.4407, Acc=0.3725, F1=0.3032\n",
      "Epoch 08: Train Loss=1.4069, Acc=0.3712, F1=0.3675 | Val Loss=1.4172, Acc=0.4118, F1=0.3706\n",
      "Epoch 09: Train Loss=1.4245, Acc=0.3645, F1=0.3588 | Val Loss=1.3883, Acc=0.3725, F1=0.3698\n",
      "Epoch 10: Train Loss=1.3617, Acc=0.3846, F1=0.3778 | Val Loss=1.5151, Acc=0.3725, F1=0.2824\n",
      "Epoch 11: Train Loss=1.3751, Acc=0.4214, F1=0.4151 | Val Loss=1.5150, Acc=0.3333, F1=0.2794\n",
      "Epoch 12: Train Loss=1.3529, Acc=0.4013, F1=0.3982 | Val Loss=1.3510, Acc=0.4118, F1=0.4072\n",
      "Epoch 13: Train Loss=1.3015, Acc=0.3946, F1=0.3862 | Val Loss=1.3932, Acc=0.3725, F1=0.3645\n",
      "Epoch 14: Train Loss=1.2196, Acc=0.5184, F1=0.5168 | Val Loss=1.4036, Acc=0.3922, F1=0.3794\n",
      "Epoch 15: Train Loss=1.2140, Acc=0.4682, F1=0.4689 | Val Loss=1.4281, Acc=0.3725, F1=0.3484\n",
      "Epoch 16: Train Loss=1.1655, Acc=0.5385, F1=0.5366 | Val Loss=1.3696, Acc=0.3725, F1=0.3707\n",
      "Epoch 17: Train Loss=1.1232, Acc=0.5619, F1=0.5565 | Val Loss=1.3980, Acc=0.3725, F1=0.3527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:03:32,822] Trial 14 finished with value: 0.4117647058823529 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.0002583605014014802, 'weight_decay': 0.00037372800583511184}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=1.0474, Acc=0.5385, F1=0.5361 | Val Loss=1.4693, Acc=0.2941, F1=0.2909\n",
      "Early stopping\n",
      "\n",
      "[trial 15] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9805, Acc=0.2876, F1=0.2856 | Val Loss=1.6373, Acc=0.3529, F1=0.2296\n",
      "Epoch 02: Train Loss=1.5525, Acc=0.3043, F1=0.3054 | Val Loss=1.4985, Acc=0.2745, F1=0.1849\n",
      "Epoch 03: Train Loss=1.5295, Acc=0.3211, F1=0.3094 | Val Loss=1.4932, Acc=0.3137, F1=0.1857\n",
      "Epoch 04: Train Loss=1.5132, Acc=0.3378, F1=0.3308 | Val Loss=1.5446, Acc=0.3137, F1=0.2461\n",
      "Epoch 05: Train Loss=1.4578, Acc=0.3746, F1=0.3747 | Val Loss=1.5161, Acc=0.3333, F1=0.2619\n",
      "Epoch 06: Train Loss=1.4431, Acc=0.3579, F1=0.3581 | Val Loss=1.5764, Acc=0.3529, F1=0.3106\n",
      "Epoch 07: Train Loss=1.3665, Acc=0.3880, F1=0.3836 | Val Loss=1.5406, Acc=0.3725, F1=0.3155\n",
      "Epoch 08: Train Loss=1.2704, Acc=0.4348, F1=0.4347 | Val Loss=1.4784, Acc=0.3529, F1=0.2897\n",
      "Epoch 09: Train Loss=1.1779, Acc=0.5050, F1=0.5034 | Val Loss=1.5909, Acc=0.3333, F1=0.2792\n",
      "Epoch 10: Train Loss=1.1456, Acc=0.5385, F1=0.5378 | Val Loss=1.7688, Acc=0.3725, F1=0.3611\n",
      "Epoch 11: Train Loss=1.0895, Acc=0.5585, F1=0.5572 | Val Loss=1.6598, Acc=0.4118, F1=0.4044\n",
      "Epoch 12: Train Loss=1.0441, Acc=0.5886, F1=0.5883 | Val Loss=1.7615, Acc=0.3922, F1=0.3661\n",
      "Epoch 13: Train Loss=0.8660, Acc=0.6722, F1=0.6695 | Val Loss=1.7607, Acc=0.4314, F1=0.4155\n",
      "Epoch 14: Train Loss=0.7563, Acc=0.7157, F1=0.7152 | Val Loss=2.0633, Acc=0.3922, F1=0.3675\n",
      "Epoch 15: Train Loss=0.7442, Acc=0.7525, F1=0.7518 | Val Loss=2.3492, Acc=0.3529, F1=0.3605\n",
      "Epoch 16: Train Loss=0.6122, Acc=0.7592, F1=0.7595 | Val Loss=2.8110, Acc=0.3333, F1=0.3188\n",
      "Epoch 17: Train Loss=0.5067, Acc=0.8395, F1=0.8393 | Val Loss=2.5015, Acc=0.4314, F1=0.4238\n",
      "Epoch 18: Train Loss=0.3742, Acc=0.8829, F1=0.8835 | Val Loss=3.1170, Acc=0.4118, F1=0.4021\n",
      "Epoch 19: Train Loss=0.6927, Acc=0.8060, F1=0.8065 | Val Loss=3.3836, Acc=0.3529, F1=0.3336\n",
      "Epoch 20: Train Loss=0.3537, Acc=0.9030, F1=0.9033 | Val Loss=3.2073, Acc=0.4902, F1=0.4650\n",
      "Epoch 21: Train Loss=0.2265, Acc=0.9365, F1=0.9364 | Val Loss=3.3155, Acc=0.4510, F1=0.4295\n",
      "Epoch 22: Train Loss=0.2602, Acc=0.9298, F1=0.9298 | Val Loss=4.5652, Acc=0.3725, F1=0.3723\n",
      "Epoch 23: Train Loss=0.2513, Acc=0.9164, F1=0.9162 | Val Loss=4.3171, Acc=0.3333, F1=0.3351\n",
      "Epoch 24: Train Loss=0.1007, Acc=0.9732, F1=0.9733 | Val Loss=4.2308, Acc=0.4314, F1=0.4138\n",
      "Epoch 25: Train Loss=0.1275, Acc=0.9599, F1=0.9600 | Val Loss=4.5816, Acc=0.4118, F1=0.4034\n",
      "Epoch 26: Train Loss=0.0643, Acc=0.9866, F1=0.9865 | Val Loss=4.5306, Acc=0.4706, F1=0.4522\n",
      "Epoch 27: Train Loss=0.0562, Acc=0.9732, F1=0.9734 | Val Loss=4.5459, Acc=0.5294, F1=0.5259\n",
      "Epoch 28: Train Loss=0.0399, Acc=0.9967, F1=0.9967 | Val Loss=4.8478, Acc=0.5098, F1=0.4867\n",
      "Epoch 29: Train Loss=0.0326, Acc=0.9866, F1=0.9866 | Val Loss=5.1539, Acc=0.4314, F1=0.4182\n",
      "Epoch 30: Train Loss=0.1643, Acc=0.9599, F1=0.9599 | Val Loss=6.0070, Acc=0.4118, F1=0.3721\n",
      "Epoch 31: Train Loss=0.1456, Acc=0.9599, F1=0.9598 | Val Loss=5.7346, Acc=0.4510, F1=0.4164\n",
      "Epoch 32: Train Loss=0.1170, Acc=0.9732, F1=0.9732 | Val Loss=5.0943, Acc=0.4118, F1=0.3914\n",
      "Epoch 33: Train Loss=0.0893, Acc=0.9732, F1=0.9732 | Val Loss=5.8590, Acc=0.3725, F1=0.3537\n",
      "Epoch 34: Train Loss=0.0924, Acc=0.9866, F1=0.9866 | Val Loss=5.4143, Acc=0.4510, F1=0.4593\n",
      "Epoch 35: Train Loss=0.0680, Acc=0.9799, F1=0.9799 | Val Loss=5.0681, Acc=0.4314, F1=0.4141\n",
      "Epoch 36: Train Loss=0.1086, Acc=0.9732, F1=0.9733 | Val Loss=5.9568, Acc=0.3922, F1=0.3620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:06:10,802] Trial 15 finished with value: 0.5294117647058824 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00022545502715832472, 'weight_decay': 6.541822415477904e-05}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss=0.0243, Acc=0.9900, F1=0.9899 | Val Loss=6.0436, Acc=0.3529, F1=0.3333\n",
      "Early stopping\n",
      "\n",
      "[trial 16] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.7539, Acc=0.2408, F1=0.2400 | Val Loss=1.5658, Acc=0.3333, F1=0.2924\n",
      "Epoch 02: Train Loss=1.5428, Acc=0.2977, F1=0.2973 | Val Loss=1.5143, Acc=0.3725, F1=0.2864\n",
      "Epoch 03: Train Loss=1.4965, Acc=0.3411, F1=0.3315 | Val Loss=1.5441, Acc=0.2941, F1=0.1785\n",
      "Epoch 04: Train Loss=1.4466, Acc=0.3679, F1=0.3646 | Val Loss=1.5545, Acc=0.2745, F1=0.1599\n",
      "Epoch 05: Train Loss=1.4096, Acc=0.3813, F1=0.3785 | Val Loss=1.4481, Acc=0.3529, F1=0.2992\n",
      "Epoch 06: Train Loss=1.3416, Acc=0.4013, F1=0.4021 | Val Loss=1.4215, Acc=0.3725, F1=0.3309\n",
      "Epoch 07: Train Loss=1.2656, Acc=0.4716, F1=0.4673 | Val Loss=1.4632, Acc=0.3922, F1=0.3520\n",
      "Epoch 08: Train Loss=1.2387, Acc=0.4515, F1=0.4478 | Val Loss=1.4394, Acc=0.3725, F1=0.3392\n",
      "Epoch 09: Train Loss=1.1820, Acc=0.5184, F1=0.5190 | Val Loss=1.4239, Acc=0.4314, F1=0.4125\n",
      "Epoch 10: Train Loss=1.0780, Acc=0.5753, F1=0.5706 | Val Loss=1.5871, Acc=0.3922, F1=0.3624\n",
      "Epoch 11: Train Loss=1.0027, Acc=0.6087, F1=0.6059 | Val Loss=1.4256, Acc=0.4314, F1=0.4175\n",
      "Epoch 12: Train Loss=0.8389, Acc=0.6722, F1=0.6714 | Val Loss=1.5735, Acc=0.4118, F1=0.3887\n",
      "Epoch 13: Train Loss=0.7870, Acc=0.6957, F1=0.6918 | Val Loss=1.6767, Acc=0.4706, F1=0.4466\n",
      "Epoch 14: Train Loss=0.7220, Acc=0.7492, F1=0.7493 | Val Loss=1.8084, Acc=0.3725, F1=0.3691\n",
      "Epoch 15: Train Loss=0.6424, Acc=0.7625, F1=0.7622 | Val Loss=1.7423, Acc=0.4902, F1=0.4641\n",
      "Epoch 16: Train Loss=0.5075, Acc=0.8161, F1=0.8153 | Val Loss=2.0083, Acc=0.4706, F1=0.4562\n",
      "Epoch 17: Train Loss=0.4289, Acc=0.8361, F1=0.8363 | Val Loss=2.0825, Acc=0.4706, F1=0.4772\n",
      "Epoch 18: Train Loss=0.3685, Acc=0.8863, F1=0.8864 | Val Loss=2.7232, Acc=0.4118, F1=0.3877\n",
      "Epoch 19: Train Loss=0.3028, Acc=0.8930, F1=0.8930 | Val Loss=3.1197, Acc=0.4510, F1=0.4446\n",
      "Epoch 20: Train Loss=0.2591, Acc=0.9298, F1=0.9299 | Val Loss=3.2668, Acc=0.5098, F1=0.5067\n",
      "Epoch 21: Train Loss=0.1739, Acc=0.9398, F1=0.9399 | Val Loss=4.2094, Acc=0.4510, F1=0.4475\n",
      "Epoch 22: Train Loss=0.1220, Acc=0.9565, F1=0.9567 | Val Loss=3.6981, Acc=0.4706, F1=0.4638\n",
      "Epoch 23: Train Loss=0.0842, Acc=0.9666, F1=0.9665 | Val Loss=4.4190, Acc=0.4902, F1=0.4906\n",
      "Epoch 24: Train Loss=0.0964, Acc=0.9599, F1=0.9598 | Val Loss=4.3192, Acc=0.4706, F1=0.4506\n",
      "Epoch 25: Train Loss=0.0549, Acc=0.9799, F1=0.9799 | Val Loss=4.8118, Acc=0.4706, F1=0.4497\n",
      "Epoch 26: Train Loss=0.0357, Acc=0.9866, F1=0.9867 | Val Loss=4.5325, Acc=0.5098, F1=0.5133\n",
      "Epoch 27: Train Loss=0.0470, Acc=0.9900, F1=0.9900 | Val Loss=4.4669, Acc=0.4706, F1=0.4570\n",
      "Epoch 28: Train Loss=0.0173, Acc=0.9933, F1=0.9933 | Val Loss=4.7995, Acc=0.4902, F1=0.4907\n",
      "Epoch 29: Train Loss=0.0155, Acc=0.9967, F1=0.9966 | Val Loss=4.8388, Acc=0.4314, F1=0.4256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:07:26,115] Trial 16 finished with value: 0.5098039215686274 and parameters: {'nhead': 4, 'num_layers': 1, 'lr': 0.000163933989301113, 'weight_decay': 4.565594045445848e-05}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=0.0100, Acc=0.9933, F1=0.9934 | Val Loss=4.6522, Acc=0.4706, F1=0.4603\n",
      "Early stopping\n",
      "\n",
      "[trial 17] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.0479, Acc=0.2977, F1=0.2983 | Val Loss=1.5824, Acc=0.3529, F1=0.2022\n",
      "Epoch 02: Train Loss=1.6811, Acc=0.2876, F1=0.2854 | Val Loss=1.5993, Acc=0.3137, F1=0.1877\n",
      "Epoch 03: Train Loss=1.5858, Acc=0.2676, F1=0.2664 | Val Loss=1.6329, Acc=0.2941, F1=0.2533\n",
      "Epoch 04: Train Loss=1.5503, Acc=0.2843, F1=0.2783 | Val Loss=1.4825, Acc=0.3137, F1=0.2409\n",
      "Epoch 05: Train Loss=1.5785, Acc=0.3077, F1=0.2984 | Val Loss=1.5009, Acc=0.2941, F1=0.2330\n",
      "Epoch 06: Train Loss=1.5053, Acc=0.3344, F1=0.3285 | Val Loss=1.5992, Acc=0.1961, F1=0.1704\n",
      "Epoch 07: Train Loss=1.4957, Acc=0.3110, F1=0.3001 | Val Loss=1.4087, Acc=0.3725, F1=0.3731\n",
      "Epoch 08: Train Loss=1.4440, Acc=0.3445, F1=0.3441 | Val Loss=1.5142, Acc=0.2941, F1=0.1789\n",
      "Epoch 09: Train Loss=1.4367, Acc=0.3344, F1=0.3302 | Val Loss=1.4108, Acc=0.3725, F1=0.3108\n",
      "Epoch 10: Train Loss=1.4056, Acc=0.3846, F1=0.3621 | Val Loss=1.4996, Acc=0.3137, F1=0.2374\n",
      "Epoch 11: Train Loss=1.4146, Acc=0.3712, F1=0.3592 | Val Loss=1.4452, Acc=0.3922, F1=0.3303\n",
      "Epoch 12: Train Loss=1.3320, Acc=0.4013, F1=0.3917 | Val Loss=1.3839, Acc=0.3529, F1=0.3179\n",
      "Epoch 13: Train Loss=1.3317, Acc=0.4181, F1=0.4136 | Val Loss=1.4468, Acc=0.2549, F1=0.2353\n",
      "Epoch 14: Train Loss=1.3134, Acc=0.4181, F1=0.4153 | Val Loss=1.4530, Acc=0.3922, F1=0.3823\n",
      "Epoch 15: Train Loss=1.2935, Acc=0.4381, F1=0.4274 | Val Loss=1.3821, Acc=0.3137, F1=0.3061\n",
      "Epoch 16: Train Loss=1.2882, Acc=0.4314, F1=0.4274 | Val Loss=1.5128, Acc=0.2941, F1=0.2477\n",
      "Epoch 17: Train Loss=1.2671, Acc=0.4314, F1=0.4278 | Val Loss=1.4713, Acc=0.3922, F1=0.2801\n",
      "Epoch 18: Train Loss=1.1999, Acc=0.5017, F1=0.5017 | Val Loss=1.5848, Acc=0.3922, F1=0.3263\n",
      "Epoch 19: Train Loss=1.1877, Acc=0.4816, F1=0.4762 | Val Loss=1.4128, Acc=0.4510, F1=0.3908\n",
      "Epoch 20: Train Loss=1.1643, Acc=0.4883, F1=0.4807 | Val Loss=1.4375, Acc=0.4510, F1=0.4030\n",
      "Epoch 21: Train Loss=1.1339, Acc=0.5084, F1=0.5006 | Val Loss=1.4772, Acc=0.4706, F1=0.4238\n",
      "Epoch 22: Train Loss=1.0940, Acc=0.5953, F1=0.5934 | Val Loss=1.3224, Acc=0.4902, F1=0.4553\n",
      "Epoch 23: Train Loss=1.0548, Acc=0.5619, F1=0.5593 | Val Loss=1.2573, Acc=0.5098, F1=0.4676\n",
      "Epoch 24: Train Loss=0.9210, Acc=0.6154, F1=0.6134 | Val Loss=1.7009, Acc=0.2941, F1=0.2368\n",
      "Epoch 25: Train Loss=0.9224, Acc=0.6421, F1=0.6412 | Val Loss=1.9579, Acc=0.2941, F1=0.3053\n",
      "Epoch 26: Train Loss=0.8736, Acc=0.6589, F1=0.6588 | Val Loss=1.6092, Acc=0.4706, F1=0.4207\n",
      "Epoch 27: Train Loss=0.8837, Acc=0.6522, F1=0.6505 | Val Loss=1.6783, Acc=0.4510, F1=0.4226\n",
      "Epoch 28: Train Loss=0.7353, Acc=0.7057, F1=0.7034 | Val Loss=1.7173, Acc=0.3922, F1=0.3463\n",
      "Epoch 29: Train Loss=0.6974, Acc=0.7157, F1=0.7167 | Val Loss=1.9260, Acc=0.3529, F1=0.3624\n",
      "Epoch 30: Train Loss=0.7716, Acc=0.7157, F1=0.7155 | Val Loss=1.9888, Acc=0.2941, F1=0.2748\n",
      "Epoch 31: Train Loss=0.7466, Acc=0.7592, F1=0.7584 | Val Loss=1.7709, Acc=0.3922, F1=0.3771\n",
      "Epoch 32: Train Loss=0.5342, Acc=0.7759, F1=0.7757 | Val Loss=2.2918, Acc=0.4118, F1=0.4310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:09:45,830] Trial 17 finished with value: 0.5098039215686274 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.0004424521231538716, 'weight_decay': 0.0002556416830707334}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss=0.5023, Acc=0.8194, F1=0.8195 | Val Loss=2.9215, Acc=0.3725, F1=0.3010\n",
      "Early stopping\n",
      "\n",
      "[trial 18] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.4791, Acc=0.1873, F1=0.1860 | Val Loss=2.3252, Acc=0.2157, F1=0.0710\n",
      "Epoch 02: Train Loss=1.8586, Acc=0.2007, F1=0.1938 | Val Loss=1.7607, Acc=0.1961, F1=0.0656\n",
      "Epoch 03: Train Loss=1.8595, Acc=0.1739, F1=0.1660 | Val Loss=1.6485, Acc=0.2157, F1=0.0710\n",
      "Epoch 04: Train Loss=1.7219, Acc=0.1906, F1=0.1895 | Val Loss=1.6365, Acc=0.1961, F1=0.0656\n",
      "Epoch 05: Train Loss=1.6644, Acc=0.1873, F1=0.1784 | Val Loss=1.6148, Acc=0.1961, F1=0.0656\n",
      "Epoch 06: Train Loss=1.7200, Acc=0.1906, F1=0.1861 | Val Loss=1.6986, Acc=0.1961, F1=0.0656\n",
      "Epoch 07: Train Loss=1.6485, Acc=0.1940, F1=0.1685 | Val Loss=1.6112, Acc=0.1961, F1=0.0656\n",
      "Epoch 08: Train Loss=1.6234, Acc=0.2241, F1=0.2189 | Val Loss=1.6151, Acc=0.2157, F1=0.0710\n",
      "Epoch 09: Train Loss=1.6312, Acc=0.1940, F1=0.1762 | Val Loss=1.6206, Acc=0.1961, F1=0.0656\n",
      "Epoch 10: Train Loss=1.6237, Acc=0.1973, F1=0.1855 | Val Loss=1.6347, Acc=0.1961, F1=0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:10:54,160] Trial 18 finished with value: 0.21568627450980393 and parameters: {'nhead': 8, 'num_layers': 3, 'lr': 0.0037827652380096233, 'weight_decay': 1.24711681871665e-05}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=1.6231, Acc=0.1973, F1=0.1620 | Val Loss=1.6437, Acc=0.1961, F1=0.0656\n",
      "Early stopping\n",
      "\n",
      "[trial 19] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9018, Acc=0.2475, F1=0.2451 | Val Loss=1.5127, Acc=0.3922, F1=0.3231\n",
      "Epoch 02: Train Loss=1.5362, Acc=0.3478, F1=0.3439 | Val Loss=1.5826, Acc=0.2745, F1=0.2512\n",
      "Epoch 03: Train Loss=1.4975, Acc=0.3244, F1=0.3195 | Val Loss=1.4618, Acc=0.4118, F1=0.3523\n",
      "Epoch 04: Train Loss=1.4812, Acc=0.3278, F1=0.3259 | Val Loss=1.4647, Acc=0.3922, F1=0.2937\n",
      "Epoch 05: Train Loss=1.4493, Acc=0.3411, F1=0.3271 | Val Loss=1.5996, Acc=0.2549, F1=0.1514\n",
      "Epoch 06: Train Loss=1.4414, Acc=0.3579, F1=0.3592 | Val Loss=1.4733, Acc=0.3333, F1=0.2493\n",
      "Epoch 07: Train Loss=1.4111, Acc=0.3880, F1=0.3733 | Val Loss=1.4386, Acc=0.3529, F1=0.3283\n",
      "Epoch 08: Train Loss=1.3829, Acc=0.4013, F1=0.3989 | Val Loss=1.4720, Acc=0.2941, F1=0.2008\n",
      "Epoch 09: Train Loss=1.3724, Acc=0.3679, F1=0.3634 | Val Loss=1.4566, Acc=0.3529, F1=0.3033\n",
      "Epoch 10: Train Loss=1.4044, Acc=0.3712, F1=0.3714 | Val Loss=1.3923, Acc=0.3333, F1=0.3254\n",
      "Epoch 11: Train Loss=1.3612, Acc=0.4147, F1=0.4093 | Val Loss=1.4319, Acc=0.4118, F1=0.3744\n",
      "Epoch 12: Train Loss=1.3710, Acc=0.3579, F1=0.3528 | Val Loss=1.4442, Acc=0.2745, F1=0.2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:11:26,258] Trial 19 finished with value: 0.4117647058823529 and parameters: {'nhead': 4, 'num_layers': 1, 'lr': 0.00041359362575230096, 'weight_decay': 0.0009728613904848122}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.3547, Acc=0.4047, F1=0.4013 | Val Loss=1.4051, Acc=0.3137, F1=0.2991\n",
      "Early stopping\n",
      "\n",
      "[trial 20] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.7680, Acc=0.2943, F1=0.2914 | Val Loss=1.6818, Acc=0.2941, F1=0.1937\n",
      "Epoch 02: Train Loss=1.5716, Acc=0.3144, F1=0.3126 | Val Loss=1.5485, Acc=0.3922, F1=0.3128\n",
      "Epoch 03: Train Loss=1.4902, Acc=0.3579, F1=0.3532 | Val Loss=1.5599, Acc=0.3333, F1=0.2450\n",
      "Epoch 04: Train Loss=1.5289, Acc=0.3043, F1=0.3011 | Val Loss=1.5844, Acc=0.2549, F1=0.1973\n",
      "Epoch 05: Train Loss=1.5090, Acc=0.3110, F1=0.3087 | Val Loss=1.4727, Acc=0.3137, F1=0.3208\n",
      "Epoch 06: Train Loss=1.4525, Acc=0.3846, F1=0.3737 | Val Loss=1.5189, Acc=0.3333, F1=0.2361\n",
      "Epoch 07: Train Loss=1.4293, Acc=0.4013, F1=0.3978 | Val Loss=1.4860, Acc=0.3922, F1=0.3327\n",
      "Epoch 08: Train Loss=1.4114, Acc=0.3746, F1=0.3651 | Val Loss=1.4375, Acc=0.3725, F1=0.3421\n",
      "Epoch 09: Train Loss=1.4460, Acc=0.3445, F1=0.3444 | Val Loss=1.4544, Acc=0.3333, F1=0.3042\n",
      "Epoch 10: Train Loss=1.3622, Acc=0.3980, F1=0.3975 | Val Loss=1.5035, Acc=0.3529, F1=0.2606\n",
      "Epoch 11: Train Loss=1.3186, Acc=0.4114, F1=0.4046 | Val Loss=1.4300, Acc=0.3137, F1=0.2786\n",
      "Epoch 12: Train Loss=1.2517, Acc=0.4515, F1=0.4433 | Val Loss=1.5210, Acc=0.4118, F1=0.3868\n",
      "Epoch 13: Train Loss=1.1963, Acc=0.5117, F1=0.5098 | Val Loss=1.4820, Acc=0.3725, F1=0.3353\n",
      "Epoch 14: Train Loss=1.1156, Acc=0.5084, F1=0.5071 | Val Loss=1.5644, Acc=0.4314, F1=0.3931\n",
      "Epoch 15: Train Loss=1.1353, Acc=0.5518, F1=0.5500 | Val Loss=1.6555, Acc=0.3333, F1=0.2700\n",
      "Epoch 16: Train Loss=0.9812, Acc=0.6154, F1=0.6117 | Val Loss=1.4821, Acc=0.4706, F1=0.4474\n",
      "Epoch 17: Train Loss=0.9978, Acc=0.6288, F1=0.6233 | Val Loss=1.6858, Acc=0.3137, F1=0.2694\n",
      "Epoch 18: Train Loss=0.8003, Acc=0.7224, F1=0.7205 | Val Loss=1.7504, Acc=0.4314, F1=0.3921\n",
      "Epoch 19: Train Loss=0.7385, Acc=0.7124, F1=0.7127 | Val Loss=1.4525, Acc=0.4902, F1=0.4610\n",
      "Epoch 20: Train Loss=0.5720, Acc=0.7692, F1=0.7682 | Val Loss=1.7768, Acc=0.4902, F1=0.4885\n",
      "Epoch 21: Train Loss=0.5469, Acc=0.7993, F1=0.7982 | Val Loss=1.9924, Acc=0.4118, F1=0.4055\n",
      "Epoch 22: Train Loss=0.5579, Acc=0.7793, F1=0.7783 | Val Loss=2.0857, Acc=0.4706, F1=0.4407\n",
      "Epoch 23: Train Loss=0.3819, Acc=0.8629, F1=0.8620 | Val Loss=2.3126, Acc=0.4510, F1=0.4259\n",
      "Epoch 24: Train Loss=0.3079, Acc=0.8696, F1=0.8684 | Val Loss=3.6317, Acc=0.4314, F1=0.3692\n",
      "Epoch 25: Train Loss=0.3566, Acc=0.8696, F1=0.8701 | Val Loss=2.7927, Acc=0.4706, F1=0.4235\n",
      "Epoch 26: Train Loss=0.3258, Acc=0.8829, F1=0.8826 | Val Loss=2.7135, Acc=0.4510, F1=0.4107\n",
      "Epoch 27: Train Loss=0.2153, Acc=0.9264, F1=0.9260 | Val Loss=3.1594, Acc=0.4118, F1=0.3863\n",
      "Epoch 28: Train Loss=0.2326, Acc=0.9197, F1=0.9188 | Val Loss=3.7837, Acc=0.3725, F1=0.3632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:13:30,530] Trial 20 finished with value: 0.49019607843137253 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00013953416755976746, 'weight_decay': 0.0002836689484186475}. Best is trial 11 with value: 0.5490196078431373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss=0.1873, Acc=0.9398, F1=0.9399 | Val Loss=3.3258, Acc=0.4118, F1=0.3917\n",
      "Early stopping\n",
      "\n",
      "[trial 21] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.7177, Acc=0.3278, F1=0.3248 | Val Loss=1.6008, Acc=0.3137, F1=0.2090\n",
      "Epoch 02: Train Loss=1.5589, Acc=0.3043, F1=0.3020 | Val Loss=1.6057, Acc=0.2745, F1=0.1580\n",
      "Epoch 03: Train Loss=1.5259, Acc=0.3278, F1=0.3201 | Val Loss=1.5798, Acc=0.2941, F1=0.1685\n",
      "Epoch 04: Train Loss=1.4752, Acc=0.3344, F1=0.3281 | Val Loss=1.4663, Acc=0.3529, F1=0.3189\n",
      "Epoch 05: Train Loss=1.4956, Acc=0.3545, F1=0.3515 | Val Loss=1.4525, Acc=0.3333, F1=0.2792\n",
      "Epoch 06: Train Loss=1.4394, Acc=0.3579, F1=0.3563 | Val Loss=1.4531, Acc=0.3137, F1=0.2335\n",
      "Epoch 07: Train Loss=1.4007, Acc=0.3913, F1=0.3915 | Val Loss=1.6243, Acc=0.3725, F1=0.2885\n",
      "Epoch 08: Train Loss=1.4311, Acc=0.3746, F1=0.3699 | Val Loss=1.4493, Acc=0.3922, F1=0.3752\n",
      "Epoch 09: Train Loss=1.2605, Acc=0.4482, F1=0.4393 | Val Loss=1.4493, Acc=0.4706, F1=0.3981\n",
      "Epoch 10: Train Loss=1.2099, Acc=0.5151, F1=0.5146 | Val Loss=1.3501, Acc=0.3922, F1=0.3666\n",
      "Epoch 11: Train Loss=1.1335, Acc=0.5585, F1=0.5500 | Val Loss=1.5329, Acc=0.3333, F1=0.3229\n",
      "Epoch 12: Train Loss=1.0905, Acc=0.5552, F1=0.5550 | Val Loss=1.2716, Acc=0.5294, F1=0.5225\n",
      "Epoch 13: Train Loss=0.9671, Acc=0.6154, F1=0.6156 | Val Loss=1.2886, Acc=0.5490, F1=0.5591\n",
      "Epoch 14: Train Loss=0.8501, Acc=0.6421, F1=0.6414 | Val Loss=1.7400, Acc=0.3529, F1=0.3165\n",
      "Epoch 15: Train Loss=0.8056, Acc=0.6856, F1=0.6837 | Val Loss=1.4608, Acc=0.5294, F1=0.5125\n",
      "Epoch 16: Train Loss=0.6038, Acc=0.7425, F1=0.7423 | Val Loss=1.6188, Acc=0.4706, F1=0.4762\n",
      "Epoch 17: Train Loss=0.4621, Acc=0.8361, F1=0.8354 | Val Loss=2.1421, Acc=0.4118, F1=0.4239\n",
      "Epoch 18: Train Loss=0.3963, Acc=0.8495, F1=0.8495 | Val Loss=2.0052, Acc=0.5294, F1=0.5267\n",
      "Epoch 19: Train Loss=0.4056, Acc=0.8395, F1=0.8389 | Val Loss=2.0779, Acc=0.4706, F1=0.4586\n",
      "Epoch 20: Train Loss=0.2774, Acc=0.9030, F1=0.9023 | Val Loss=2.6761, Acc=0.3922, F1=0.3952\n",
      "Epoch 21: Train Loss=0.2610, Acc=0.8930, F1=0.8929 | Val Loss=2.4957, Acc=0.5294, F1=0.5086\n",
      "Epoch 22: Train Loss=0.1681, Acc=0.9565, F1=0.9564 | Val Loss=3.4227, Acc=0.4510, F1=0.4757\n",
      "Epoch 23: Train Loss=0.1531, Acc=0.9565, F1=0.9564 | Val Loss=2.7257, Acc=0.5686, F1=0.5550\n",
      "Epoch 24: Train Loss=0.0467, Acc=0.9900, F1=0.9899 | Val Loss=3.6093, Acc=0.4510, F1=0.4442\n",
      "Epoch 25: Train Loss=0.0256, Acc=0.9967, F1=0.9967 | Val Loss=3.8215, Acc=0.4706, F1=0.4607\n",
      "Epoch 26: Train Loss=0.0277, Acc=0.9933, F1=0.9933 | Val Loss=3.9432, Acc=0.4902, F1=0.4620\n",
      "Epoch 27: Train Loss=0.0333, Acc=0.9833, F1=0.9833 | Val Loss=3.7307, Acc=0.4902, F1=0.4785\n",
      "Epoch 28: Train Loss=0.0304, Acc=0.9900, F1=0.9899 | Val Loss=4.2318, Acc=0.4118, F1=0.4222\n",
      "Epoch 29: Train Loss=0.0232, Acc=0.9900, F1=0.9900 | Val Loss=4.3341, Acc=0.5098, F1=0.5201\n",
      "Epoch 30: Train Loss=0.0375, Acc=0.9900, F1=0.9900 | Val Loss=5.0274, Acc=0.4118, F1=0.4027\n",
      "Epoch 31: Train Loss=0.1198, Acc=0.9632, F1=0.9631 | Val Loss=3.9431, Acc=0.4706, F1=0.4611\n",
      "Epoch 32: Train Loss=0.0405, Acc=0.9866, F1=0.9866 | Val Loss=4.7637, Acc=0.4706, F1=0.4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:15:53,723] Trial 21 finished with value: 0.5686274509803921 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00010434959787802714, 'weight_decay': 9.753615006446377e-05}. Best is trial 21 with value: 0.5686274509803921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss=0.0510, Acc=0.9866, F1=0.9866 | Val Loss=3.7077, Acc=0.4706, F1=0.4696\n",
      "Early stopping\n",
      "\n",
      "[trial 22] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.8595, Acc=0.2809, F1=0.2811 | Val Loss=1.7523, Acc=0.2549, F1=0.1867\n",
      "Epoch 02: Train Loss=1.6416, Acc=0.3311, F1=0.3287 | Val Loss=1.7572, Acc=0.3333, F1=0.1924\n",
      "Epoch 03: Train Loss=1.5339, Acc=0.3579, F1=0.3582 | Val Loss=1.5650, Acc=0.3333, F1=0.2543\n",
      "Epoch 04: Train Loss=1.5617, Acc=0.3043, F1=0.3027 | Val Loss=1.5530, Acc=0.2549, F1=0.1463\n",
      "Epoch 05: Train Loss=1.4303, Acc=0.3712, F1=0.3543 | Val Loss=1.5365, Acc=0.3529, F1=0.3000\n",
      "Epoch 06: Train Loss=1.4411, Acc=0.3980, F1=0.3977 | Val Loss=1.5153, Acc=0.3529, F1=0.2493\n",
      "Epoch 07: Train Loss=1.3623, Acc=0.4114, F1=0.4066 | Val Loss=1.4677, Acc=0.3529, F1=0.3304\n",
      "Epoch 08: Train Loss=1.3418, Acc=0.4214, F1=0.4178 | Val Loss=1.4352, Acc=0.4118, F1=0.3893\n",
      "Epoch 09: Train Loss=1.2424, Acc=0.4916, F1=0.4889 | Val Loss=1.4692, Acc=0.3529, F1=0.3304\n",
      "Epoch 10: Train Loss=1.1203, Acc=0.5585, F1=0.5581 | Val Loss=1.4054, Acc=0.4314, F1=0.4078\n",
      "Epoch 11: Train Loss=1.0156, Acc=0.5786, F1=0.5782 | Val Loss=1.5197, Acc=0.4510, F1=0.4355\n",
      "Epoch 12: Train Loss=0.9038, Acc=0.6656, F1=0.6645 | Val Loss=1.6176, Acc=0.4118, F1=0.4158\n",
      "Epoch 13: Train Loss=0.7974, Acc=0.6622, F1=0.6601 | Val Loss=1.6030, Acc=0.4118, F1=0.3995\n",
      "Epoch 14: Train Loss=0.7087, Acc=0.7659, F1=0.7655 | Val Loss=2.3261, Acc=0.4902, F1=0.4412\n",
      "Epoch 15: Train Loss=0.6444, Acc=0.7492, F1=0.7494 | Val Loss=1.7648, Acc=0.4314, F1=0.3972\n",
      "Epoch 16: Train Loss=0.3151, Acc=0.8729, F1=0.8727 | Val Loss=3.0611, Acc=0.3922, F1=0.3505\n",
      "Epoch 17: Train Loss=0.3655, Acc=0.8629, F1=0.8629 | Val Loss=2.9465, Acc=0.4118, F1=0.3911\n",
      "Epoch 18: Train Loss=0.2906, Acc=0.9097, F1=0.9092 | Val Loss=3.3880, Acc=0.4706, F1=0.4516\n",
      "Epoch 19: Train Loss=0.2391, Acc=0.9164, F1=0.9162 | Val Loss=3.7329, Acc=0.3333, F1=0.3005\n",
      "Epoch 20: Train Loss=0.2427, Acc=0.9331, F1=0.9330 | Val Loss=4.0555, Acc=0.4118, F1=0.4097\n",
      "Epoch 21: Train Loss=0.0816, Acc=0.9799, F1=0.9799 | Val Loss=3.9256, Acc=0.4314, F1=0.4243\n",
      "Epoch 22: Train Loss=0.0711, Acc=0.9699, F1=0.9699 | Val Loss=4.0371, Acc=0.4706, F1=0.4665\n",
      "Epoch 23: Train Loss=0.1647, Acc=0.9532, F1=0.9530 | Val Loss=4.1375, Acc=0.3725, F1=0.3684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:17:37,644] Trial 22 finished with value: 0.49019607843137253 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00017320214282304762, 'weight_decay': 6.144906551352695e-05}. Best is trial 21 with value: 0.5686274509803921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=0.0293, Acc=0.9900, F1=0.9899 | Val Loss=4.5415, Acc=0.4118, F1=0.3983\n",
      "Early stopping\n",
      "\n",
      "[trial 23] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.7971, Acc=0.2776, F1=0.2768 | Val Loss=1.6315, Acc=0.2549, F1=0.1706\n",
      "Epoch 02: Train Loss=1.5805, Acc=0.2843, F1=0.2814 | Val Loss=1.5069, Acc=0.3725, F1=0.3103\n",
      "Epoch 03: Train Loss=1.5109, Acc=0.3177, F1=0.3124 | Val Loss=1.4777, Acc=0.3333, F1=0.2215\n",
      "Epoch 04: Train Loss=1.4992, Acc=0.3445, F1=0.3423 | Val Loss=1.7239, Acc=0.2941, F1=0.2075\n",
      "Epoch 05: Train Loss=1.4824, Acc=0.3545, F1=0.3499 | Val Loss=1.5217, Acc=0.2353, F1=0.2086\n",
      "Epoch 06: Train Loss=1.4222, Acc=0.3411, F1=0.3395 | Val Loss=1.3997, Acc=0.3922, F1=0.3804\n",
      "Epoch 07: Train Loss=1.3814, Acc=0.3779, F1=0.3788 | Val Loss=1.4913, Acc=0.3137, F1=0.2316\n",
      "Epoch 08: Train Loss=1.3302, Acc=0.4615, F1=0.4615 | Val Loss=1.4450, Acc=0.3333, F1=0.2632\n",
      "Epoch 09: Train Loss=1.3002, Acc=0.4515, F1=0.4487 | Val Loss=1.4017, Acc=0.3725, F1=0.3735\n",
      "Epoch 10: Train Loss=1.1759, Acc=0.5452, F1=0.5425 | Val Loss=1.4728, Acc=0.3529, F1=0.2953\n",
      "Epoch 11: Train Loss=1.0513, Acc=0.5786, F1=0.5746 | Val Loss=1.4600, Acc=0.3922, F1=0.3891\n",
      "Epoch 12: Train Loss=0.9459, Acc=0.6321, F1=0.6314 | Val Loss=1.7295, Acc=0.3922, F1=0.3763\n",
      "Epoch 13: Train Loss=0.8550, Acc=0.6622, F1=0.6622 | Val Loss=1.6717, Acc=0.3922, F1=0.3840\n",
      "Epoch 14: Train Loss=0.7062, Acc=0.7191, F1=0.7159 | Val Loss=1.9760, Acc=0.3922, F1=0.3746\n",
      "Epoch 15: Train Loss=0.5516, Acc=0.7993, F1=0.8003 | Val Loss=2.7269, Acc=0.3725, F1=0.3459\n",
      "Epoch 16: Train Loss=0.4111, Acc=0.8395, F1=0.8377 | Val Loss=2.5136, Acc=0.4314, F1=0.3959\n",
      "Epoch 17: Train Loss=0.3989, Acc=0.8629, F1=0.8599 | Val Loss=3.0536, Acc=0.3137, F1=0.2782\n",
      "Epoch 18: Train Loss=0.3222, Acc=0.8662, F1=0.8656 | Val Loss=3.1512, Acc=0.4118, F1=0.3961\n",
      "Epoch 19: Train Loss=0.2060, Acc=0.9365, F1=0.9363 | Val Loss=3.3844, Acc=0.4118, F1=0.4070\n",
      "Epoch 20: Train Loss=0.1979, Acc=0.9298, F1=0.9294 | Val Loss=3.9512, Acc=0.4314, F1=0.4084\n",
      "Epoch 21: Train Loss=0.2320, Acc=0.9231, F1=0.9232 | Val Loss=4.4011, Acc=0.3725, F1=0.3384\n",
      "Epoch 22: Train Loss=0.1394, Acc=0.9565, F1=0.9565 | Val Loss=4.2807, Acc=0.3922, F1=0.3635\n",
      "Epoch 23: Train Loss=0.1073, Acc=0.9498, F1=0.9499 | Val Loss=4.1411, Acc=0.4314, F1=0.4237\n",
      "Epoch 24: Train Loss=0.0843, Acc=0.9766, F1=0.9767 | Val Loss=4.0192, Acc=0.4314, F1=0.4121\n",
      "Epoch 25: Train Loss=0.0087, Acc=0.9967, F1=0.9967 | Val Loss=4.3511, Acc=0.3922, F1=0.3905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:19:31,023] Trial 23 finished with value: 0.43137254901960786 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00010052410334227605, 'weight_decay': 3.6334054481525195e-05}. Best is trial 21 with value: 0.5686274509803921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=0.0243, Acc=0.9933, F1=0.9933 | Val Loss=4.9410, Acc=0.3922, F1=0.3703\n",
      "Early stopping\n",
      "\n",
      "[trial 24] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.0857, Acc=0.2375, F1=0.2389 | Val Loss=1.8363, Acc=0.1961, F1=0.0656\n",
      "Epoch 02: Train Loss=1.6349, Acc=0.2742, F1=0.2615 | Val Loss=1.6699, Acc=0.2353, F1=0.1248\n",
      "Epoch 03: Train Loss=1.6174, Acc=0.2241, F1=0.2068 | Val Loss=1.5229, Acc=0.3529, F1=0.2300\n",
      "Epoch 04: Train Loss=1.6137, Acc=0.2876, F1=0.2877 | Val Loss=1.5718, Acc=0.1961, F1=0.0656\n",
      "Epoch 05: Train Loss=1.5742, Acc=0.2542, F1=0.2510 | Val Loss=1.6213, Acc=0.1961, F1=0.0656\n",
      "Epoch 06: Train Loss=1.5495, Acc=0.3077, F1=0.3088 | Val Loss=1.5308, Acc=0.3137, F1=0.2331\n",
      "Epoch 07: Train Loss=1.6159, Acc=0.2140, F1=0.2097 | Val Loss=1.5263, Acc=0.2353, F1=0.1712\n",
      "Epoch 08: Train Loss=1.5197, Acc=0.3445, F1=0.3363 | Val Loss=1.5583, Acc=0.3137, F1=0.1812\n",
      "Epoch 09: Train Loss=1.5020, Acc=0.3077, F1=0.2816 | Val Loss=1.4686, Acc=0.3137, F1=0.2087\n",
      "Epoch 10: Train Loss=1.4975, Acc=0.3344, F1=0.2617 | Val Loss=1.4684, Acc=0.2941, F1=0.1823\n",
      "Epoch 11: Train Loss=1.5030, Acc=0.2843, F1=0.2812 | Val Loss=1.4917, Acc=0.2745, F1=0.1632\n",
      "Epoch 12: Train Loss=1.5460, Acc=0.2977, F1=0.2733 | Val Loss=1.5524, Acc=0.2941, F1=0.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:20:52,363] Trial 24 finished with value: 0.35294117647058826 and parameters: {'nhead': 4, 'num_layers': 3, 'lr': 0.00032367871286896876, 'weight_decay': 7.751334024424333e-05}. Best is trial 21 with value: 0.5686274509803921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.5012, Acc=0.2575, F1=0.2476 | Val Loss=1.4755, Acc=0.3333, F1=0.1932\n",
      "Early stopping\n",
      "\n",
      "[trial 25] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.8458, Acc=0.2676, F1=0.2699 | Val Loss=1.7006, Acc=0.2353, F1=0.1227\n",
      "Epoch 02: Train Loss=1.5971, Acc=0.2776, F1=0.2773 | Val Loss=1.6256, Acc=0.2353, F1=0.1696\n",
      "Epoch 03: Train Loss=1.5554, Acc=0.3043, F1=0.2985 | Val Loss=1.4877, Acc=0.2941, F1=0.2612\n",
      "Epoch 04: Train Loss=1.4827, Acc=0.3211, F1=0.3186 | Val Loss=1.6266, Acc=0.3137, F1=0.1877\n",
      "Epoch 05: Train Loss=1.4682, Acc=0.3344, F1=0.3258 | Val Loss=1.5277, Acc=0.2941, F1=0.2104\n",
      "Epoch 06: Train Loss=1.4299, Acc=0.3679, F1=0.3616 | Val Loss=1.4201, Acc=0.3725, F1=0.3420\n",
      "Epoch 07: Train Loss=1.3951, Acc=0.3645, F1=0.3516 | Val Loss=1.4840, Acc=0.3725, F1=0.3257\n",
      "Epoch 08: Train Loss=1.3297, Acc=0.4147, F1=0.4105 | Val Loss=1.5292, Acc=0.3333, F1=0.3104\n",
      "Epoch 09: Train Loss=1.3101, Acc=0.4348, F1=0.4304 | Val Loss=1.3739, Acc=0.3725, F1=0.3585\n",
      "Epoch 10: Train Loss=1.2322, Acc=0.4849, F1=0.4823 | Val Loss=1.5441, Acc=0.3529, F1=0.3175\n",
      "Epoch 11: Train Loss=1.1691, Acc=0.5050, F1=0.5031 | Val Loss=1.4267, Acc=0.4118, F1=0.3972\n",
      "Epoch 12: Train Loss=1.0819, Acc=0.5585, F1=0.5516 | Val Loss=1.7278, Acc=0.3529, F1=0.2809\n",
      "Epoch 13: Train Loss=1.0363, Acc=0.5786, F1=0.5775 | Val Loss=1.5690, Acc=0.3922, F1=0.3461\n",
      "Epoch 14: Train Loss=0.8928, Acc=0.6789, F1=0.6792 | Val Loss=1.7196, Acc=0.4510, F1=0.3706\n",
      "Epoch 15: Train Loss=0.8057, Acc=0.6923, F1=0.6916 | Val Loss=1.6848, Acc=0.4118, F1=0.3565\n",
      "Epoch 16: Train Loss=0.6157, Acc=0.7926, F1=0.7918 | Val Loss=1.6707, Acc=0.5294, F1=0.5388\n",
      "Epoch 17: Train Loss=0.5608, Acc=0.7759, F1=0.7764 | Val Loss=2.1354, Acc=0.4706, F1=0.4543\n",
      "Epoch 18: Train Loss=0.4702, Acc=0.8060, F1=0.8056 | Val Loss=2.8092, Acc=0.2549, F1=0.2370\n",
      "Epoch 19: Train Loss=0.3338, Acc=0.8763, F1=0.8761 | Val Loss=2.3850, Acc=0.4510, F1=0.4473\n",
      "Epoch 20: Train Loss=0.4736, Acc=0.8763, F1=0.8754 | Val Loss=2.4808, Acc=0.5098, F1=0.4975\n",
      "Epoch 21: Train Loss=0.3530, Acc=0.8796, F1=0.8788 | Val Loss=2.5163, Acc=0.5098, F1=0.4875\n",
      "Epoch 22: Train Loss=0.1376, Acc=0.9398, F1=0.9396 | Val Loss=3.0527, Acc=0.4510, F1=0.4541\n",
      "Epoch 23: Train Loss=0.2322, Acc=0.9331, F1=0.9330 | Val Loss=3.3080, Acc=0.4510, F1=0.4442\n",
      "Epoch 24: Train Loss=0.1509, Acc=0.9766, F1=0.9764 | Val Loss=2.6487, Acc=0.5490, F1=0.5486\n",
      "Epoch 25: Train Loss=0.2285, Acc=0.9666, F1=0.9666 | Val Loss=3.6281, Acc=0.4706, F1=0.4544\n",
      "Epoch 26: Train Loss=0.0844, Acc=0.9666, F1=0.9666 | Val Loss=3.5229, Acc=0.5098, F1=0.5132\n",
      "Epoch 27: Train Loss=0.1042, Acc=0.9565, F1=0.9562 | Val Loss=3.6049, Acc=0.4706, F1=0.4509\n",
      "Epoch 28: Train Loss=0.1157, Acc=0.9732, F1=0.9732 | Val Loss=4.1929, Acc=0.4314, F1=0.4403\n",
      "Epoch 29: Train Loss=0.1279, Acc=0.9732, F1=0.9731 | Val Loss=3.6063, Acc=0.4706, F1=0.4629\n",
      "Epoch 30: Train Loss=0.0330, Acc=0.9866, F1=0.9866 | Val Loss=3.9692, Acc=0.5294, F1=0.4891\n",
      "Epoch 31: Train Loss=0.0494, Acc=0.9866, F1=0.9866 | Val Loss=4.6959, Acc=0.4510, F1=0.4166\n",
      "Epoch 32: Train Loss=0.0498, Acc=0.9866, F1=0.9866 | Val Loss=4.3100, Acc=0.4706, F1=0.4766\n",
      "Epoch 33: Train Loss=0.0497, Acc=0.9866, F1=0.9866 | Val Loss=4.7924, Acc=0.4510, F1=0.4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:23:20,983] Trial 25 finished with value: 0.5490196078431373 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00020301680804382034, 'weight_decay': 0.00016307267195726492}. Best is trial 21 with value: 0.5686274509803921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss=0.0467, Acc=0.9866, F1=0.9867 | Val Loss=4.6528, Acc=0.3922, F1=0.3899\n",
      "Early stopping\n",
      "\n",
      "[trial 26] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.8187, Acc=0.2776, F1=0.2756 | Val Loss=1.5476, Acc=0.3333, F1=0.2801\n",
      "Epoch 02: Train Loss=1.5289, Acc=0.3545, F1=0.3483 | Val Loss=1.4333, Acc=0.3137, F1=0.2851\n",
      "Epoch 03: Train Loss=1.5000, Acc=0.3779, F1=0.3754 | Val Loss=1.6202, Acc=0.3137, F1=0.2093\n",
      "Epoch 04: Train Loss=1.4311, Acc=0.3645, F1=0.3649 | Val Loss=1.4925, Acc=0.3529, F1=0.2721\n",
      "Epoch 05: Train Loss=1.3705, Acc=0.3946, F1=0.3932 | Val Loss=1.4650, Acc=0.3333, F1=0.2884\n",
      "Epoch 06: Train Loss=1.3628, Acc=0.3813, F1=0.3819 | Val Loss=1.4969, Acc=0.3137, F1=0.2773\n",
      "Epoch 07: Train Loss=1.3160, Acc=0.4247, F1=0.4217 | Val Loss=1.5812, Acc=0.2941, F1=0.2373\n",
      "Epoch 08: Train Loss=1.2658, Acc=0.4749, F1=0.4738 | Val Loss=1.4271, Acc=0.3333, F1=0.3088\n",
      "Epoch 09: Train Loss=1.2197, Acc=0.4849, F1=0.4846 | Val Loss=1.4452, Acc=0.3725, F1=0.3546\n",
      "Epoch 10: Train Loss=1.1520, Acc=0.5485, F1=0.5472 | Val Loss=1.4607, Acc=0.4706, F1=0.4456\n",
      "Epoch 11: Train Loss=1.0791, Acc=0.5819, F1=0.5811 | Val Loss=1.6136, Acc=0.4314, F1=0.3407\n",
      "Epoch 12: Train Loss=1.0192, Acc=0.5151, F1=0.5154 | Val Loss=1.4417, Acc=0.4706, F1=0.4509\n",
      "Epoch 13: Train Loss=0.9521, Acc=0.6187, F1=0.6172 | Val Loss=1.4437, Acc=0.4314, F1=0.4277\n",
      "Epoch 14: Train Loss=0.9228, Acc=0.6187, F1=0.6170 | Val Loss=1.5436, Acc=0.4118, F1=0.3834\n",
      "Epoch 15: Train Loss=0.8169, Acc=0.7057, F1=0.7053 | Val Loss=1.5117, Acc=0.4706, F1=0.4502\n",
      "Epoch 16: Train Loss=0.8218, Acc=0.6890, F1=0.6892 | Val Loss=1.6682, Acc=0.4706, F1=0.4338\n",
      "Epoch 17: Train Loss=0.7421, Acc=0.7090, F1=0.7095 | Val Loss=1.4543, Acc=0.5294, F1=0.4877\n",
      "Epoch 18: Train Loss=0.6355, Acc=0.7692, F1=0.7693 | Val Loss=1.6182, Acc=0.5294, F1=0.4697\n",
      "Epoch 19: Train Loss=0.6404, Acc=0.7324, F1=0.7308 | Val Loss=2.1309, Acc=0.4510, F1=0.4235\n",
      "Epoch 20: Train Loss=0.5564, Acc=0.7860, F1=0.7858 | Val Loss=1.8478, Acc=0.5490, F1=0.5238\n",
      "Epoch 21: Train Loss=0.4168, Acc=0.8562, F1=0.8560 | Val Loss=2.4133, Acc=0.4902, F1=0.4602\n",
      "Epoch 22: Train Loss=0.4453, Acc=0.8395, F1=0.8398 | Val Loss=2.3542, Acc=0.5294, F1=0.4953\n",
      "Epoch 23: Train Loss=0.3444, Acc=0.8662, F1=0.8664 | Val Loss=2.7597, Acc=0.5294, F1=0.4959\n",
      "Epoch 24: Train Loss=0.2980, Acc=0.9030, F1=0.9033 | Val Loss=3.2276, Acc=0.4314, F1=0.4053\n",
      "Epoch 25: Train Loss=0.3654, Acc=0.8896, F1=0.8895 | Val Loss=4.4527, Acc=0.3333, F1=0.2919\n",
      "Epoch 26: Train Loss=0.2130, Acc=0.9365, F1=0.9367 | Val Loss=3.6762, Acc=0.4902, F1=0.4588\n",
      "Epoch 27: Train Loss=0.1124, Acc=0.9498, F1=0.9497 | Val Loss=3.3804, Acc=0.4706, F1=0.4636\n",
      "Epoch 28: Train Loss=0.1101, Acc=0.9565, F1=0.9564 | Val Loss=3.9393, Acc=0.4118, F1=0.4095\n",
      "Epoch 29: Train Loss=0.0866, Acc=0.9766, F1=0.9765 | Val Loss=4.1187, Acc=0.4510, F1=0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:24:39,364] Trial 26 finished with value: 0.5490196078431373 and parameters: {'nhead': 8, 'num_layers': 1, 'lr': 0.00019072713147606145, 'weight_decay': 0.00015739304768163162}. Best is trial 21 with value: 0.5686274509803921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=0.0618, Acc=0.9799, F1=0.9799 | Val Loss=4.4398, Acc=0.4510, F1=0.4413\n",
      "Early stopping\n",
      "\n",
      "[trial 27] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.3299, Acc=0.2174, F1=0.2143 | Val Loss=1.7884, Acc=0.2745, F1=0.1562\n",
      "Epoch 02: Train Loss=1.7240, Acc=0.2174, F1=0.2104 | Val Loss=1.6196, Acc=0.2941, F1=0.1667\n",
      "Epoch 03: Train Loss=1.6501, Acc=0.2375, F1=0.2284 | Val Loss=1.5516, Acc=0.2941, F1=0.2446\n",
      "Epoch 04: Train Loss=1.6250, Acc=0.2642, F1=0.2613 | Val Loss=1.4438, Acc=0.3922, F1=0.2858\n",
      "Epoch 05: Train Loss=1.6040, Acc=0.2441, F1=0.2351 | Val Loss=1.6234, Acc=0.2353, F1=0.1085\n",
      "Epoch 06: Train Loss=1.6032, Acc=0.2776, F1=0.2766 | Val Loss=1.4856, Acc=0.2941, F1=0.1652\n",
      "Epoch 07: Train Loss=1.5422, Acc=0.3545, F1=0.3536 | Val Loss=1.6149, Acc=0.2941, F1=0.1694\n",
      "Epoch 08: Train Loss=1.5751, Acc=0.2876, F1=0.2807 | Val Loss=1.4925, Acc=0.2745, F1=0.1852\n",
      "Epoch 09: Train Loss=1.5229, Acc=0.2575, F1=0.2311 | Val Loss=1.5600, Acc=0.2745, F1=0.1584\n",
      "Epoch 10: Train Loss=1.5068, Acc=0.2843, F1=0.2573 | Val Loss=1.4872, Acc=0.3725, F1=0.3503\n",
      "Epoch 11: Train Loss=1.5044, Acc=0.2977, F1=0.2928 | Val Loss=1.4594, Acc=0.3529, F1=0.2446\n",
      "Epoch 12: Train Loss=1.4808, Acc=0.3177, F1=0.3000 | Val Loss=1.4702, Acc=0.2745, F1=0.2346\n",
      "Epoch 13: Train Loss=1.4628, Acc=0.3144, F1=0.3139 | Val Loss=1.4934, Acc=0.2745, F1=0.1878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:25:39,414] Trial 27 finished with value: 0.39215686274509803 and parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.0006644311640426634, 'weight_decay': 0.0005887057869447707}. Best is trial 21 with value: 0.5686274509803921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=1.4993, Acc=0.3110, F1=0.2521 | Val Loss=1.5310, Acc=0.3922, F1=0.3464\n",
      "Early stopping\n",
      "\n",
      "[trial 28] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=1.9844, Acc=0.2575, F1=0.2569 | Val Loss=1.6324, Acc=0.2353, F1=0.1880\n",
      "Epoch 02: Train Loss=1.6019, Acc=0.2843, F1=0.2831 | Val Loss=1.5879, Acc=0.2549, F1=0.1492\n",
      "Epoch 03: Train Loss=1.5442, Acc=0.3177, F1=0.3177 | Val Loss=1.4603, Acc=0.3922, F1=0.2751\n",
      "Epoch 04: Train Loss=1.5227, Acc=0.2943, F1=0.2826 | Val Loss=1.5675, Acc=0.2549, F1=0.1867\n",
      "Epoch 05: Train Loss=1.5892, Acc=0.2943, F1=0.2928 | Val Loss=1.4814, Acc=0.3137, F1=0.2241\n",
      "Epoch 06: Train Loss=1.5024, Acc=0.3344, F1=0.3322 | Val Loss=1.4629, Acc=0.3137, F1=0.2559\n",
      "Epoch 07: Train Loss=1.4651, Acc=0.3645, F1=0.3602 | Val Loss=1.6840, Acc=0.2941, F1=0.1645\n",
      "Epoch 08: Train Loss=1.5240, Acc=0.3110, F1=0.3038 | Val Loss=1.5117, Acc=0.3333, F1=0.2361\n",
      "Epoch 09: Train Loss=1.4602, Acc=0.3512, F1=0.3371 | Val Loss=1.4120, Acc=0.2941, F1=0.2749\n",
      "Epoch 10: Train Loss=1.4415, Acc=0.3645, F1=0.3506 | Val Loss=1.5878, Acc=0.3333, F1=0.3343\n",
      "Epoch 11: Train Loss=1.4248, Acc=0.3579, F1=0.3467 | Val Loss=1.4879, Acc=0.2549, F1=0.2441\n",
      "Epoch 12: Train Loss=1.4203, Acc=0.3913, F1=0.3882 | Val Loss=1.4019, Acc=0.4314, F1=0.3769\n",
      "Epoch 13: Train Loss=1.3410, Acc=0.4080, F1=0.3992 | Val Loss=1.5240, Acc=0.3137, F1=0.2340\n",
      "Epoch 14: Train Loss=1.3035, Acc=0.4247, F1=0.4188 | Val Loss=1.4836, Acc=0.2941, F1=0.2842\n",
      "Epoch 15: Train Loss=1.2859, Acc=0.4448, F1=0.4414 | Val Loss=1.4895, Acc=0.2941, F1=0.2767\n",
      "Epoch 16: Train Loss=1.2384, Acc=0.4381, F1=0.4386 | Val Loss=1.4469, Acc=0.3137, F1=0.3128\n",
      "Epoch 17: Train Loss=1.2393, Acc=0.4682, F1=0.4656 | Val Loss=1.4637, Acc=0.3529, F1=0.2985\n",
      "Epoch 18: Train Loss=1.1343, Acc=0.5217, F1=0.5175 | Val Loss=1.7855, Acc=0.3529, F1=0.2990\n",
      "Epoch 19: Train Loss=1.0724, Acc=0.5652, F1=0.5645 | Val Loss=1.8361, Acc=0.3529, F1=0.2877\n",
      "Epoch 20: Train Loss=1.0538, Acc=0.5786, F1=0.5779 | Val Loss=1.4757, Acc=0.4118, F1=0.3707\n",
      "Epoch 21: Train Loss=0.9454, Acc=0.5987, F1=0.5984 | Val Loss=1.7197, Acc=0.4510, F1=0.3665\n",
      "Epoch 22: Train Loss=0.8774, Acc=0.6488, F1=0.6472 | Val Loss=1.6770, Acc=0.2941, F1=0.2561\n",
      "Epoch 23: Train Loss=0.8937, Acc=0.6288, F1=0.6250 | Val Loss=1.5288, Acc=0.4510, F1=0.4428\n",
      "Epoch 24: Train Loss=0.7114, Acc=0.7324, F1=0.7323 | Val Loss=1.8327, Acc=0.5098, F1=0.4828\n",
      "Epoch 25: Train Loss=0.7235, Acc=0.6823, F1=0.6823 | Val Loss=1.8183, Acc=0.4314, F1=0.4108\n",
      "Epoch 26: Train Loss=0.6260, Acc=0.7759, F1=0.7744 | Val Loss=1.9008, Acc=0.4706, F1=0.4665\n",
      "Epoch 27: Train Loss=0.6733, Acc=0.7692, F1=0.7697 | Val Loss=1.9112, Acc=0.3922, F1=0.3939\n",
      "Epoch 28: Train Loss=0.6739, Acc=0.7659, F1=0.7647 | Val Loss=2.1269, Acc=0.3922, F1=0.3799\n",
      "Epoch 29: Train Loss=0.6035, Acc=0.7826, F1=0.7806 | Val Loss=2.4084, Acc=0.4510, F1=0.4447\n",
      "Epoch 30: Train Loss=0.4417, Acc=0.8528, F1=0.8528 | Val Loss=2.5468, Acc=0.4510, F1=0.4400\n",
      "Epoch 31: Train Loss=0.4203, Acc=0.8796, F1=0.8795 | Val Loss=2.8774, Acc=0.4510, F1=0.4185\n",
      "Epoch 32: Train Loss=0.4547, Acc=0.8528, F1=0.8527 | Val Loss=2.7670, Acc=0.4510, F1=0.4362\n",
      "Epoch 33: Train Loss=0.3317, Acc=0.8829, F1=0.8823 | Val Loss=3.0680, Acc=0.4118, F1=0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:29:10,247] Trial 28 finished with value: 0.5098039215686274 and parameters: {'nhead': 4, 'num_layers': 3, 'lr': 0.00015743845385984696, 'weight_decay': 0.00022243029399284466}. Best is trial 21 with value: 0.5686274509803921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss=0.3090, Acc=0.9164, F1=0.9164 | Val Loss=3.9735, Acc=0.4118, F1=0.4028\n",
      "Early stopping\n",
      "\n",
      "[trial 29] build loaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.0036, Acc=0.2207, F1=0.2143 | Val Loss=1.5430, Acc=0.2941, F1=0.1650\n",
      "Epoch 02: Train Loss=1.6910, Acc=0.2943, F1=0.2936 | Val Loss=1.6140, Acc=0.2549, F1=0.1525\n",
      "Epoch 03: Train Loss=1.7600, Acc=0.2776, F1=0.2663 | Val Loss=1.5309, Acc=0.2157, F1=0.1489\n",
      "Epoch 04: Train Loss=1.6479, Acc=0.2876, F1=0.2816 | Val Loss=1.5444, Acc=0.3529, F1=0.2566\n",
      "Epoch 05: Train Loss=1.5630, Acc=0.3177, F1=0.3006 | Val Loss=1.5191, Acc=0.2549, F1=0.1525\n",
      "Epoch 06: Train Loss=1.5577, Acc=0.2776, F1=0.2700 | Val Loss=1.5019, Acc=0.3333, F1=0.1945\n",
      "Epoch 07: Train Loss=1.5638, Acc=0.2676, F1=0.2584 | Val Loss=1.5698, Acc=0.3137, F1=0.2160\n",
      "Epoch 08: Train Loss=1.5255, Acc=0.3244, F1=0.2957 | Val Loss=1.4834, Acc=0.2941, F1=0.1673\n",
      "Epoch 09: Train Loss=1.5421, Acc=0.3144, F1=0.3095 | Val Loss=1.4993, Acc=0.2941, F1=0.1706\n",
      "Epoch 10: Train Loss=1.5205, Acc=0.2910, F1=0.2857 | Val Loss=1.4891, Acc=0.2353, F1=0.2016\n",
      "Epoch 11: Train Loss=1.5040, Acc=0.3411, F1=0.2969 | Val Loss=1.5423, Acc=0.2941, F1=0.1650\n",
      "Epoch 12: Train Loss=1.5225, Acc=0.2742, F1=0.2532 | Val Loss=1.5166, Acc=0.2941, F1=0.1991\n",
      "Epoch 13: Train Loss=1.5334, Acc=0.3211, F1=0.3261 | Val Loss=1.4947, Acc=0.3137, F1=0.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 22:31:05,150] Trial 29 finished with value: 0.35294117647058826 and parameters: {'nhead': 8, 'num_layers': 4, 'lr': 0.00033969671747088913, 'weight_decay': 0.00048115499617301763}. Best is trial 21 with value: 0.5686274509803921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=1.5190, Acc=0.3445, F1=0.3433 | Val Loss=1.5917, Acc=0.2157, F1=0.1254\n",
      "Early stopping\n",
      "Best hyper-parameters: {'nhead': 4, 'num_layers': 2, 'lr': 0.00010434959787802714, 'weight_decay': 9.753615006446377e-05}\n",
      "Best Val ACC (Optuna): 0.5686274509803921 | Val F1: 0.5549999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded eval — Train Acc=0.9900, F1=0.9900 | Val Acc=0.5686, F1=0.5550 | ΔACC=0.000000\n",
      "Saved VAL preds → results_final\\video_cls_val_dep.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAIcCAYAAAA9jUBvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKnklEQVR4nO3de3zO9f/H8ee12a7NzLAZG+Z8PhtpInL6hkRFJHKu0DdS1EhKh1F9i5Q5xJwPlUiFIsdCjabkkK8i+ppsDlPDsH1+f3SzX5dtbJft85nPHvff7XO7/a739fm8P6/P+8vl1ev9vt6XwzAMQwAAAMgxD6sDAAAAuFWRSAEAALiJRAoAAMBNJFIAAABuIpECAABwE4kUAACAm0ikAAAA3EQiBQAA4CYSKQAAADeRSCHf+PHHH9W/f39VrFhRPj4+KlKkiBo1aqTXX39dp0+fztN7x8XFqWXLlgoICJDD4dDkyZNz/R4Oh0Mvvvhirvd7I3PnzpXD4ZDD4dCmTZsyvG8YhqpUqSKHw6FWrVq5dY9p06Zp7ty5Obpm06ZNWcZ0MyZMmKBatWopLS1Nn3zyiRwOh6ZPn57l+evWrZPD4dBbb73l0t6oUSM5HA69+eabmV53dVx37tyZZd8HDx6Ut7e3vv/+e/ceJo+9+OKLcjgcVocB3NJIpJAvzJo1S+Hh4YqNjdWoUaO0du1arVixQt27d9f06dM1cODAPL3/gAEDFB8fr6VLl2r79u3q2bNnrt9j+/btGjRoUK73m13+/v6aPXt2hvbNmzfrl19+kb+/v9t9u5NINWrUSNu3b1ejRo3cvu+1jh8/rtdff10TJkyQh4eHOnXqpNKlS2vOnDlZXhMTEyMvLy/16dMnvW337t2Ki4uTpEzHLLuqVaumhx9+WE899ZTbfQDI30ikYLnt27dryJAhatu2rXbt2qWhQ4eqVatWateunSIjI3XgwAH1798/T2P46aef1LZtW3Xo0EG33367Spcunev3uP3221W2bNlc7ze7evTooeXLl+vcuXMu7bNnz1ZERITCwsJMiePy5cu6cuWKihYtqttvv11FixbNtb6nTJmiYsWK6f7775ckFSpUSI888ohiY2P1008/ZTj/7NmzWrFihe69916VLFkyvf3999+XJHXq1EkHDhzQtm3b3I7piSee0JYtW26qDwD5F4kULPfaa6/J4XBo5syZcjqdGd739vbWvffem/46LS1Nr7/+umrUqCGn06ng4GA98sgj+v33312ua9WqlerUqaPY2Fi1aNFChQsXVqVKlTRx4kSlpaVJ+v/pmStXrig6Ojp9CkzKetrj6jVHjhxJb9uwYYNatWqlwMBA+fr6KiwsTA888IDOnz+ffk5mU3s//fSTunTpouLFi8vHx0cNGjTQvHnzXM65OgW2ZMkSjR07VqGhoSpatKjatm2rn3/+OXuDLOmhhx6SJC1ZsiS9LSkpScuXL9eAAQMyveall15S06ZNVaJECRUtWlSNGjXS7Nmz9c/fOq9QoYL27t2rzZs3p49fhQoVXGJfsGCBnn76aZUpU0ZOp1OHDh3KMLWXmJiocuXKqVmzZrp8+XJ6//v27ZOfn59LxSgzly5d0uzZs9WrVy95ePz/R9vVamZMTEyGa5YsWaKLFy+6PP/Fixe1ePFihYeH6+2335ak61a0biQ8PFw1a9a87vSiGT7//HM1aNBATqdTFStWzHLK0jAMTZs2TQ0aNJCvr6+KFy+ubt266ddff3U57+rfr61bt+r222+Xr6+vypQpo3Hjxik1NdWMRwLyBwOw0JUrV4zChQsbTZs2zfY1jz76qCHJeOKJJ4y1a9ca06dPN0qWLGmUK1fOSEhISD+vZcuWRmBgoFG1alVj+vTpxrp164yhQ4cakox58+YZhmEYJ0+eNLZv325IMrp162Zs377d2L59u2EYhjF+/Hgjs78iMTExhiTj8OHDhmEYxuHDhw0fHx+jXbt2xsqVK41NmzYZixYtMvr06WOcOXMm/TpJxvjx49NfHzhwwPD39zcqV65szJ8/3/j888+Nhx56yJBkTJo0Kf28jRs3GpKMChUqGA8//LDx+eefG0uWLDHCwsKMqlWrGleuXLnueF2NNzY21ujTp49x2223pb8XHR1t+Pn5GefOnTNq165ttGzZ0uXafv36GbNnzzbWrVtnrFu3znj55ZcNX19f46WXXko/5/vvvzcqVapkNGzYMH38vv/+e5fYy5QpY3Tr1s1YtWqV8dlnnxmnTp1Kf2/jxo3pfX399ddGoUKFjKeeesowDMNITk42atWqZdSoUcP466+/rvucW7ZsMSQZq1evzvBe8+bNjeDgYOPSpUsu7U2aNDHKlCnjMoaLFi0yJBnvvfde+rVFihQx/vzzzyzH9UaGDBliBAUFGWlpaTc8Ny+sX7/e8PT0NJo3b258/PHHxocffmg0adLECAsLy/BnfPDgwYaXl5fx9NNPG2vXrjUWL15s1KhRwyhVqpRx4sSJ9POu/v0KDQ013nnnHeOLL74wnnzySUOSMWzYMLMfEbAMiRQsdeLECUOS0bNnz2ydv3//fkOSMXToUJf2b7/91pBkjBkzJr2tZcuWhiTj22+/dTm3Vq1axr/+9S+Xtsw+/LObSH300UeGJGP37t3Xjf3aRKpnz56G0+k0jh496nJehw4djMKFCxtnz541DOP/k5GOHTu6nPfBBx8YktITv6z88x/8q3399NNPhmH8nUj069fPMAwj00Tqn1JTU43Lly8bEyZMMAIDA12SgqyuvXq/O++8M8v3/plIGYZhTJo0yZBkrFixwujbt6/h6+tr/Pjjj9d9xn9e989/7K8dg48//ji97aeffjIkGWPHjnU5t3Xr1oaPj096Enz12tmzZ2faZ3YSqVmzZhmSjP3799/w3LzQtGlTIzQ01Lhw4UJ627lz54wSJUq4/Bm/+h8V//nPf1yuP3bsmOHr62uMHj06ve3q369PPvnE5dzBgwcbHh4exm+//ZZHTwPkL0zt4ZayceNGSVK/fv1c2m+77TbVrFlTX331lUt76dKlddttt7m01atXT7/99luuxdSgQQN5e3vr0Ucf1bx58zJMgWRlw4YNatOmjcqVK+fS3q9fP50/f17bt293af/n9Kb093NIytGztGzZUpUrV9acOXO0Z88excbGZjmtdzXGtm3bKiAgQJ6envLy8tILL7ygU6dO6eTJk9m+7wMPPJDtc0eNGqVOnTrpoYce0rx58zR16lTVrVv3htcdP35cDodDQUFBGd578MEH5e/v7zJFN2fOHDkcDpf1d4cPH9bGjRt1//33q1ixYpKk7t27Z7g2p4KDgyVJ//vf/6573pUrV9w6rjeVlpycrNjYWN1///3y8fFJb/f391fnzp1dzv3ss8/kcDjUu3dvl/5Lly6t+vXrZ/iGpb+/f4Y/l7169VJaWpq2bNmSnaEBbnkkUrBUUFCQChcurMOHD2fr/FOnTkmSQkJCMrwXGhqa/v5VgYGBGc5zOp26cOGCG9FmrnLlylq/fr2Cg4M1bNgwVa5cWZUrV9aUKVOue92pU6eyfI6r7//Ttc9ydT1ZTp7lauKwcOFCTZ8+XdWqVVOLFi0yPfe7775T+/btJf39rcpvvvlGsbGxGjt2bI7vm9lzXi/Gfv366eLFiypduvQN10ZddeHCBXl5ecnT0zPDe4ULF1bPnj21du1anThxQleuXNHChQvTE8ur5syZI8Mw1K1bN509e1Znz57V5cuXde+99+qbb77RgQMHsv0c/3Q1gbnemB05ckReXl5uHf98hmudOXNGaWlpmX6B4tq2P/74Q4ZhqFSpUhnusWPHDiUmJrqcX6pUqSz7vPbPL2BXhawOAAWbp6en2rRpozVr1uj333+/4bfariYT8fHxGc49fvx4ptUId139xy8lJcVlEfy1/5hIUosWLdSiRQulpqZq586dmjp1qkaMGKFSpUpluZVCYGCg4uPjM7QfP35cknL1Wf6pX79+euGFFzR9+nS9+uqrWZ63dOlSeXl56bPPPnOpZKxcuTLH98zJXkXx8fEaNmyYGjRooL179+qZZ57RO++8c8PrgoKCdOnSJSUnJ8vPzy/D+wMHDtSsWbM0f/58VatWTSdPntR//vOf9PfT0tLSt3C4+q2/a82ZM0evv/56tp/lqqv7oF3vf9PQ0FDFxsbmuG9JmX5J46rixYvL4XDoxIkTGd67ti0oKEgOh0Nbt27NtM9r2/74448s+8zsP2IAOyKRguUiIyO1evVqDR48WJ988om8vb1d3r98+bLWrl2rzp07q3Xr1pKkhQsXqkmTJunnxMbGav/+/enVktxw9ZtnP/74o8u9Pv300yyv8fT0VNOmTVWjRg0tWrRI33//fZaJVJs2bbRixQodP348vQolSfPnz1fhwoV1++23586DXKNMmTIaNWqUDhw4oL59+2Z5nsPhUKFChVwqPBcuXNCCBQsynJtbVb7U1FQ99NBDcjgcWrNmjRYtWqRnnnlGrVq1yjK5uapGjRqSpF9++SV92vOfmjZtqjp16igmJkbVqlVTQECAy5TjF198od9//13Dhg1Tt27dMlz/xBNPaP78+XrttddUqFDOPjp//fVXeXh4qHr16lme4+3trcaNG+eo3+zw8/PTbbfdpo8//lhvvPFGelL8559/ZvizfM8992jixIn63//+pwcffPCGff/5559atWqVy/Te4sWL5eHhoTvvvDN3HwTIp0ikYLmIiAhFR0dr6NChCg8P15AhQ1S7dm1dvnxZcXFxmjlzpurUqaPOnTurevXqevTRRzV16lR5eHioQ4cOOnLkiMaNG6dy5crl6saHHTt2VIkSJTRw4EBNmDBBhQoV0ty5c3Xs2DGX86ZPn64NGzaoU6dOCgsL08WLF9PX07Rt2zbL/sePH6/PPvtMd911l1544QWVKFFCixYt0ueff67XX39dAQEBufYs15o4ceINz+nUqZPeeust9erVS48++qhOnTqlN998M9NKRd26dbV06VItW7ZMlSpVko+PT7bWNV1r/Pjx2rp1q7788kuVLl1aTz/9tDZv3qyBAweqYcOGqlixYpbXXt2VfceOHZkmUtLfG6+OHDlSP//8sx577DH5+vqmvzd79mwVKlRIY8aMcUlsr3rsscf05JNP6vPPP1eXLl3S2zds2OCyFcZVHTt2VOHChdNjatCggYoXL56dYch1L7/8su6++261a9dOTz/9tFJTUzVp0iT5+fm5/GrAHXfcoUcffVT9+/fXzp07deedd8rPz0/x8fH6+uuvVbduXQ0ZMiT9/MDAQA0ZMkRHjx5VtWrVtHr1as2aNUtDhgwxbV8ywHJWr3YHrtq9e7fRt29fIywszPD29jb8/PyMhg0bGi+88IJx8uTJ9PNSU1ONSZMmGdWqVTO8vLyMoKAgo3fv3saxY8dc+mvZsqVRu3btDPfp27evUb58eZc2ZfGV7e+++85o1qyZ4efnZ5QpU8YYP3688f7777t8a2/79u3GfffdZ5QvX95wOp1GYGCg0bJlS2PVqlUZ7vHPb+0ZhmHs2bPH6Ny5sxEQEGB4e3sb9evXN2JiYlzOufrttg8//NCl/fDhw4akDOdfK7vfLsvsm3dz5swxqlevbjidTqNSpUpGVFSUMXv2bJfnNwzDOHLkiNG+fXvD39/fkJQ+vlnF/s/3rn5r78svvzQ8PDwyjNGpU6eMsLAwo0mTJkZKSsp1n6FFixYZvt34TwkJCYa3t7chyfjuu+8ytHft2jXLa8+cOWP4+voanTt3Ngzj/8c1q+Pq+Pz5559G4cKFM3wTzmyrVq0y6tWrZ3h7exthYWHGxIkTs/xm6pw5c4ymTZsafn5+hq+vr1G5cmXjkUceMXbu3Jl+ztW/X5s2bTIaN25sOJ1OIyQkxBgzZoxx+fJlMx8NsJTDMP6xsx4A3MKWL1+uHj166LffflOZMmWsDkfS35Wu4cOH69ixY5ZVpPJCq1atlJiYmOmO8UBBwrf2ANjG/fffryZNmigqKsrqUCT9vZ3BpEmTFBkZaaskCsD/I5ECYBsOh0OzZs1SaGho+s8AWenYsWPq3bu3nn76aatDAZBHmNoDAABwExUpAABQIF25ckXPP/+8KlasKF9fX1WqVEkTJkzIUUWb7Q8AAECBNGnSJE2fPl3z5s1T7dq1tXPnTvXv318BAQEaPnx4tvogkQIAAAXS9u3b1aVLF3Xq1EnS3xsxL1myRDt37sx2H0ztAQAA20hJSdG5c+dcjpSUlEzPbd68ub766isdPHhQkvTDDz/o66+/VseOHbN9P1tWpIat2G91CAVO77rZ/1Fa3Lz9Z85ZHUKB0qshu3SbKe7IWatDKHAiqhQz9X6+DZ/Is76f7RKkl156yaVt/PjxevHFFzOe++yzSkpKUo0aNeTp6anU1FS9+uqreuihh7J9P1smUgAAoGCKjIzUyJEjXdqy+mHvZcuWaeHChVq8eLFq166t3bt3a8SIEQoNDb3ub5H+E4kUAAAwlyPvVhY5nc4sE6drjRo1Ss8991z6j8vXrVtXv/32m6KiorKdSLFGCgAAFEjnz5+Xh4drKuTp6cn2BwAAIB9zOKyOQJLUuXNnvfrqqwoLC1Pt2rUVFxent956SwMGDMh2HyRSAACgQJo6darGjRunoUOH6uTJkwoNDdVjjz2mF154Idt9kEgBAABz5eEaqZzw9/fX5MmTNXnyZLf7IJECAADmyidTe7khf6SEAAAAtyAqUgAAwFz5ZGovN9jnSQAAAExGRQoAAJiLNVIAAACgIgUAAMzFGikAAABQkQIAAOay0RopEikAAGAupvYAAABARQoAAJjLRlN7VKQAAADcREUKAACYizVSAAAAoCIFAADMxRopAAAAUJECAADmstEaKRIpAABgLhslUvZ5EgAAAJNRkQIAAObyYLE5AABAgUdFCgAAmIs1UgAAAKAiBQAAzGWjDTlJpAAAgLmY2gMAAAAVKQAAYC4bTe1RkQIAAHATFSkAAGAu1kgBAACAihQAADAXa6QAAABARSqfaV8tUF1qB2vDodNavucPq8Oxnc8+mKtd2zYp/vff5OXtVJWadfVg/ycUUra81aHZVtz6TxX31adKSvj7z3NQ2fJqdl9vVa5/m8WR2duyJYs0N2a2EhMSVLlKVY1+bowahTe2Oizb4TPFTayRQl4IK+ajOyoU0+9JF60OxbYO7IlT607dNO4/szXqlXeUlpqqN59/UikXL1gdmm35lwhSyx4D1ffl99T35fdUvlYDffzWeCX8fsTq0Gxr7ZrVen1ilAY/OkTLPlqpRo3CNfSxwYo/ftzq0GyHzxQ3ORx5d5iMRCqfcHo61K9JqBbHxev8pVSrw7GtZ16eohbt7lGZ8pUUVqmaBj41TqcSTujIoQNWh2ZbVRpFqHKDpioRUlYlQsrqzgcHyNvHV8cP7bc6NNtaMC9G9z3wgO7v1l2VKlfW6MixKh1SWh8sW2J1aLbDZwosndr7/fffFR0drW3btunEiRNyOBwqVaqUmjVrpscff1zlypWzMjxTPdigtPae+Es/J5zX3dWtjqbguJD8lyTJr0hRiyMpGNLSUnXg2y26nHJRZarWsjocW7p86ZL279urAYMedWmPaHaHftgdZ1FUBQefKdlko6k9yxKpr7/+Wh06dFC5cuXUvn17tW/fXoZh6OTJk1q5cqWmTp2qNWvW6I477rAqRNOElymqcgE+en3TEatDKVAMw9CSWVNUrXZ9la1Q2epwbC3h2GEtePFJXbl8Sd4+vrpvxHgFlWENSV44c/aMUlNTFRgY6NIeGBikxMQEi6IqGPhMKZgsS6SeeuopDRo0SG+//XaW748YMUKxsbHX7SclJUUpKSkubamXL8nTyzvXYs1LxXwLqVu9Unr3m6O6kmZYHU6BsiD6DR07ckhj35hhdSi2VyKkrPq/Ol0Xz/+lg7Ff6/MZb6jX8/8hmcpDjmvWihiGkaENuYvPlByw0Z9Fy2prP/30kx5//PEs33/sscf0008/3bCfqKgoBQQEuBy7ls/MzVDzVFgxHxX1KaRn76qod7rU0DtdaqhaST+1qlxc73SpIfv8UctfFkS/qd3fbtVzUdNUIqiU1eHYnmchLxUvXUYhlaqrZY+BCg6rpJ1rV1gdli0VL1Zcnp6eSkxMdGk/ffqUAgODLIrK/vhMKbgsq0iFhIRo27Ztql498wVB27dvV0hIyA37iYyM1MiRI13aRq89nCsxmuHnhPN6Zf2vLm19wkP0x5+X9OXBU6JGlbsMw9DC6W9q1/bNei5qmkqWDrU6pILJMJR65ZLVUdiSl7e3ataqrR3bvlGbtu3S23ds26ZWrdtYGJk98ZniJtZI3bxnnnlGjz/+uHbt2qV27dqpVKlScjgcOnHihNatW6f3339fkydPvmE/TqdTTqfTpe1WmdaTpJQraYr/MyVD21+XUjO04+YtmPaGtm/+QsPHvSEfXz+dPX1KklTYz0/eTh+Lo7Onzctmq1L921Q0sKQuXbyg/ds36uj+H9V99GtWh2Zbffr219jnRqtWnTqqX7+hln+4TPHx8ereo6fVodkOnyluIpG6eUOHDlVgYKDefvttzZgxQ6mpf3/l39PTU+Hh4Zo/f74efPBBq8KDTW1YvVySNPG5IS7tA0eMU4t291gRku0lnzurz6ZPUvLZ03IW9lPJchXVffRrqlg33OrQbOvuDh2VdPaMZkZPU0LCSVWpWk3vTZ+p0NAyVodmO3ymwGEYhuWzR5cvX06fzw8KCpKXl9dN9TdsBfvTmK133RtPwyL37D9zzuoQCpReDcOsDqFAiTty1uoQCpyIKsVMvZ/vvdF51veFVUNufFIuyhc/EePl5ZWt9VAAAAD5Sb5IpAAAQAFiozVS9nkSAACAHKhQoYIcDkeGY9iwYdnug4oUAAAwVz7ZkDM2Njb9y27S33tctmvXTt27d892HyRSAACgQCpZsqTL64kTJ6py5cpq2bJltvsgkQIAAObKwzVSmf10XGZ7Tl7r0qVLWrhwoUaOHJmjn1NijRQAADCXw5FnR2Y/HRcVFXXDkFauXKmzZ8+qX79+OXoUKlIAAMA2MvvpuBtVoyRp9uzZ6tChg0JDc/YzPyRSAADAVDmZOsup7EzjXeu3337T+vXr9fHHH+f4fkztAQCAAi0mJkbBwcHq1KlTjq+lIgUAAEyVlxWpnEpLS1NMTIz69u2rQoVynhZRkQIAAAXW+vXrdfToUQ0YMMCt66lIAQAAc+WfgpTat28vwzDcvp6KFAAAgJuoSAEAAFPlpzVSN4tECgAAmMpOiRRTewAAAG6iIgUAAExFRQoAAABUpAAAgLmoSAEAAICKFAAAMJl9ClIkUgAAwFxM7QEAAICKFAAAMBcVKQAAAFCRAgAA5qIiBQAAACpSAADAXFSkAAAAQEUKAACYzD4FKRIpAABgLqb2AAAAQEUKAACYi4oUAAAAqEgBAABzUZECAAAAFSkAAGAy+xSkSKQAAIC5mNoDAAAAFSkAAGAuO1WkbJlI9a4bYnUIBU7rUR9ZHUKBsm9Wb6tDAPJMwwrFrA4ByDZbJlIAACD/slNFijVSAAAAbqIiBQAATEVFCgAAAFSkAACAyexTkCKRAgAA5mJqDwAAAFSkAACAuahIAQAAgIoUAAAwFxUpAAAAUJECAAAms09BiooUAACAu6hIAQAAU9lpjRSJFAAAMJWdEimm9gAAANxERQoAAJiKihQAAIAN/O9//1Pv3r0VGBiowoULq0GDBtq1a1e2r6ciBQAATJVfKlJnzpzRHXfcobvuuktr1qxRcHCwfvnlFxUrVizbfZBIAQCAAmnSpEkqV66cYmJi0tsqVKiQoz6Y2gMAAOZy5N2RkpKic+fOuRwpKSmZhrFq1So1btxY3bt3V3BwsBo2bKhZs2bl6FFIpAAAgKkcDkeeHVFRUQoICHA5oqKiMo3j119/VXR0tKpWraovvvhCjz/+uJ588knNnz8/28/C1B4AALCNyMhIjRw50qXN6XRmem5aWpoaN26s1157TZLUsGFD7d27V9HR0XrkkUeydT8SKQAAYKq8XGzudDqzTJyuFRISolq1arm01axZU8uXL8/2/ZjaAwAABdIdd9yhn3/+2aXt4MGDKl++fLb7oCIFAABMlU92P9BTTz2lZs2a6bXXXtODDz6o7777TjNnztTMmTOz3QcVKQAAUCA1adJEK1as0JIlS1SnTh29/PLLmjx5sh5++OFs90FFCgAAmCq/bMgpSffcc4/uuecet6+nIgUAAOAmKlIAAMBU+aggddNIpAAAgKny09TezWJqDwAAwE1UpAAAgKlsVJCiIgUAAOAuKlIAAMBUHh72KUlRkQIAAHATFSkAAGAqO62RIpECAACmstP2ByRSFvvsg7natW2T4n//TV7eTlWpWVcP9n9CIWWz/8vTyL4DM3qofLB/hvbpa/bpqZnbLIjI/vbs3qWPFs/Vfw/s1+lTCXoh6m01u7O11WHZ3rIlizQ3ZrYSExJUuUpVjX5ujBqFN7Y6LNtivAsu1khZ7MCeOLXu1E3j/jNbo155R2mpqXrz+SeVcvGC1aHZUvNRn6hC/0XpR8fxqyVJH39z2OLI7OvihQuqWKW6ho58zupQCoy1a1br9YlRGvzoEC37aKUaNQrX0McGK/74catDsyXGO+ccjrw7zEYiZbFnXp6iFu3uUZnylRRWqZoGPjVOpxJO6MihA1aHZkuJ5y7qj7MX0o+OjcP0S3yStu6Ntzo022oS0Vz9Hn1CzVu1tTqUAmPBvBjd98ADur9bd1WqXFmjI8eqdEhpfbBsidWh2RLjXbCRSOUzF5L/kiT5FSlqcST251XIQz1bVtG8rw5aHQqQay5fuqT9+/Yqollzl/aIZnfoh91xFkVlX4y3exwOR54dZiORykcMw9CSWVNUrXZ9la1Q2epwbO/e28qrmJ+3Fm74r9WhALnmzNkzSk1NVWBgoEt7YGCQEhMTLIrKvhhv5OtE6tixYxowYMB1z0lJSdG5c+dcjkspKSZFmLsWRL+hY0cO6fHRL1sdSoHQt211ffH974o/c97qUIBcd+1/mRuGYatvSuU3jHfOUJEyyenTpzVv3rzrnhMVFaWAgACXY/6Mt02KMPcsiH5Tu7/dqueipqlEUCmrw7G9sJJF1LpeqOauZy0a7KV4seLy9PRUYmKiS/vp06cUGBhkUVT2xXjD0u0PVq1add33f/311xv2ERkZqZEjR7q0xR27db7xZhiGFk5/U7u2b9ZzUdNUsnSo1SEVCH1aV9PJpItas/OY1aEAucrL21s1a9XWjm3fqE3bduntO7ZtU6vWbSyMzJ4Yb/fYqVhnaSLVtWtXORwOGYaR5Tk3KtM5nU45nU6XNm9nWq7EZ4YF097Q9s1faPi4N+Tj66ezp09Jkgr7+cnb6WNxdPbkcEiPtK6qRZv+q9S0rP/sIXdcOH9ex38/mv76xPH/6ZeDB+RfNEDBpUMsjMy++vTtr7HPjVatOnVUv35DLf9wmeLj49W9R0+rQ7Mlxjvn7DTtaWkiFRISovfee09du3bN9P3du3crPDzc3KBMtmH1cknSxOeGuLQPHDFOLdrdY0VItte6XhmFBftr3lc/Wx1KgXDwwF49++9B6a9nTn1TktS2w7165nnWA+aFuzt0VNLZM5oZPU0JCSdVpWo1vTd9pkJDy1gdmi0x3gWbw7heOSiP3XvvvWrQoIEmTJiQ6fs//PCDGjZsqLS0nFWYth86mwvRISdaj/rI6hAKlH2zelsdQoESUozqMOzNx+SySqMJG/Ks7+9fMPeXEyytSI0aNUrJyclZvl+lShVt3LjRxIgAAACyz9JEqkWLFtd938/PTy1btjQpGgAAYAY7rZHK19sfAAAA5GeWVqQAAEDBY6OCFBUpAAAAd1GRAgAAprLTGikSKQAAYCob5VFM7QEAALiLihQAADCVnab2qEgBAAC4iYoUAAAwlY0KUlSkAAAA3EVFCgAAmMpOa6RIpAAAgKlslEcxtQcAAOAuKlIAAMBUdpraoyIFAADgJipSAADAVDYqSFGRAgAAcBcVKQAAYCrWSAEAAICKFAAAMJedKlIkUgAAwFQ2yqOY2gMAAHAXFSkAAGAqO03tUZECAAAF0osvviiHw+FylC5dOkd9UJECAACmyk8Fqdq1a2v9+vXprz09PXN0PYkUAAAosAoVKpTjKpTL9bkYCwAAwA3l5RqplJQUpaSkuLQ5nU45nc5Mz//vf/+r0NBQOZ1ONW3aVK+99poqVaqU7fuxRgoAAJjK4ci7IyoqSgEBAS5HVFRUpnE0bdpU8+fP1xdffKFZs2bpxIkTatasmU6dOpXtZ6EiBQAAbCMyMlIjR450acuqGtWhQ4f0/79u3bqKiIhQ5cqVNW/evAx9ZIVECgAAmMojD6f2rjeNdyN+fn6qW7eu/vvf/2b7Gqb2AAAA9Pf6qv379yskJCTb15BIAQAAU+XlGqmceOaZZ7R582YdPnxY3377rbp166Zz586pb9++2e6DqT0AAFAg/f7773rooYeUmJiokiVL6vbbb9eOHTtUvnz5bPdBIgUAAEyVX34iZunSpTfdB1N7AAAAbqIiBQAATOWRPwpSuYJECgAAmCq/TO3lBqb2AAAA3ERFCgAAmMpGBSl7JlINKxSzOoQCZ8Mb3awOoUCp1e4Zq0MoUM7Evmt1CADyKVsmUgAAIP9yyD4lKdZIAQAAuImKFAAAMJWdtj+gIgUAAOAmKlIAAMBUdtpHikQKAACYykZ5FFN7AAAA7qIiBQAATOVho5IUFSkAAAA3UZECAACmslFBiooUAACAu6hIAQAAU7H9AQAAgJtslEcxtQcAAOAuKlIAAMBUbH8AAAAAKlIAAMBc9qlHUZECAABwGxUpAABgKjttf0BFCgAAwE1UpAAAgKk87FOQIpECAADmYmoPAAAAVKQAAIC5bFSQoiIFAADgLipSAADAVKyRAgAAABUpAABgLrY/AAAAcBNTewAAAKAiBQAAzGWfepSbFakFCxbojjvuUGhoqH777TdJ0uTJk/XJJ5/kanAAAAD5WY4TqejoaI0cOVIdO3bU2bNnlZqaKkkqVqyYJk+enNvxAQAAm/FwOPLsMP1ZcnrB1KlTNWvWLI0dO1aenp7p7Y0bN9aePXtyNTgAAID8LMdrpA4fPqyGDRtmaHc6nUpOTs6VoAAAgH3Z6Et7Oa9IVaxYUbt3787QvmbNGtWqVSs3YgIAALgl5LgiNWrUKA0bNkwXL16UYRj67rvvtGTJEkVFRen999/PixgBAICN2GkfqRwnUv3799eVK1c0evRonT9/Xr169VKZMmU0ZcoU9ezZMy9iBAAANmKjPMq9faQGDx6swYMHKzExUWlpaQoODs7tuAAAAPK9m9qQMygoKLfiKPCWLVmkuTGzlZiQoMpVqmr0c2PUKLyx1WHZzmcfzNWubZsU//tv8vJ2qkrNunqw/xMKKVve6tBsy9PTQ88/1lE9OzZWqcCiOpF4Tgs+3aGJs76QYRhWh2dbfKaYi/HOGSu2Kcgrbi02r1SpUpYHcm7tmtV6fWKUBj86RMs+WqlGjcI19LHBij9+3OrQbOfAnji17tRN4/4zW6NeeUdpqal68/knlXLxgtWh2dbT/dppULfmemrih2pw/ysaO2WlnnqkrYb2bGl1aLbFZ4q5GG/7iIqKksPh0IgRI7J9TY4rUtd2fvnyZcXFxWnt2rUaNWpUTruDpAXzYnTfAw/o/m7dJUmjI8dq27av9cGyJRr+1NMWR2cvz7w8xeX1wKfG6cled+vIoQOqXifjth64eU3rVdRnm3/U2q/3SpKOxp/Wg3c3VqNaYRZHZl98ppiL8c65/FiQio2N1cyZM1WvXr0cXZfjRGr48OGZtr/33nvauXNnTrsr8C5fuqT9+/ZqwKBHXdojmt2hH3bHWRRVwXEh+S9Jkl+RohZHYl/bd/+iQd2aq0pYsA4dPam61coookEljX5zudWh2RKfKeZivO3hr7/+0sMPP6xZs2bplVdeydG1bv3WXmY6dOig5ctz/sF44cIFff3119q3b1+G9y5evKj58+fnRnj51pmzZ5SamqrAwECX9sDAICUmJlgUVcFgGIaWzJqiarXrq2yFylaHY1tvxqzTB2t36YcVz+vcd1O0Y8mzenfxJn2wdpfVodkSnynmYrzd43A48uxwx7Bhw9SpUye1bds2x9fe1GLzf/roo49UokSJHF1z8OBBtW/fXkePHpXD4VCLFi20ZMkShYSESJKSkpLUv39/PfLII1n2kZKSopSUFJc2w9Mpp9OZ84ew0LX/4xuGYat9NvKjBdFv6NiRQxr7xgyrQ7G17v8K10Mdm6jfmHna90u86lUvozee6ab4hCQt+vRbq8OzLT5TzMV45x+Z5QVOZ9Z5wdKlS/X9998rNjbWrfvluCLVsGFDNWrUKP1o2LChQkJCNGbMGI0ZMyZHfT377LOqW7euTp48qZ9//llFixbVHXfcoaNHj2a7j6ioKAUEBLgcb0yKyuljWaZ4seLy9PRUYmKiS/vp06cUGMi3IvPKgug3tfvbrXouappKBJWyOhxbe21EV70Zs04ffrFLew8d15LPYzV10QaN6t/O6tBsic8UczHe7vHIwyOzvCAqKvO84NixYxo+fLgWLlwoHx8ft54lxxWprl27urz28PBQyZIl1apVK9WoUSNHfW3btk3r169XUFCQgoKCtGrVKg0bNkwtWrTQxo0b5efnd8M+IiMjNXLkSJc2w/PWqUZ5eXurZq3a2rHtG7Vp+///sOzYtk2tWrexMDJ7MgxDC6e/qV3bN+u5qGkqWTrU6pBsz9fHW2lGmktbapohD49cW1mAf+AzxVyMt3vyslqXWV6QVTVq165dOnnypMLDw9PbUlNTtWXLFr377rtKSUmRp6fnde+Xo0TqypUrqlChgv71r3+pdOnSObk0UxcuXFChQq4hvPfee/Lw8FDLli21ePHiG/aRWbnu4pWbDs1Uffr219jnRqtWnTqqX7+hln+4TPHx8ereg53ic9uCaW9o++YvNHzcG/Lx9dPZ06ckSYX9/OTtdO+/RnB9q7fs0bMD/6Vj8We075d4NahRVk/2vkvzV+6wOjTb4jPFXIx3/nK9abxrtWnTRnv27HFp69+/v2rUqKFnn332hkmUlMNEqlChQhoyZIj279+fk8uyVKNGDe3cuVM1a9Z0aZ86daoMw9C9996bK/fJ7+7u0FFJZ89oZvQ0JSScVJWq1fTe9JkKDS1jdWi2s2H131+ImPjcEJf2gSPGqUW7e6wIyfZGTvpQ44feoyljeqhk8SKKT0jS7I++0Wsz11gdmm3xmWIuxjvnPPLJ8jF/f3/VqVPHpc3Pz0+BgYEZ2rPiMHK4tfBdd92l4cOHZ5jic0dUVJS2bt2q1atXZ/r+0KFDNX36dKWlpWX6flZutYqUHcQdOWt1CAVK6+7PWx1CgXIm9l2rQwDylE+uffUse0Z8ciDP+p7cJWfLjK7VqlUrNWjQQJMnT87W+TlOpD788EM999xzeuqppxQeHp5hHVNON7LKCyRS5iORMheJlLlIpGB3ZidSI1flXSL11r03l0jlVLaHbsCAAZo8ebJ69OghSXryySfT33M4HOlf9UxNTc39KAEAAPKhbCdS8+bN08SJE3X48OG8jAcAANicnfbYynYidXUGsHz58nkWDAAAsL/8stg8N+RoIxc7ZZAAAAA3K0fLy6pVq3bDZOr06dM3FRAAALA3O9VlcpRIvfTSSwoICMirWAAAAG4pOUqkevbsqeDg4LyKBQAAFAAeNipJZXuNFOujAAAAXOX4W3sAAAA3w04/WZ7tRCqnP9MCAABgdyZvCg8AAAo6O60WIpECAACmKpCLzQEAAOCKihQAADCVjQpSVKQAAADcRUUKAACYqsD+aDEAAAD+HxUpAABgKjt9a49ECgAAmMpGeRRTewAAAO6iIgUAAEzFYnMAAABQkQIAAOZyyD4lKSpSAAAAbqIiBQAATMUaKQAAAFCRAgAA5rJTRYpECgAAmMphox05mdoDAABwExUpAABgKjtN7VGRAgAAcBMVKQAAYCobLZGiIgUAAOAuKlIAAMBUHjYqSVGRAgAAcBMVKQAAYCo7fWuPRAoAAJjKRjN7TO0BAAC4i4oUAAAwlYfsU5KyZSK1OO6o1SEUOHdVDLY6hALlTOy7VodQoPCZArsb0CTM6hBuWbZMpAAAQP7FGikAAABQkQIAAOZi+wMAAAA3sbM5AAAAqEgBAABz2aggRUUKAAAUTNHR0apXr56KFi2qokWLKiIiQmvWrMlRH1SkAACAqfLLGqmyZctq4sSJqlKliiRp3rx56tKli+Li4lS7du1s9UEiBQAACqTOnTu7vH711VcVHR2tHTt2kEgBAID8KZ8UpFykpqbqww8/VHJysiIiIrJ9HYkUAACwjZSUFKWkpLi0OZ1OOZ3OTM/fs2ePIiIidPHiRRUpUkQrVqxQrVq1sn0/FpsDAABTeeThERUVpYCAAJcjKioqy1iqV6+u3bt3a8eOHRoyZIj69u2rffv2ZftZHIZhGDl6+lvAnFh+YNRs/GixuUKK+VgdQoHCjxbD7sz+0eJ5O4/lWd896wbnqCJ1rbZt26py5cqaMWNGts5nag8AANhGTpKmzBiGkSERux4SKQAAYKr8stZ8zJgx6tChg8qVK6c///xTS5cu1aZNm7R27dps90EiBQAACqQ//vhDffr0UXx8vAICAlSvXj2tXbtW7dq1y3YfJFIAAMBU+WVDztmzZ990H3xrDwAAwE1UpAAAgKnyRz0qd5BIAQAAU+WTmb1cwdQeAACAm6hIAQAAUzlsVJKiIgUAAOAmKlIAAMBUdqri2OlZAAAATEVFCgAAmIo1UgAAAKAiBQAAzGWfehSJFAAAMBlTewAAAKAiBQAAzGWnKo6dngUAAMBUVKQAAICpWCMFAAAAKlIAAMBc9qlHUZECAABwGxUpAABgKhstkSKRAgAA5vKw0eQeU3sAAABuoiJlsbj1nyruq0+VlPCHJCmobHk1u6+3Kte/zeLI7GvP7l36aPFc/ffAfp0+laAXot5WsztbWx2WrS1bskhzY2YrMSFBlatU1ejnxqhReGOrw7IlPlPMxXi7h6k95Br/EkFq2WOgipcqI0n6aeuX+vit8er3arRKlq1gbXA2dfHCBVWsUl3tOnbRK2Oftjoc21u7ZrVenxilsePGq0HDRvrog6Ua+thgrVj1uUJCQ60Oz3b4TDEX4w0SKYtVaRTh8vrOBwco7qvPdPzQfv4S5pEmEc3VJKK51WEUGAvmxei+Bx7Q/d26S5JGR47Vtm1f64NlSzT8KRLZ3MZnirkYb/c4WCOFvJCWlqp92zfqcspFlalay+pwgJt2+dIl7d+3VxHNXBPXiGZ36IfdcRZFVXDwmWIuxrtgsrwitX//fu3YsUMRERGqUaOGDhw4oClTpiglJUW9e/dW69b2X7uScOywFrz4pK5cviRvH1/dN2K8gsqUtzos4KadOXtGqampCgwMdGkPDAxSYmKCRVHZH58p5mK8c441Urlk7dq16tKli4oUKaLz589rxYoVeuSRR1S/fn0ZhqF//etf+uKLL66bTKWkpCglJcWl7fKlFHl5O/M6/FxTIqSs+r86XRfP/6WDsV/r8xlvqNfz/+EvImzj2t/VMgzDVr+1ld/wmWIuxjvn2P4gl0yYMEGjRo3SqVOnFBMTo169emnw4MFat26d1q9fr9GjR2vixInX7SMqKkoBAQEux+q500x6gtzhWchLxUuXUUil6mrZY6CCwypp59oVVocF3LTixYrL09NTiYmJLu2nT59SYGCQRVHZH58p5mK8CzZLE6m9e/eqX79+kqQHH3xQf/75px544IH09x966CH9+OOP1+0jMjJSSUlJLkfHfkPzMuy8ZxhKvXLJ6iiAm+bl7a2atWprx7ZvXNp3bNum+g0aWhRVAcRnirkY7xtyOPLuMJvla6Su8vDwkI+Pj4oVK5be5u/vr6SkpOte53Q65XS6TuN5eZ/NgwjzxuZls1Wp/m0qGlhSly5e0P7tG3V0/4/qPvo1q0OzrQvnz+v470fTX584/j/9cvCA/IsGKLh0iIWR2VOfvv019rnRqlWnjurXb6jlHy5TfHy8uvfoaXVotsRnirkYb1iaSFWoUEGHDh1SlSpVJEnbt29XWFhY+vvHjh1TSIi9/2FLPndWn02fpOSzp+Us7KeS5Sqq++jXVLFuuNWh2dbBA3v17L8Hpb+eOfVNSVLbDvfqmedftios27q7Q0clnT2jmdHTlJBwUlWqVtN702cqNLSM1aHZEp8p5mK83WOnJZIOwzAMq24+ffp0lStXTp06dcr0/bFjx+qPP/7Q+++/n6N+58QevfFJyFV3VQy2OoQCJaSYj9UhFCiL4/hMgb0NaBJ245Ny0Zf78+5bu+1rlsyzvjNjaUXq8ccfv+77r776qkmRAAAAs7AhJwAAAPLPYnMAAFAweNinIEUiBQAAzMXUHgAAAKhIAQAAc9lp+wMqUgAAAG6iIgUAAEzFGikAAABQkQIAAOZi+wMAAAA3MbUHAAAAKlIAAMBcbH8AAABwi4uKilKTJk3k7++v4OBgde3aVT///HOO+iCRAgAApnLk4ZETmzdv1rBhw7Rjxw6tW7dOV65cUfv27ZWcnJztPpjaAwAABdLatWtdXsfExCg4OFi7du3SnXfema0+SKQAAICpPPLpIqmkpCRJUokSJbJ9DYkUAACwjZSUFKWkpLi0OZ1OOZ3O615nGIZGjhyp5s2bq06dOtm+H2ukAACAqfJyjVRUVJQCAgJcjqioqBvG9MQTT+jHH3/UkiVLcvQsVKQAAIC58nBmLzIyUiNHjnRpu1E16t///rdWrVqlLVu2qGzZsjm6H4kUAACwjexM411lGIb+/e9/a8WKFdq0aZMqVqyY4/uRSAEAAFPll5+IGTZsmBYvXqxPPvlE/v7+OnHihCQpICBAvr6+2eqDNVIAAKBAio6OVlJSklq1aqWQkJD0Y9myZdnug4oUAAAwVX7Z/cAwjJvug4oUAACAm6hIAQAAU+WTglSuoCIFAADgJipSAADAXDYqSZFIAQAAU+WX7Q9yA1N7AAAAbqIiBQAATJVftj/IDVSkAAAA3ERFCgAAmMpGBSkqUgAAAO6iIgUAAMxlo5IUiRQAADAV2x8AAACAihQAADAX2x8AAACAihQAADCXjQpS9kykejUMszoEAICbhr32pdUhFDgDVgyyOoRbli0TKQAAkI/ZqCTFGikAAAA3UZECAACmstM+UiRSAADAVGx/AAAAACpSAADAXDYqSFGRAgAAcBcVKQAAYC4blaSoSAEAALiJihQAADAV2x8AAAC4ie0PAAAAQEUKAACYy0YFKSpSAAAA7qIiBQAAzGWjkhQVKQAAADdRkQIAAKay0/YHVKQAAADcREUKAACYyk77SJFIAQAAU9koj2JqDwAAwF1UpAAAgLlsVJKiIgUAAOAmKlIAAMBUbH8AAAAAKlIAAMBcdtr+gIoUAACAm6hIAQAAU9moIEUiBQAATGajTIqpPQAAUGBt2bJFnTt3VmhoqBwOh1auXJmj60mkAACAqRx5+H85lZycrPr16+vdd99161mY2gMAAAVWhw4d1KFDB7evJ5ECAACmstP2ByRSAADANlJSUpSSkuLS5nQ65XQ68+R+rJECAACmcuThERUVpYCAAJcjKioqz56FihQAADBXHk7tRUZGauTIkS5teVWNkkikAACAjeTlNF5mSKQAAICp3NmmIK/89ddfOnToUPrrw4cPa/fu3SpRooTCwsJueD2JFAAAKLB27typu+66K/311WnBvn37au7cuTe8nkQqn1i2ZJHmxsxWYkKCKlepqtHPjVGj8MZWh2VbjLe5GG/zxK3/VHFffaqkhD8kSUFly6vZfb1Vuf5tFkdmTwdm9FD5YP8M7dPX7NNTM7dZENGtIT9tf9CqVSsZhuH29XxrLx9Yu2a1Xp8YpcGPDtGyj1aqUaNwDX1ssOKPH7c6NFtivM3FeJvLv0SQWvYYqL4vv6e+L7+n8rUa6OO3xivh9yNWh2ZLzUd9ogr9F6UfHcevliR9/M1hiyODWUik8oEF82J03wMP6P5u3VWpcmWNjhyr0iGl9cGyJVaHZkuMt7kYb3NVaRShyg2aqkRIWZUIKas7Hxwgbx9fHT+03+rQbCnx3EX9cfZC+tGxcZh+iU/S1r3xVoeWr+Xl9gdmy3eJ1M2U125Fly9d0v59exXRrLlLe0SzO/TD7jiLorIvxttcjLe10tJStW/7Rl1OuagyVWtZHY7teRXyUM+WVTTvq4NWhwIT5bs1Uk6nUz/88INq1qxpdSimOHP2jFJTUxUYGOjSHhgYpMTEBIuisi/G21yMtzUSjh3Wghef1JXLl+Tt46v7RoxXUJnyVodle/feVl7F/Ly1cMN/rQ4l38tPa6RulmWJ1LWbZV2VmpqqiRMnpn/wvvXWW9ftJ7Ot4A1Pc/eQyA2Oa/5UGYaRoQ25h/E2F+NtrhIhZdX/1em6eP4vHYz9Wp/PeEO9nv8PyVQe69u2ur74/nfFnzlvdSi3APv8/bcskZo8ebLq16+vYsWKubQbhqH9+/fLz88vWx+0UVFReumll1zaxo4br+dfeDEXo807xYsVl6enpxITE13aT58+pcDAIIuisi/G21yMtzU8C3mpeOkykqSQStUV/+vP2rl2he4eOMLawGwsrGQRta4Xqp6vr7c6FJjMsjVSr776qpKSkjRu3Dht3Lgx/fD09NTcuXO1ceNGbdiw4Yb9REZGKikpyeUY9WykCU+QO7y8vVWzVm3t2PaNS/uObdtUv0FDi6KyL8bbXIx3PmEYSr1yyeoobK1P62o6mXRRa3YeszqUW4LDkXeH2SyrSEVGRqpt27bq3bu3OnfurKioKHl5eeW4n8y2gr94JbeiNEefvv019rnRqlWnjurXb6jlHy5TfHy8uvfoaXVotsR4m4vxNtfmZbNVqf5tKhpYUpcuXtD+7Rt1dP+P6j76NatDsy2HQ3qkdVUt2vRfpaYVrC9MweLF5k2aNNGuXbs0bNgwNW7cWAsXLiyQ6ybu7tBRSWfPaGb0NCUknFSVqtX03vSZCg0tY3VotsR4m4vxNlfyubP6bPokJZ89LWdhP5UsV1HdR7+minXDrQ7NtlrXK6OwYH/N++pnq0O5ZdjpX3qHkU/2G1i6dKlGjBihhIQE7dmzR7Vquf9V3VutIgUgf1scd9TqEAqUYa99aXUIBc6FFYNMvd/xs3k31RxazDvP+s5Mvtn+oGfPnmrevLl27dql8uX5ZgkAAHZlp8mnfJNISVLZsmVVtmxZq8MAAADIlnyVSAEAAPtz2GiVFIkUAAAwl33yqPz3W3sAAAC3CipSAADAVDYqSFGRAgAAcBcVKQAAYCo7bX9ARQoAAMBNVKQAAICp2P4AAADAXfbJo5jaAwAAcBcVKQAAYCobFaSoSAEAALiLihQAADAV2x8AAACAihQAADCXnbY/oCIFAADgJipSAADAVKyRAgAAAIkUAACAu5jaAwAApmJqDwAAAFSkAACAudj+AAAAAFSkAACAuey0RopECgAAmMpGeRRTewAAAO6iIgUAAMxlo5IUFSkAAAA3UZECAACmYvsDAAAAUJECAADmstP2B1SkAAAA3ERFCgAAmMpGBSkSKQAAYDIbZVJM7QEAgAJt2rRpqlixonx8fBQeHq6tW7dm+1oSKQAAYCpHHv5fTi1btkwjRozQ2LFjFRcXpxYtWqhDhw46evRotq4nkQIAAAXWW2+9pYEDB2rQoEGqWbOmJk+erHLlyik6Ojpb15NIAQAAUzkceXfkxKVLl7Rr1y61b9/epb19+/batm1btvpgsTkAALCNlJQUpaSkuLQ5nU45nc4M5yYmJio1NVWlSpVyaS9VqpROnDiRrfvZMpHyuQWfKiUlRVFRUYqMjMz0f2zkPsbcXLfyeA9oEmZ1CDl2S4/3ikFWh+CWW3nMzZaX/06/+EqUXnrpJZe28ePH68UXX8zyGsc1pSzDMDK0ZXmtYRhGjqNErjt37pwCAgKUlJSkokWLWh1OgcCYm4vxNhfjbT7GPH/ISUXq0qVLKly4sD788EPdd9996e3Dhw/X7t27tXnz5hvejzVSAADANpxOp4oWLepyZFUh9Pb2Vnh4uNatW+fSvm7dOjVr1ixb97sFJ8EAAAByx8iRI9WnTx81btxYERERmjlzpo4eParHH388W9eTSAEAgAKrR48eOnXqlCZMmKD4+HjVqVNHq1evVvny5bN1PYlUPuF0OjV+/HgWKJqIMTcX420uxtt8jPmta+jQoRo6dKhb17LYHAAAwE0sNgcAAHATiRQAAICbSKQAAADcRCKVT0ybNk0VK1aUj4+PwsPDtXXrVqtDsq0tW7aoc+fOCg0NlcPh0MqVK60OydaioqLUpEkT+fv7Kzg4WF27dtXPP/9sdVi2FR0drXr16qXvnxMREaE1a9ZYHVaBERUVJYfDoREjRlgdCkxCIpUPLFu2TCNGjNDYsWMVFxenFi1aqEOHDjp69KjVodlScnKy6tevr3fffdfqUAqEzZs3a9iwYdqxY4fWrVunK1euqH379kpOTrY6NFsqW7asJk6cqJ07d2rnzp1q3bq1unTpor1791odmu3FxsZq5syZqlevntWhwER8ay8faNq0qRo1aqTo6Oj0tpo1a6pr166KioqyMDL7czgcWrFihbp27Wp1KAVGQkKCgoODtXnzZt15551Wh1MglChRQm+88YYGDhxodSi29ddff6lRo0aaNm2aXnnlFTVo0ECTJ0+2OiyYgIqUxS5duqRdu3apffv2Lu3t27fXtm3bLIoKyDtJSUmS/v7HHXkrNTVVS5cuVXJysiIiIqwOx9aGDRumTp06qW3btlaHApOxIafFEhMTlZqaqlKlSrm0lypVSidOnLAoKiBvGIahkSNHqnnz5qpTp47V4djWnj17FBERoYsXL6pIkSJasWKFatWqZXVYtrV06VJ9//33io2NtToUWIBEKp9wOBwurw3DyNAG3OqeeOIJ/fjjj/r666+tDsXWqlevrt27d+vs2bNavny5+vbtq82bN5NM5YFjx45p+PDh+vLLL+Xj42N1OLAAiZTFgoKC5OnpmaH6dPLkyQxVKuBW9u9//1urVq3Sli1bVLZsWavDsTVvb29VqVJFktS4cWPFxsZqypQpmjFjhsWR2c+uXbt08uRJhYeHp7elpqZqy5Ytevfdd5WSkiJPT08LI0ReY42Uxby9vRUeHq5169a5tK9bt07NmjWzKCog9xiGoSeeeEIff/yxNmzYoIoVK1odUoFjGIZSUlKsDsOW2rRpoz179mj37t3pR+PGjfXwww9r9+7dJFEFABWpfGDkyJHq06ePGjdurIiICM2cOVNHjx7V448/bnVotvTXX3/p0KFD6a8PHz6s3bt3q0SJEgoLC7MwMnsaNmyYFi9erE8++UT+/v7p1deAgAD5+vpaHJ39jBkzRh06dFC5cuX0559/aunSpdq0aZPWrl1rdWi25O/vn2G9n5+fnwIDA1kHWECQSOUDPXr00KlTpzRhwgTFx8erTp06Wr16tcqXL291aLa0c+dO3XXXXemvR44cKUnq27ev5s6da1FU9nV1W49WrVq5tMfExKhfv37mB2Rzf/zxh/r06aP4+HgFBASoXr16Wrt2rdq1a2d1aIAtsY8UAACAm1gjBQAA4CYSKQAAADeRSAEAALiJRAoAAMBNJFIAAABuIpECAABwE4kUAACAm0ikAAAA3EQiBSBPvPjii2rQoEH66379+qlr166mx3HkyBE5HA7t3r3b9HsDsD8SKaCA6devnxwOhxwOh7y8vFSpUiU988wzSk5OztP7TpkyJds/wUPyA+BWwW/tAQXQ3XffrZiYGF2+fFlbt27VoEGDlJycnP67eFddvnxZXl5euXLPgICAXOkHAPITKlJAAeR0OlW6dGmVK1dOvXr10sMPP6yVK1emT8fNmTNHlSpVktPplGEYSkpK0qOPPqrg4GAVLVpUrVu31g8//ODS58SJE1WqVCn5+/tr4MCBunjxosv7107tpaWladKkSapSpYqcTqfCwsL06quvSpIqVqwoSWrYsKEcDofLDx7HxMSoZs2a8vHxUY0aNTRt2jSX+3z33Xdq2LChfHx81LhxY8XFxeXiyAGAKypSAOTr66vLly9Lkg4dOqQPPvhAy5cvl6enpySpU6dOKlGihFavXq2AgADNmDFDbdq00cGDB1WiRAl98MEHGj9+vN577z21aNFCCxYs0DvvvKNKlSplec/IyEjNmjVLb7/9tpo3b674+HgdOHBA0t/J0G233ab169erdu3a8vb2liTNmjVL48eP17vvvquGDRsqLi5OgwcPlp+fn/r27avk5GTdc889at26tRYuXKjDhw9r+PDheTx6AAo0A0CB0rdvX6NLly7pr7/99lsjMDDQePDBB43x48cbXl5exsmTJ9Pf/+qrr4yiRYsaFy9edOmncuXKxowZMwzDMIyIiAjj8ccfd3m/adOmRv369TO977lz5wyn02nMmjUr0xgPHz5sSDLi4uJc2suVK2csXrzYpe3ll182IiIiDMMwjBkzZhglSpQwkpOT09+Pjo7OtC8AyA1M7QEF0GeffaYiRYrIx8dHERERuvPOOzV16lRJUvny5VWyZMn0c3ft2qW//vpLgYGBKlKkSPpx+PBh/fLLL5Kk/fv3KyIiwuUe177+p/379yslJUVt2rTJdswJCQk6duyYBg4c6BLHK6+84hJH/fr1Vbhw4WzFAQA3i6k9oAC66667FB0dLS8vL4WGhrosKPfz83M5Ny0tTSEhIdq0aVOGfooVK+bW/X19fXN8TVpamqS/p/eaNm3q8t7VKUjDMNyKBwDcRSIFFEB+fn6qUqVKts5t1KiRTpw4oUKFCqlChQqZnlOzZk3t2LFDjzzySHrbjh07suyzatWq8vX11VdffaVBgwZleP/qmqjU1NT0tlKlSqlMmTL69ddf9fDDD2fab61atbRgwQJduHAhPVm7XhwAcLOY2gNwXW3btlVERIS6du2qL774QkeOHNG2bdv0/PPPa+fOnZKk4cOHa86cOZozZ44OHjyo8ePHa+/evVn26ePjo2effVajR4/W/Pnz9csvv2jHjh2aPXu2JCk4OFi+vr5au3at/vjjDyUlJUn6e5PPqKgoTZkyRQcPHtSePXsUExOjt956S5LUq1cveXh4aODAgdq3b59Wr16tN998M49HCEBBRiIF4LocDodWr16tO++8UwMGDFC1atXUs2dPHTlyRKVKlZIk9ejRQy+88IKeffZZhYeH67ffftOQIUOu2++4ceP09NNP64UXXlDNmjXVo0cPnTx5UpJUqFAhvfPOO5oxY4ZCQ0PVpUsXSdKgQYP0/vvva+7cuapbt65atmypuXPnpm+XUKRIEX366afat2+fGjZsqLFjx2rSpEl5ODoACjqHwaICAAAAt1CRAgAAcBOJFAAAgJtIpAAAANxEIgUAAOAmEikAAAA3kUgBAAC4iUQKAADATSRSAAAAbiKRAgAAcBOJFAAAgJtIpAAAANxEIgUAAOCm/wPEycgxb+xfIgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 650x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (VAL):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4444    0.3636    0.4000        11\n",
      "           1     0.5833    0.7000    0.6364        10\n",
      "           2     0.6667    0.8000    0.7273        10\n",
      "           3     0.5000    0.3000    0.3750        10\n",
      "           4     0.5833    0.7000    0.6364        10\n",
      "\n",
      "    accuracy                         0.5686        51\n",
      "   macro avg     0.5556    0.5727    0.5550        51\n",
      "weighted avg     0.5534    0.5686    0.5520        51\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC-ROC (VAL): micro 0.8223 | macro 0.8335\n"
     ]
    }
   ],
   "source": [
    "# --- Split 2: Person-Dependent (adjust paths to your second split)\n",
    "train_ids_B = read_ids_from_dir(\"Person-Dependent_Split/train\")\n",
    "val_ids_B   = read_ids_from_dir(\"Person-Dependent_Split/val\")\n",
    "train_df_B  = df[df[\"video_id\"].isin(train_ids_B)].reset_index(drop=True)\n",
    "val_df_B    = df[df[\"video_id\"].isin(val_ids_B)].reset_index(drop=True)\n",
    "\n",
    "res_B = run_split(\"dep\", train_ids_B, val_ids_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b83bb4-b8b6-4d36-a5a7-2b7231e774d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992c298-d29b-4790-a8db-3e1fe62b5bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3dc5d7-7e8a-4fb2-8478-72bac6e96109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b785977-928c-4e75-8891-322d4818aec6",
   "metadata": {},
   "source": [
    "# Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2176daf-6755-4cbd-9e78-267d815cb013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== [ind] CLS: Train+Val -> Test (labels from CSV) =====\n",
      "train+val: 350 | test: 150 | label_col=view_range_enc_ind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mansi Jadhav\\AppData\\Local\\Temp\\ipykernel_25176\\658662478.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_obj = torch.load(pt_path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "internal train: 295 | internal val: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train: loss 1.8722 acc 0.2814 f1 0.2860 || Val: loss 1.3620 acc 0.4000 f1 0.3093\n",
      "Epoch 02 | Train: loss 1.4726 acc 0.3831 f1 0.3836 || Val: loss 1.4384 acc 0.4545 f1 0.3170\n",
      "Epoch 03 | Train: loss 1.3759 acc 0.3864 f1 0.3812 || Val: loss 1.3012 acc 0.6000 f1 0.5402\n",
      "Epoch 04 | Train: loss 1.3552 acc 0.4271 f1 0.4283 || Val: loss 1.7878 acc 0.2909 f1 0.2562\n",
      "Epoch 05 | Train: loss 1.4008 acc 0.3898 f1 0.3892 || Val: loss 1.4636 acc 0.4000 f1 0.2982\n",
      "Epoch 06 | Train: loss 1.2501 acc 0.4475 f1 0.4512 || Val: loss 1.3003 acc 0.4909 f1 0.4897\n",
      "Epoch 07 | Train: loss 1.2385 acc 0.4915 f1 0.4887 || Val: loss 1.5382 acc 0.4545 f1 0.4322\n",
      "Epoch 08 | Train: loss 1.2766 acc 0.4610 f1 0.4601 || Val: loss 1.5471 acc 0.3636 f1 0.2755\n",
      "Epoch 09 | Train: loss 1.2303 acc 0.4983 f1 0.4841 || Val: loss 1.2786 acc 0.4545 f1 0.3854\n",
      "Epoch 10 | Train: loss 1.0870 acc 0.5458 f1 0.5430 || Val: loss 1.6316 acc 0.2545 f1 0.2334\n",
      "Epoch 11 | Train: loss 1.2971 acc 0.4814 f1 0.4773 || Val: loss 1.4452 acc 0.4182 f1 0.3362\n",
      "Early stopping.\n",
      "[ind] Best epoch: 3 | Best Val Acc=0.6000\n",
      "[ind] TEST — Acc=0.3533 | Macro-F1=0.3058 | ROC-AUC micro=0.6824222222222223 macro=0.6761911475234944\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7 23  5  0  5]\n",
      " [ 4 15  3  0  2]\n",
      " [ 3 12  3  0  5]\n",
      " [ 2 10  3  3 11]\n",
      " [ 0  7  1  1 25]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4375    0.1750    0.2500        40\n",
      "           1     0.2239    0.6250    0.3297        24\n",
      "           2     0.2000    0.1304    0.1579        23\n",
      "           3     0.7500    0.1034    0.1818        29\n",
      "           4     0.5208    0.7353    0.6098        34\n",
      "\n",
      "    accuracy                         0.3533       150\n",
      "   macro avg     0.4264    0.3538    0.3058       150\n",
      "weighted avg     0.4462    0.3533    0.3170       150\n",
      "\n",
      "[ind] Saved test predictions to: results_final\\video_cls_test_ind.csv\n",
      "[ind] Saved final model bundle to: models_final\\video_reg_final_ind.pt\n",
      "\n",
      "===== [dep] CLS: Train+Val -> Test (labels from CSV) =====\n",
      "train+val: 350 | test: 150 | label_col=view_range_enc_dep\n",
      "internal train: 300 | internal val: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mansi Jadhav\\AppData\\Local\\Temp\\ipykernel_25176\\658662478.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_obj = torch.load(pt_path, map_location=DEVICE)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train: loss 3.0376 acc 0.2933 f1 0.2924 || Val: loss 1.7017 acc 0.3800 f1 0.2844\n",
      "Epoch 02 | Train: loss 1.5654 acc 0.4100 f1 0.3841 || Val: loss 1.5102 acc 0.3200 f1 0.2381\n",
      "Epoch 03 | Train: loss 1.4508 acc 0.3467 f1 0.3363 || Val: loss 1.9688 acc 0.2800 f1 0.1595\n",
      "Epoch 04 | Train: loss 1.4198 acc 0.3733 f1 0.3613 || Val: loss 1.5721 acc 0.2800 f1 0.2476\n",
      "Epoch 05 | Train: loss 1.3637 acc 0.4033 f1 0.3632 || Val: loss 1.6315 acc 0.3400 f1 0.2620\n",
      "Epoch 06 | Train: loss 1.3840 acc 0.3967 f1 0.3912 || Val: loss 1.8669 acc 0.2400 f1 0.1878\n",
      "Epoch 07 | Train: loss 1.3612 acc 0.4233 f1 0.4173 || Val: loss 1.6808 acc 0.3600 f1 0.3096\n",
      "Epoch 08 | Train: loss 1.3266 acc 0.4167 f1 0.3994 || Val: loss 1.8099 acc 0.3000 f1 0.2333\n",
      "Epoch 09 | Train: loss 1.3350 acc 0.4300 f1 0.4288 || Val: loss 1.6315 acc 0.3000 f1 0.2595\n",
      "Early stopping.\n",
      "[dep] Best epoch: 1 | Best Val Acc=0.3800\n",
      "[dep] TEST — Acc=0.2933 | Macro-F1=0.2115 | ROC-AUC micro=0.6275444444444445 macro=0.6072877857860488\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 5 14  0  0  7]\n",
      " [11 20  0  0  4]\n",
      " [ 3 13  0  0 11]\n",
      " [ 8 13  0  0 18]\n",
      " [ 2  2  0  0 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1724    0.1923    0.1818        26\n",
      "           1     0.3226    0.5714    0.4124        35\n",
      "           2     0.0000    0.0000    0.0000        27\n",
      "           3     0.0000    0.0000    0.0000        39\n",
      "           4     0.3220    0.8261    0.4634        23\n",
      "\n",
      "    accuracy                         0.2933       150\n",
      "   macro avg     0.1634    0.3180    0.2115       150\n",
      "weighted avg     0.1545    0.2933    0.1988       150\n",
      "\n",
      "[dep] Saved test predictions to: results_final\\video_cls_test_dep.csv\n",
      "[dep] Saved final model bundle to: models_final\\video_reg_final_dep.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report, confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "import pickle\n",
    "\n",
    "FEATURE_DIR = \"videomae_features_new\"\n",
    "CSV_PATH    = \"FinalDataset.csv\"\n",
    "\n",
    "BATCH_SIZE_DEFAULT = 8        \n",
    "N_EPOCHS    = 40\n",
    "PATIENCE    = 8\n",
    "SEED        = 42\n",
    "INPUT_DIM   = 768             # feature dimension\n",
    "NUM_WORKERS = 0\n",
    "DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PIN         = torch.cuda.is_available()\n",
    "\n",
    "LABEL_COL_MAP = {\n",
    "    \"ind\": \"view_range_enc_ind\",\n",
    "    \"dep\": \"view_range_enc_dep\",\n",
    "}\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    s = SEED + worker_id\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "def read_ids_from_dir(dir_path: str):\n",
    "    assert os.path.isdir(dir_path), f\"Missing directory: {dir_path}\"\n",
    "    return set(os.path.splitext(fn)[0] for fn in os.listdir(dir_path))\n",
    "\n",
    "def get_dfs_for_split(split_tag: str):\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    base = f\"Person-{'Independent' if split_tag=='ind' else 'Dependent'}_Split\"\n",
    "    train_ids = read_ids_from_dir(os.path.join(base, \"train\"))\n",
    "    val_ids   = read_ids_from_dir(os.path.join(base, \"val\"))\n",
    "    test_ids  = read_ids_from_dir(os.path.join(base, \"test\"))\n",
    "\n",
    "    trainval_ids = train_ids | val_ids\n",
    "    trainval_df  = df[df.video_id.isin(trainval_ids)].reset_index(drop=True) # Combine train and validation dataframe\n",
    "    test_df      = df[df.video_id.isin(test_ids)].reset_index(drop=True) # Get the test dataset\n",
    "\n",
    "    need = {\"video_id\",\"channel_id\",\"log_view_count\",\"view_count\",\n",
    "            \"view_range_enc_ind\",\"view_range_enc_dep\"}\n",
    "    assert need.issubset(trainval_df.columns), f\"Missing in trainval: {need - set(trainval_df.columns)}\"\n",
    "    assert need.issubset(test_df.columns), f\"Missing in test: {need - set(test_df.columns)}\"\n",
    "    return trainval_df, test_df\n",
    "\n",
    "def build_internal_val_from_labels(trainval_df: pd.DataFrame, split_tag: str,\n",
    "                                   val_rel=0.15, seed=SEED):\n",
    "    label_col = LABEL_COL_MAP[split_tag]\n",
    "    assert label_col in trainval_df.columns, f\"Missing {label_col}.\"\n",
    "    assert \"channel_id\" in trainval_df.columns, \"Missing channel_id.\"\n",
    "\n",
    "    # Ensure integer-encoded labels 0..K-1\n",
    "    y = pd.Series(trainval_df[label_col]).astype(str)\n",
    "    if not y.str.fullmatch(r\"\\d+\").all():\n",
    "        y_int = pd.Series(pd.Categorical(y).codes).astype(int)\n",
    "    else:\n",
    "        y_int = y.astype(int)\n",
    "\n",
    "    n_splits = max(2, int(round(1.0 / val_rel)))  # e.g., 0.15 -> ~7\n",
    "    idx = np.arange(len(trainval_df))\n",
    "\n",
    "    if split_tag == \"ind\":\n",
    "        groups = trainval_df[\"channel_id\"].values\n",
    "        cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)  # no channel overlap for ind\n",
    "        tr_idx, va_idx = next(cv.split(idx, y_int, groups=groups))\n",
    "    else:\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)   # channel overlap for dep\n",
    "        tr_idx, va_idx = next(cv.split(idx.reshape(-1,1), y_int))\n",
    "\n",
    "    return tr_idx, va_idx, y_int\n",
    "\n",
    "# Load best params/state \n",
    "def load_best_cls_bundle(split_tag: str):\n",
    "    pt_path  = MODEL_DIR / f\"video_cls_{split_tag}.pt\"   # Load the best saved model\n",
    "    pkl_path = MODEL_DIR / f\"video_cls_bundle_{split_tag}.pkl\"\n",
    "    assert pt_path.exists(), f\"Missing: {pt_path}\"\n",
    "    state_obj = torch.load(pt_path, map_location=DEVICE)\n",
    "    if isinstance(state_obj, dict) and \"state_dict\" in state_obj:\n",
    "        state_dict = state_obj[\"state_dict\"]\n",
    "    else:\n",
    "        state_dict = state_obj  # saved raw state_dict\n",
    "\n",
    "    best_params = None\n",
    "    class_names = None\n",
    "    num_classes = None\n",
    "    if pkl_path.exists():\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            bundle = pickle.load(f)\n",
    "        best_params = bundle.get(\"best_params\") or bundle.get(\"params\")\n",
    "        class_names = bundle.get(\"class_names\")\n",
    "        num_classes = bundle.get(\"num_classes\")\n",
    "        if num_classes is None and class_names is not None:\n",
    "            num_classes = len(class_names)\n",
    "\n",
    "    return state_dict, best_params, class_names, num_classes\n",
    "\n",
    "# Train / Eval loops\n",
    "def run_epoch(model, loader, criterion, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "\n",
    "    all_logits, all_targets = [], []\n",
    "    running_loss, n_batches = 0.0, 0\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            logits = model(xb)      # forward pass\n",
    "            loss = criterion(logits, yb)    # \n",
    "\n",
    "            if is_train:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(yb.detach().cpu())\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "    logits_np = torch.cat(all_logits, dim=0).numpy()\n",
    "    targets_np = torch.cat(all_targets, dim=0).numpy()\n",
    "    preds = logits_np.argmax(axis=1)\n",
    "    acc = accuracy_score(targets_np, preds)\n",
    "    f1  = f1_score(targets_np, preds, average=\"macro\")\n",
    "\n",
    "    return running_loss / max(n_batches, 1), acc, f1, logits_np, targets_np\n",
    "\n",
    "# ======================= Runner (train+val -> test) ===========\n",
    "def train_on_trainval_then_test_cls(split_tag: str):\n",
    "    \"\"\"\n",
    "    Classification pipeline:\n",
    "    - Load best params/state (if best_params missing, fall back to defaults)\n",
    "    - Create one internal val from train+val via precomputed labels (no new bins)\n",
    "    - Train CE, early stop on Val Accuracy\n",
    "    - Evaluate on TEST: Acc, Macro-F1, per-class report, confusion, ROC-AUC (micro+macro)\n",
    "    - Save predictions CSV + summary JSON\n",
    "    \"\"\"\n",
    "    set_seed(SEED)\n",
    "    print(f\"\\n===== [{split_tag}] CLS: Train+Val -> Test (labels from CSV) =====\")\n",
    "\n",
    "    # Dataframes\n",
    "    trainval_df, test_df = get_dfs_for_split(split_tag)\n",
    "    label_col = LABEL_COL_MAP[split_tag]\n",
    "    print(f\"train+val: {len(trainval_df)} | test: {len(test_df)} | label_col={label_col}\")\n",
    "\n",
    "    _, _, y_int = build_internal_val_from_labels(trainval_df, split_tag=split_tag, val_rel=0.15, seed=SEED)\n",
    "\n",
    "    # Load best bundle (state dict + hyperparams)\n",
    "    state_dict, best_params, class_names, num_classes = load_best_cls_bundle(split_tag)\n",
    "\n",
    "    if best_params is None:\n",
    "        # sensible defaults if bundle missing hyperparams\n",
    "        best_params = {\n",
    "            \"batch_size\": BATCH_SIZE_DEFAULT,\n",
    "            \"lr\": 1e-3,\n",
    "            \"weight_decay\": 1e-5,\n",
    "            \"nhead\": 8,\n",
    "            \"num_layers\": 2,\n",
    "            \"dim_ff\": 1024,\n",
    "            \"dropout\": 0.1\n",
    "        }\n",
    "    batch_size = int(best_params.get(\"batch_size\", BATCH_SIZE_DEFAULT))\n",
    "\n",
    "    # Build internal split\n",
    "    tr_idx, va_idx, _ = build_internal_val_from_labels(trainval_df, split_tag=split_tag, val_rel=0.15, seed=SEED)\n",
    "    tr_in = trainval_df.iloc[tr_idx].reset_index(drop=True)\n",
    "    va_in = trainval_df.iloc[va_idx].reset_index(drop=True)\n",
    "    print(f\"internal train: {len(tr_in)} | internal val: {len(va_in)}\")\n",
    "\n",
    "    # Model\n",
    "    model = TransformerClassifier(\n",
    "        d_model=INPUT_DIM,\n",
    "        nhead=int(best_params[\"nhead\"]),\n",
    "        num_layers=int(best_params[\"num_layers\"]),\n",
    "        num_classes=5\n",
    "    ).to(DEVICE)\n",
    "    # load pretrained/best weights as initialization\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Loaders\n",
    "    g = torch.Generator().manual_seed(SEED)    # Reproducibility\n",
    "    tr_loader = DataLoader(\n",
    "        TemporalFeatureDataset(tr_in, feature_dir=FEATURE_DIR, target_column=label_col),\n",
    "        batch_size=batch_size, shuffle=True, generator=g,\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN,\n",
    "        worker_init_fn=worker_init_fn if NUM_WORKERS>0 else None\n",
    "    )\n",
    "    va_loader = DataLoader(\n",
    "        TemporalFeatureDataset(va_in, feature_dir=FEATURE_DIR, target_column=label_col),\n",
    "        batch_size=batch_size, shuffle=False,                               # no shuffle\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN,\n",
    "        worker_init_fn=worker_init_fn if NUM_WORKERS>0 else None\n",
    "    )\n",
    "    te_loader = DataLoader(\n",
    "        TemporalFeatureDataset(test_df, feature_dir=FEATURE_DIR, target_column=label_col),\n",
    "        batch_size=batch_size, shuffle=False,                              # no shuffle\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN,\n",
    "        worker_init_fn=worker_init_fn if NUM_WORKERS>0 else None\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=float(best_params[\"lr\"]), weight_decay=float(best_params[\"weight_decay\"]))  # Get the best params\n",
    "\n",
    "    best_acc, best_state, best_epoch, bad = -1.0, None, None, 0\n",
    "    for ep in range(1, N_EPOCHS + 1):\n",
    "        tr_loss, tr_acc, tr_f1, _, _ = run_epoch(model, tr_loader, criterion, optimizer)  # Train on train set\n",
    "        va_loss, va_acc, va_f1, _, _ = run_epoch(model, va_loader, criterion, optimizer=None)  # Evaluate on the new val set\n",
    "        print(f\"Epoch {ep:02d} | Train: loss {tr_loss:.4f} acc {tr_acc:.4f} f1 {tr_f1:.4f} || \"\n",
    "              f\"Val: loss {va_loss:.4f} acc {va_acc:.4f} f1 {va_f1:.4f}\")\n",
    "        if va_acc > best_acc:\n",
    "            best_acc = float(va_acc)\n",
    "            best_f1 = float(va_f1)\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = ep\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= PATIENCE:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)     # Load the best model\n",
    "    print(f\"[{split_tag}] Best epoch: {best_epoch} | Best Val Acc={best_acc:.4f}\")\n",
    "\n",
    "    # Test evaluation\n",
    "    te_loss, te_acc, te_f1, te_logits, te_targets = run_epoch(model, te_loader, criterion, optimizer=None)\n",
    "    te_preds = te_logits.argmax(axis=1)\n",
    "\n",
    "    # ROC-AUC (micro/macro) – needs one-vs-rest probabilities\n",
    "    try:\n",
    "        te_probs = torch.softmax(torch.tensor(te_logits), dim=1).numpy()\n",
    "        classes = np.unique(np.concatenate([te_targets, te_preds]))\n",
    "        y_true_bin = label_binarize(te_targets, classes=classes)\n",
    "        auc_micro = roc_auc_score(y_true_bin, te_probs[:, classes], average=\"micro\", multi_class=\"ovr\")\n",
    "        auc_macro = roc_auc_score(y_true_bin, te_probs[:, classes], average=\"macro\", multi_class=\"ovr\")\n",
    "    except Exception as e:\n",
    "        auc_micro = None\n",
    "        auc_macro = None\n",
    "        print(f\"[{split_tag}] ROC-AUC not available ({e}).\")\n",
    "\n",
    "    cm = confusion_matrix(te_targets, te_preds)\n",
    "    report = classification_report(te_targets, te_preds, digits=4, zero_division=0)\n",
    "\n",
    "    print(f\"[{split_tag}] TEST — Acc={te_acc:.4f} | Macro-F1={te_f1:.4f} | \"\n",
    "          f\"ROC-AUC micro={auc_micro if auc_micro is not None else 'n/a'} \"\n",
    "          f\"macro={auc_macro if auc_macro is not None else 'n/a'}\")\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "    # Save predictions CSV\n",
    "    out = test_df[[\"video_id\",\"channel_id\", label_col]].copy()\n",
    "    out = out.rename(columns={label_col: \"y_true\"})\n",
    "    out[\"pred\"] = te_preds\n",
    "    # also save probabilities per class if available\n",
    "    if 'te_probs' in locals():\n",
    "        for c in range(te_probs.shape[1]):\n",
    "            out[f\"prob_{c}\"] = te_probs[:, c]\n",
    "            \n",
    "    save_csv = RESULTS_DIR / f\"video_cls_test_{split_tag}.csv\"\n",
    "    out.to_csv(save_csv, index=False)\n",
    "    print(f\"[{split_tag}] Saved test predictions to: {save_csv}\")\n",
    "\n",
    "    # --- SAVE THE FINAL (refit) MODEL BUNDLE\n",
    "    final_bundle = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"best_params\": best_params,\n",
    "        \"internal_val_acc\": best_acc,\n",
    "        \"internal_val_f1\": best_f1,\n",
    "        \"seed\": SEED,\n",
    "    }\n",
    "    final_path = MODEL_DIR / f\"video_reg_final_{split_tag}.pt\"\n",
    "    torch.save(final_bundle, final_path)\n",
    "    print(f\"[{split_tag}] Saved final model bundle to: {final_path}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"test_acc\": te_acc,\n",
    "        \"test_macro_f1\": te_f1,\n",
    "        \"roc_auc_micro\": auc_micro,\n",
    "        \"roc_auc_macro\": auc_macro,\n",
    "        \"preds_path\": save_csv,\n",
    "        \"best_epoch\": best_epoch\n",
    "    }\n",
    "\n",
    "res_ind_cls = train_on_trainval_then_test_cls(\"ind\")\n",
    "res_dep_cls = train_on_trainval_then_test_cls(\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfccd507-7abc-4541-a876-8de633ad0c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178fb583-7e6c-47b2-bffd-82ee31180682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c492f-7c68-4de6-bb1f-9e801dcc3588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0025523-662f-41ab-9c5c-8dd40525b9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
